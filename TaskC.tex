% !TEX root = Conjecture.tex
\begin{conditional}{\notappendix}
  \section{From $\POR$ to $\SFP$ and vice-versa}
  \paragraph{Introduction}
  \label{par:introduction}
  In the previous sections we have proved that
  there is a strong correspondence between the
  set of functions $\POR$ and the $\Sigma^b_1$
  formul\ae{} of $\Lpw$, precisely that:

  \[
  \forall G \in \Sigma^b_1. \exists f_G \in \POR. \big(\RS, \omega \vdash \forall x. \exists ! y. G(x, y) \land \omega \in \llbracket G(x, y) \rrbracket\big)  \leftrightarrow f_G(x, \omega) = y
  \]

  and that

  \[
  \forall f \in \POR.\exists G_f \in \Sigma^b_1. \big(\RS, \omega \vdash \forall x. \exists ! y. G(x, y) \land \omega \in \llbracket G(x, y) \rrbracket\big) \leftrightarrow f_G(x, \omega) = y
  \]


   this means that each $\Sigma^b_1$ formula of the arithmetic $\Lpw$
   can be mapped to a $\POR$ function and vice-versa. For this reason,
   if we prove that there's a similar correspondencebetweenn $\POR$
   and some standard class of functions we could be able to arithmetize
   probabilistic complexity classes such as $\BPP$.

   Indeed, $\BPP$ is defined on top of the set $\PPT$, which itself is
   defined as follows:

   \begin{defn}[$\PPT$]
     $\PPT$ is the class of functions $\Ss \longrightarrow [0, 1]^\Ss$ which
      are computable by Probabilistic Turing Machine (see \ref{def:ppt}) in
      polynomial number of steps.
   \end{defn}

   More precisely, the goal of this part is to show that
   for each $f$ in $\PPT$, the probability
   that $f(x)=y$ is equal to  measure of the sets of functions $\omega$
   which drive the corresponding function in $\POR$ to compute $y$
   on input $x$. We also want to show that the converse holds, too.
   Formally:

  \begin{conj}
    \label{conj:taskc}
    It holds that
    \begin{itemize}
      \item $\forall f\in \PPT. \exists g_f \in \POR. \mathit{Pr}[f(x)=y]=
      \mu(\{x \in \{\zzero, \oone\}^\Ss | g_f(x, \omega)=y\})$
      \item $\forall g \in \POR. \exists f_g \in \PPT.
       \mu(\{x \in \{\zzero, \oone\}^\Ss | g(x, \omega)=y\})=\mathit{Pr}[f_g(x)=y]$
    \end{itemize}
  \end{conj}

\end{conditional}
\begin{conditional}{\extendedorsup}

   \paragraph{Outline}

   In order to prove Conjecture \ref{conj:taskc}, we need to:

   \begin{enumerate}
     \item Define a formalism for which a conjecture similar to \ref{conj:taskc}
     can be proved with few effort. Such formalism is $\SFP$.
     It will be introduced in Section \ref{sec:SFP}, but we  prove the
     correspondence between $\PPT$ and $\SFP$ only at the end,
     in Section \ref{sub:SFPtoPPT}. This delay should not be too much of a problem
     because the definition of $\SFP$ is almost the same of $\PPT$ so,
     in our opinion, their equivalence is almost trivial.
     \item On top of the definition of $\SFP$, define its encoding in $\POR$
     and prove it correct. This is carried out in Section~\ref{sec:SFPtoPOR}.
     \item Finally, prove that each function in $\POR$ can be encoded in $\SFP$,
     too. This reduction is presented in Section~\ref{sec:SFPtoPOR}.
   \end{enumerate}
\end{conditional}
\begin{conditional}{\notappendix}

  We will prove that the functions
  that can be computed in the $\SFP$
  formalism are precisely the ones
  in $\POR$.
  The present Section is tripartite.
  First, in Section~\ref{sec:SFP}, we will define $\SFP$,
  then in Section~\ref{sec:SFPtoPOR},
  we will establish that all the functions that
  are calculated by an $\SFP$-machine are in
  $\POR$.
  Finally, in Section~\ref{sec:PORtoSFP},
  we will prove vice-versa that each $\POR$-function
  can be computed by an
  $\SFP$-machine.
\end{conditional}

The overall picture of the reduction is described by Figure \ref{fig:redschema}.

\begin{figure}
  \begin{resizebox}{\textwidth}{!}{%
    \begin{tikzpicture}
      \def \radius{7cm}
    %  \node (POR) {$\POR$};
    %  \node[right = 10cm of POR] (SFP) {$\SFP$};
    %  \node[below right = 2cm and 1cm of POR] (SIFPRA) {$\SIFPRA$};
    %  \node[below right = 1cm and 1cm of SIFPRA] (SIFPLA) {$\SIFPLA$};
    %  \node[above right = 1cm and 2cm  of SIFPLA] (SFPOD) {$\SFPOD$};
      \node at ({-30}:\radius) (SFP) {$\SFP$};
      \node at ({-50}:\radius) (SFPOD) {$\SFPOD$};
      \node at ({-90}:\radius) (SIFPLA) {$\SIFPLA$};
      \node at ({-130}:\radius) (SIFPRA) {$\SIFPRA$};
      \node at ({-150}:\radius) (POR) {$\POR$};

      \draw[->] (SFP) edge node[fill=white] {Section \ref{sec:SFPtoPOR}}(POR);

      \draw[->] (POR) edge[bend right=15] node[fill=white] {\ref{subsub:portosifpra}}(SIFPRA);
      \draw[->] (SIFPRA) edge[bend right=15] node[fill=white] {\ref{subsub:sifpratosifpla}}(SIFPLA);
      \draw[->] (SIFPLA) edge[bend right=15]node[fill=white] {\ref{subsub:sifplatosfpod}} (SFPOD);
      \draw[->] (SFPOD) edge[bend right=15] node[fill=white] {\ref{subsub:sfpodtosfp}}(SFP);

      \node[right = 5cm of SFP] (PPT) {$\PPT$};

      \draw[<->] (PPT) edge node[fill=white] {Section \ref{sub:SFPtoPPT}}(SFP);
      %\draw[->] (SFP) edge (PPT);
    \end{tikzpicture}
    }%
  \end{resizebox}
  \caption{Schema of the Reductions from $\POR$ from $\PPT$ and vice-versa}
  \label{fig:redschema}

\end{figure}










%%% SUBSECTION
%%% SFP-Formalism
\subsection{Preliminaries on $\SFP$ and other tools}
\label{sec:SFP}

\subsubsection{On $\SFP$ functions}
\label{subsec:SFP}
\begin{conditional}{\notappendix}

  $\SFP$ is intended to capture the concept
  of Stream Polynomial Time function. For this reason, when defining
  $\SFP$, we would like to ground it on top of some kind of Stream Turing Machines.

  Unfortunately, Probabilistic Turing Machines
  as proposed in Definition \ref{def:PTMbarak} are not
  suitable for the reduction we are aiming to. These machines' source of randomness
  is implicit,
  since its comes from an uniform distribution of probability
  (the probability of using a transition function or the other)
  and generates, as output, distributions of probabilities over strings, instead
  of strings. Differently, $\POR$ encodes it by means of an oracle function
  $\omega : \Ss \longrightarrow \Bool$ and outputs strings.

  \begin{defn}[Probabilistic Turing Machine, \cite{barak}]
    \label{def:PTMbarak}
    A probabilistic Turing machine (PTM) is a Turing machine with two
    transition functions $\delta_0, \delta_1$. To execute a PTM $M$
    on an input $x$, we choose in each step with probability $\frac 1 2$
    to apply the transition function $\delta_0$ and with probability $\frac 1 2$
    to apply $\delta_1$. This choice is made independently of all previous choices.
  \end{defn}

  For these reason we decided to use a slight variation of such model, which
  uses a explicit read-only random tape instead of a probability function as
  source of randomness to determine the transition.
  This is what we call a Stream Machine.

  Stream machines are ordinary $k+1$-taped Turing Machines which use one of
  their tape to store an infinite stream of characters. This tape, which we will
  also call \emph{oracle}, is read from left to right, one character for transition.

  The formalism of the Stream Machine is an useful intermediate between $\POR$
  and $\PPT$. Indeed:
  \begin{itemize}
    \item It uses a tape as explicit source of randomness, which can
    be easily represented by means of a function $\eta: \Nat \longrightarrow \Bool$.
    This behavior is consistent with $\POR$, which uses functions
    $\omega: \Ss \longrightarrow \Bool$.
    \item It is a particular instance of a multi-tape Turing Machine, so many well
    known results about this formalism can be reused for the reduction from
    $\POR$ to $\SFP$.
    \item Even intuitively, $\SFP$ is almost equivalent to the PTM formalism, so it will
    be easy to prove that some interesting class of function can be characterized
    as subset of the functions computed by stream machines.
  \end{itemize}

  % The first class of functions which we will characterize as a subset of Stream
  % Machine is exactly $\SFP$.
  %
  % \begin{defn}[$\SFP$, informally]
  %   $\SFP$ is the class of functions $f: \Ss\times \Bool^\Nat \longrightarrow \Ss$ which can
  %   be computed by a Stream Machine in polynomial time.
  % \end{defn}

  In order to formalize the definition above, we need to formalize Stream Machines, too:




  %%% DF
  %%%   Stream Machine

    \begin{defn}[Stream Machine]
      \label{def:sm}
    A \emph{stream machine} is a quadruple
    $M:= \langle \Qs,\Sigma, \delta,q\rangle$,
    where:
    \begin{itemize}
    \itemsep0em
    \item $\Qs$ is a finite set of states ranged over by
    $q_1,\dots, q_n$
    %
    \item $\Sigma$ is a finite set of characters ranged
    over by $c_1,\dots, c_n$
    %
    \item $\delta:\Qs \times \Sigmab \times
    \{\zzero, \oone\} \longrightarrow \Qs
    \times \Sigmab \times \{L,R\}$
    is a transition function that describes the new configuration
    reached by an $\SFP$-machine.
    $L,R$ are two fixed constants
    (take for instance $\zzero$ and $\oone$) and
    $\Sigmab=\Sigma\cup \{\sstar\}$;
    $\sstar$ represents the \emph{blank character}, so
    $\sstar\notin \Sigma$
    %
    \item $q\in \Qs$ is an initial state,
    \end{itemize}
    Note that the assumption $\Sigma=\{\oone,\zzero\}$
    would not be reductive.
    \end{defn}

    %% Notation
    \begin{notation}
    From now on we will denote the blank character
    $\sstar$ as $c_{|\Sigma|+1}$.
    \end{notation}

    Usually, the configuration of an ordinary Turing Machine is a tuple
    which keeps track of the current state and some strings which represent the
    state of the machine tape(s). The portion of the function which has not been
    queried yet will be represented throughout a function
    $\eta: \Nat \longrightarrow \{\zzero, \oone\}$.
    % Using strings for representing
    % the configuration of the tapes is possible only tape contains a finite
    % sequence of characters, but a Stream Machine uses a tape with an infinite
    % sequence of $\zzero$ and $\oone$ as source of randomness.
    % For this reason, while defining the configuration
    % of this class of Turing Machines, we decided to represent the value of the
    % oracle tape by means of a function $\eta \in \Bool^\Nat$.


    %%% DF
    %%% Configuration of a Stream Machine
    \begin{defn}[Configuration of a Stream Machine]
      \label{def:smconf}
    The \emph{configuration of a stream machine $\MS$}
    is a quadruple $\langle \sigma, q, \tau, \eta\rangle$,
    where;
    \begin{itemize}
    \itemsep0em
    \item $\sigma\in \Sigmab^*$
    is the portion of the first tape on the left
    of the head
    %
    \item $q\in \Qs$ is the current state of $\MS$
    %
    \item $\tau\in \Sigmab$ is the portion of the first
    tape on the right of the head.
    %
    \item $\eta \in \{\zzero,\oone\}^{\Nat}$
    is the portion of the second tape that has not been read yet.
    \end{itemize}
    \end{defn}


    Now we would like to formalize the fact that at each step,
    the machine queries a new value of its oracle tape.
    The shifting of the work tape can be naturally defined
    by prefixing and post-fixing of characters to strings and the same operation
    is has to be extended to infinite tapes.

    For this reason we need to define some shifting operation between
    a function $\Nat \longrightarrow \Bool$ and a string $\sigma \in \Ss$.

    \begin{defn}[Shifting operation]
      \label{def:shifting}
      Given a string $\sigma \in \Ss$ and a function
      $\eta: \Nat \longrightarrow \Bool$, we define the shifting of $\eta$
      by the prefix $\sigma$, denoted $\sigma\eta$ as a function
      $\Nat \longrightarrow \Bool$ by induction on $\sigma$
      as follows:

      \begin{align*}
      (\eepsilon \eta)(n) &:= \eta(n)\\
      (b\tau)\eta(n) &:= \begin{cases}
                          b & \text{ if } n = 0\\
                          (\tau\eta)(n-1) & \text{otherwise}\\
                        \end{cases}
      \end{align*}

    \end{defn}

    This allows us to give a formal definition of the machine's transitions.

    %%% DF
    %%% Stream Machine Reachability Function
    \begin{defn}[Stream Machine Transition Function]
      \label{def:smtransfun}
    Given a stream machine $M=\langle \Qs,
    \Sigma, \delta, q\rangle$,
    we define the partial transition function
    $\vdash_{\delta} \Sigmab^* \times \Qs
    \times \Sigmab^* \times \{\zzero,
    \oone\}^{\Nat} \longrightarrow \Sigmab^*
    \times \Qs \times \Sigmab^* \times \{\zzero,
    \oone\}^{\Nat}$
    between two configurations of $M_S$ as:
    %
    \begin{align*}
    \langle \sigma, q, c\tau, \zzero \eta\rangle
    \vdash_{\delta} \langle\sigma c', q', \tau, \eta\rangle
    \ \ \ \ \ \ \ \ \ \ \ \ \ &\text{ if }
    \delta (q,c,\zzero)
    = \langle q',c',R\rangle
    \\
    %
    \langle \sigma c_0, q, c_1\tau, \zzero
    \eta\rangle
    \vdash_{\delta} \langle \sigma, q', c_0c_1'\tau,
    \eta\rangle
     \ \ \ \ \ \ \ \ \ \ \ \ \ &\text{ if }
    \delta (q, c_1,\zzero)
    = \langle q', c_1', L\rangle  \\
    %
    \langle \sigma, q, c\tau, \oone \eta\rangle
    \vdash_{\delta}
    \langle \sigma c', q', \tau, \eta\rangle
     \ \ \ \ \ \ \ \ \ \ \ \ \ &\text{ if }
     \delta(q, c, \oone)=
     \langle q', c', R\rangle \\
     %
     \langle \sigma c_0, q, c_1\tau,
     \oone\eta\rangle
     \vdash_{\delta} \langle \sigma,
     q', c_0c_1' \tau, \eta \rangle
      \ \ \ \ \ \ \ \ \ \ \ \ \ &\text{ if }
     \delta(q, c_1,\oone)
     = \langle q',c_1', L\rangle.
    \end{align*}
    \end{defn}

    The function obtained composing $n$ times the reachability
    function describes the configuration reached by the machine after $n$
    steps of computation. This is stated as follows:



    % DF
    \begin{defn}[Stream Machine Reachability Functions]
      \label{def:smreachfuns}
    Given a stream machine $M:=\langle \Qs,
    \Sigma, \delta, q_0\rangle$,
    we denote with $\{\reaches n {M}\}_n$
    the smallest family of relations
    for which:
    \begin{align*}
    \langle \sigma, q, \tau, \eta \rangle
    &\reaches 0 M
    \langle \sigma, q, \tau, \eta\rangle \\
    %
    \Big (
    \langle \sigma, q, \tau, \eta\rangle
    \reaches n M \langle \sigma',
    q', \tau',\eta'\rangle
    \Big )
    \wedge
    \Big (
    \langle \sigma', q',
    \tau', \eta'\rangle
    &\vdash_{\delta}
    \langle \sigma'', q', \tau'',
    \eta'' \rangle
    \Big )
    \rightarrow
    \Big (
    \langle \sigma,q,\tau, \eta\rangle
    \reaches {n+1} M\langle
    \sigma'', q'\tau'',\eta''\rangle
    \Big )
    \end{align*}
    \end{defn}

    \begin{notation}[$\reaches n \delta$]
      Given a machine $M := \langle \Qs, \Sigma \delta,q \rangle$ for sace of smplicity,
      when there is no ambiguity in writing so, we will write $\reaches \delta n$
      instead of $\reaches M n$.
    \end{notation}

    We would also like to point out that
    our machine does not use final states: the computation
    is considered finished whenever the transition function is not defined on
    the current configuration. This choice comes without a loss in generality,
    because we can imagine
    to add a final state $q_F$ and a transition from all the configurations
    on which the transition function is undefined to $q_F$.

    For seek of completeness, we want to show that each $\reaches n M$ relation
    is a function.
  \end{conditional}

  \begin{conditional}{\shortonly}
    The following result can be easily proved by induction.\footnote{For
    further details, see Section~\ref{sec:appC}}.
  \end{conditional}

  \begin{remark} If $M:=\langle \Qs,
  \Sigma, \delta, q_0\rangle$ is a Stream Machine, it holds that
  $\forall n.\reaches n M$ is
  a function.
\end{remark}


  \begin{conditional}{\appendixorsup}
    %%% LEMMA
    \begin{proof}
    The proof is by induction on $n$.
    \begin{itemize}
    \itemsep0em
    \item Let $n=0$. In this case $\reaches n M$
    is the identity function.

    \item We assume the claim to hold for $n$, and
    prove it for $n+1$. For IH, $\reaches n M$
    is a function. Then, since
    $\vdash_{\delta}$ is a function,  $\reaches {n+1} M
    = \ \reaches n M \circ
    \vdash_{\delta}$ is a function, too.

    \end{itemize}
    \end{proof}
  \end{conditional}

  \begin{conditional}{\notappendix}

    Now, we would like to give a formal definition of the function computed
    by a Stream Machine. This will allow us to define $\SFP$ as the set of
    functions which can be
    computed by polynomial Stream Machines.
    %
    First, we build a notion of final configuration.

    %%% Notation
    \begin{notation}[Final Configuration]
      \label{notation:smfin}
    Given a stream machine $M:=\langle\Qs,\Sigma,
    \delta, q_0\rangle$
    and a configuration
    $\langle \sigma, q,\tau,\eta\rangle$,
    we write $\langle\sigma,q,\tau,\eta\rangle
    \not\vdash_{\delta}$ when there are no
    $\sigma',
    q',\tau',\eta'$ such that $\langle \sigma,q,\tau\eta\rangle
    \vdash_{\delta}\langle
    \sigma',q',\tau',\eta'\rangle$.
    \end{notation}

    This allows us to define the function computed by a Stream Machine.

    %%% DF
    %%% Value Computed by a Stream Machine
    \begin{defn}[Value Computed by a Stream Machine]
      \label{def:smval}
    Given a machine
    $M:=\langle \Qs,\Sigma,\delta,q_0\rangle$,
    $M$ computes $\gamma$ on input $\sigma$
    and oracle $\eta$ if and only if
    $$
    \exists n.\langle \eepsilon, q_0,\sigma, \eta\rangle
    \reaches n M
    \langle \gamma', q', \tau, \psi\rangle \not\vdash_{\delta}
    $$
    for some $\tau,q',\psi$ and $\gamma$ is the longet suffix
    without $\circledast$ of $\gamma'$.
    In that case, we write $M(\sigma,\eta)=\gamma$.
    \end{defn}

    This outlines a function $f_M: \Ss \times \Bool^\Nat \longrightarrow \Ss$
    for each Stream Machine $M$.

    %%% DF
    \begin{defn}[Polynomial Stream Machine]
      \label{def:sfpmachine}
    A \emph{Polynomial Stream Machine}
    is a Stream Machine $\MSFP :=
    \langle \Qs,\Sigma,\delta,q_0\rangle$
    such that,

    $$
    \exists p \in \POLY.\forall \sigma, \eta.
    \exists n\le p(|\sigma|).
    \langle \eepsilon, q_0,\sigma, \eta\rangle
    \reaches n {M_{\SFP}} \langle \gamma,
    q', \tau, \psi\rangle \not \vdash_{\delta}.
    $$
    % $$
    % \exists p \in \POLY.\forall \sigma, \eta,
    % n. \langle \eepsilon, q_0,\sigma, \eta\rangle
    % \reaches n {M_{\SFP}} \langle \gamma,
    % q', \tau, \psi\rangle \not\vdash_{\delta}
    % \rightarrow n \leq p(|\sigma|).
    % $$
    \end{defn}
    %
    %

    Before defining $\SFP$, we want to
    fix a class of Stream Machines in order to
    make the definition of $\SFP$ as solid as possible.

    \begin{defn}[Canonical Stream Machine]
      A Canonical Stream Machine is a stream machine in which:
      \begin{itemize}
        \item $\Sigma =\{\zzero, \oone\}$
        \item $L = \zzero, R = \oone$
      \end{itemize}
    \end{defn}


    Finally, we can define the set $\SFP$.

    \begin{defn}[$\SFP$]
      \label{def:sfp}
      %\small
      \[
      \SFP := \{ f \in \Ss \times \Bool^\Nat~|~ \text{There is a Polynomial Canonical Stream
      Machine $M$ such that }f=f_M\}
      \]
      \normalsize
    \end{defn}

    Because of the last definitions, later, we will abbreviate
    \emph{Polynomial Stream Machines} with ``$\SFP$ machines''.
    This because we have defined $\SFP$ as the set of
    functions computable by \emph{Polynomial Stream Machines}.

    We would like to stress out the fact that the definitions given so far
    deal with single-input
    single-tape machines only. This comes without a loss of generality:
    we could naturally extend our
    definitions to multi-input and multi-tape machines, in a similar way of how
    these extensions are defined for canonical Turing Machines.
    Moreover, in the following parts, we will use multi-tape Stream Machines for
    simplifying some proofs.

    Now, it is quite simple to outline a road-map which will allow us to prove
    Conjecture \ref{conj:taskc}.

    \begin{enumerate}
      \item Prove that each function in $\SFP$ can be computed by a function in $\POR$.
      \item Prove that each function in $\POR$ can be computed by a function in $\SFP$.
      \item Prove that $\SFP=\PPT$.
    \end{enumerate}


\begin{comment}
    \noindent
    The desired result can be now stated as:


    %%% LEMMA
    \begin{lemma}
    For every deterministic $\SFP$-machine,
    $M := \langle \Qs, \Sigma, \delta,q_0\rangle$,
    there exists a $\POR$-function $f$, such that:
    $$
    f(\sigma,\eta)= M.
    $$
    \end{lemma}
\end{comment}

  Before proceeding with the proofs of the results stated above, we'd like to
  point out some observations:

  \begin{enumerate}
    \item $\POR$ and $\SFP$ are two inherently different sets:
    \begin{align*}
      \POR \subseteq & \bigcup_{i \in \Nat} \Ss^i\times \{\zzero, \oone\}^\Ss \to \Ss\\
      \SFP \subseteq & \bigcup_{i \in \Nat} \Ss^i\times \{\zzero, \oone\}^\Nat \to \Ss
    \end{align*}
    \item Functions in $\SFP$ are determined by a polynomial prefix of their oracle,
    while a similar result seems is not true for $\POR$.
  \end{enumerate}

  These facts will require us some effort in the following encodings and will drive us
  to state results which are weaker than the ones we proved for $\Lpw$ and $\POR$.
  %
  For instance, when reducing $\SFP$ to $\POR$,
  a generic machine $M(x, \eta) \in \SFP$ can
  be simulated by a function $f_M(x, \omega) \in \POR$, which at each
  simulated transition queries a different coordinate of its oracle $\omega$,
  to emulate the value which $M$ reads on the $\eta$ tape.
  This drives to results which relate sets of oracle functions through their
  measure, instead of stating that they're the same set.

  But the correspondence between $\eta$ and $\omega$, even if intuitive, is not
  trivial under a technical perspective because of the necessity
  to link functions in $\Os$ to functions in $\Bool^\Nat$; this fact
  drove us to define some mathematical structures, called \emph{Reduction Trees},
  which helps us to prove the correctness of our encoding. \emph{Reduction Trees}
  keep track of all the possible sequences of coordinates used by a probabilistic
  function to query the oracle.


  This is in contrast with what happens when dealing with $\Sigma^b_1$ formul\ae{} in $\Lpw$
  and $\POR$ functions:  in that case we could state lemmas without any measure
  theoretic claim inside. This was due to the identity between the oracles
  passed as parameters to $\POR$ functions and the oracles in the semantics
  of a formula. For instance this allowed us to prove that:
%
  \[
  \forall G \in \Sigma^b_1. \exists f_G \in \POR. \big(\RS, \omega \vdash \forall x. \exists ! y. G(x, y) \land \omega \in \llbracket G(x, y) \rrbracket\big)  \leftrightarrow f_G(x, \omega) = y
  \]
%
  which itself entails that
%
  \[
  \forall G\in \Sigma^b_1. \exists f_G \in \POR.
  \forall x, y. \{\omega \in \Os | f_G(x, \omega)=y\} = \llbracket G(x, y)\rrbracket
  \]
%
  Obviously, a similar identity cannot be proved for $\POR$ and $\SFP$ because
  we defined them on top of different sets of oracle-functions.
  In order to fill this gap, we decided to show a weaker (but strong enough) result:
  the encodings between $\POR$ and $\SFP$ preserve the measure of the
  sets of oracles driving an input $x$ to an output $y$. Formally:
%
\begin{conj}
  \label{conj:SFP}
  \[
  \forall f\in \POR. \exists M_f \in \SFP.
  \forall x, y.\mu\big( \{\omega \in \Os | f(x, \omega)=y\} \big)=
  \mu \big(\{\eta \in \Bool^\Nat | M_f(x, \eta)=y\}\big)
  \]
  and conversely
  \[
  \forall M_f \in \SFP. \exists f\in \POR.
  \forall x, y.\mu \big(\{\eta \in \Bool^\Nat | M_f(x, \eta)=y\}\big)=
  \mu\big( \{\omega \in \Os | f(x, \omega)=y\} \big)
  \]
\end{conj}
%
  This outlines the necessity to define cylinders of oracle functions on top
  of which we will be able to define the notion of measure.

\subsubsection{Cylindes and Reduction Trees}

By definition, the result of a random function is determined
by its input, but also depends on the underlying randomness. In other words,
depending on the value of the oracle function on some specific coordinates,
the probabilistic function will drive to different outputs.

For this reason we need to introduce two important structures which capture this
phenomenon:

\begin{enumerate}
  \item Cylinder sets, tofor describe the oracles which drive a probabilistic
  function to compute the same output $y$ on input $x$.
  \item Reduction Trees, which describe the coordinates of the oracle which are useful
  to produce an input.
  %
  %and how the value of the oracle on these coordinates affects the final result.
\end{enumerate}

  \begin{defn}[Cylinder set]
    Given a set\footnote{  In the following part of our discussion we will be mostly interested in cylinders
      of $\Os$ and $\Bool^\Nat$. For this reason we will not specify whether we are considering
      cylinders of a set or the others, because it can be inferred by the argument of the function
}
    $\mathbb Q$ in the form $\Bool^A$, we define the positive
    cylinder associated to $\mathbb V$ on coordinate $x$ as:
    \[
      P(x) = \{ \psi \in \mathbb V | \psi(x)= \one \}
    \]
    similarly, we define the negative cylinders as:
    \[
      N(x) = \{ \psi \in \mathbb V | \psi(x)= \zero \}
    \]
  \end{defn}

  \begin{notation}[Generical cylinder set]
    From now on, given a set $\mathbb V$ and a $v \in \mathbb V$, we will write
    $C(v)$ to denote either a positive cylinder on $v$ or a negative cylinder on
    $v$
  \end{notation}

  \begin{defn}[Cylinders of a set]
    Let $\mathbb V$ be a set, we define $\mathit{Cyl}(\mathbb V)$ the set:
    $$
    \mathit{Cyl}(\mathbb V):=\{ X \in \mathcal P(\mathbb V)| \exists v \in \mathbb V.
    X = C(v)\}
    $$
  \end{defn}

  Intuitively $\mathit{Cyl}(\mathbb V)$ is the set of all the possible cylinders
  of $\mathbb V$.
  %
  Cylinders are an important ergodic notion, because they can be used to build a
  $\sigma$-algebra which, and then a measure space.

  \begin{defn}[$\sigma$-algebra $\mathcal C$, \cite{billingsley}]
    \label{def:cylsigmaalgebra}
    For $\Omega$ being $\Bool^\Nat$ or $\Bool^\Ss$,
    let: $\mathcal C_0$ be the set of all the countable intersections of cylineders
    of $\Omega$:
    $$
      \mathcal C_0 := \bigcup_{n \in \Nat}\bigcap_{0 \le i \le n} C(i)
    $$
    We call $\mathcal C$ is the smallest $\sigma$-algebra containing
    $\mathcal C_0$, i.e.:
    $$
      \mathcal C := \sigma(\mathcal C_0)
    $$
  \end{defn}

  Upon this $\sigma$-algebra, we can apply the natural contruction of a measure
  function, which is actually a probability function, too.

  \begin{defn}[Measure on $\mathcal C$, \cite{mqpa}]
    For $\Omega$ being $\Bool^\Nat$ or $\Bool^\Ss$,
    We define $\mu$ as the smallest probability function (see \cite{billingsley})
    for the $\sigma$-algebra
    $\mathcal C$ such that:
    $$
    \forall i \in \Nat.\mu(C(i))=\frac 1 2
    $$
  \end{defn}





  \begin{defn}[Reduction Tree]
    An \rt A is a production of the following grammar:
    \[
    \mathit{Tree}::= \mathit T\ a\ (\mathit{Tree})\ (\mathit{Tree})\ |\ \mathit{nil}
    \]
    with $a \in A$.
  \end{defn}

  For deterministic paradigms, reduction trees are degenerate, because
  they consist in empty trees, but when dealing with probabilistic paradigms, they
  acquire significance because it's possible to associate one of these structures
  to any functions ad any input.

  \begin{example}
    If we take in exam the
    $\POR$ function $f(x, \omega) = Q(Q(x, \omega), \omega)$,
    we intuitively build the reduction tree associated to such function for any
    possible input, for instance, take as input $\one\zero\one$.
    The function will use that vale as coordinate for querying the inner $Q$
    function, later, that value will be used as a coordinate for querying the
    outer $Q$, so the root will have two child nodes: one labeled with $\zzero$
    and the other labeled with $\oone$. Such tree
    is represented in Figure \ref{fig:samplert}.
  \end{example}

  \begin{figure}[]
    \begin{tikzpicture}[node distance=2cm]
        \node (a) {$\one\zero\one$};
        \node[below left = 15mm and 22.5mm of a] (b) {$\zzero$};
        \node[below right = 15mm and 22.5mm of a] (c) {$\oone$};

        % \node[below left = 15mm of b] (d) {$\zero$};
        % \node[below right = 15mm of b] (e) {$\one$};
        %
        % \node[below left = 2 cm of c] (f) {$\zero$};
        % \node[below right = 2 cm of c] (g) {$\one$};


        \draw[->] (a) edge (b);
        \draw[->] (a) edge (c);

        % \draw[->] (b) edge (d);
        % \draw[->] (b) edge (e);
        %
        % \draw[->] (c) edge (f);
        % \draw[->] (c) edge (g);

    \end{tikzpicture}
    \caption{\rt {\Ss} associated to $f(x, \omega) = Q(Q(\one\zero\one, \omega), \omega)$}
    \label{fig:samplert}
  \end{figure}

  We can associate a sequence of cylinder sets to each path from the root
  of a reduction tree to one of its leafs. The intersection of such set is exactly
  the set of oracles which drive the function to produce the value on the leaf.
  We can state define these sequence of cylinders by induction:

  \begin{defn}[Cylinder Paths of a Reduction Tree]
    Given a \rt {A} $t$, we define the set of cylinder paths as follows:
    \begin{align*}
      \mathit{cylp}(L) &:= \{\varepsilon\}\\
      \mathit{cylp}(T\ a\ t_0\ t_2) &:= \{N(a),t~ |~ t \in \mathit{cylp}(t_0)\} \cup \{P(a),t ~|~ t \in \mathit{cylp}(t_1)\}
    \end{align*}
  \end{defn}

  \begin{defn}[Reduction Tree associated to a function]
    \label{def:rtasfun}
    We say that a \rt {A} $t$ is associated to a function
    $f: B^n\times (\{\zzero, \oone\}^A)\longrightarrow C$ and
    input $\vec x \in B^n$ if and only if
    $C(a^{\vec x}_0), \ldots,  C(a^{\vec x}_n) \in \mathit{cylp}(t)$
    and $f(\vec x,\bigcap_{i=0}^n C(a^{\vec x}_i))$ is a singleton.
    If it is the case, we write $t \in \RT A f {\vec x}$.
  \end{defn}

  \begin{notation}{(Abuse)}
    When talking about Reduction Trees associated to $\POR$ and to $\SFP$
    functions, sometimes we will write $t \in \RT \POR f x$ and
    $t \in \RT \SFP M x$ respectively to enforce the fact that those trees are
    neither generic \rt \Ss\  nor \rt \Nat\, but they are
    related to a specific class of functions. Concisely: $t \in \RT \SFP f x$
    is a synonym for $t \in \RT \Nat f x \land f \in \SFP$, similarly for $\POR$.
  \end{notation}


  From Definition \ref{def:rtasfun} we can instantiate the notion of Reduction Tree
  associated to a $\POR$ function and to a $\SFP$ function, but before
  we need to define when two Reduction Trees are structurally identical
  Reduction Trees.

  \begin{defn}[Structurally Identical Reduction Trees]
    For each pair of Reduction Trees $t_1 \in \RT A {x_1}$ and $t_2 \in \RT B {x_2}$,
    we define the relation of being Structurally Identical $\SI$
    as the smallest relation closed under the following
    rules:
    \begin{itemize}
      \item $\mathit{nil}\ \SI\ \mathit{nil}$
      \item $\left(\mathit{Tree}\ z_1\ t_1^L\ t_1^R\right)\ \SI\ \left(\mathit{Tree}\ z_2\ t_2^L\ t_2^R\right)$
      if and only if $t_1^L\ \SI\ t_2^L$ and $t_1^R\ \SI\ t_2^R$.
    \end{itemize}
  \end{defn}


  % \begin{defn}[Reduction Tree associated to a $\POR$ function]
  %   We say that a \rt \Ss\  $t$ is associated to a function $f \in \POR$ and
  %   input $x$ if and only if $\mathit{cylp}(t)= C(s^x_0), \ldots,  C(s^x_n)$
  %   and $f(x,\bigcap_{i=0}^n C(s^x_i))$ is a singleton. If it is the case, we write
  %   $t \in \RT\POR f x$.
  % \end{defn}
  %
  %
  % Similarly, we can define the notion of reduction Tree associated to a $\POR$
  % function:
  %
  % \begin{defn}[Reduction Tree associated to a $\SFP$ function]
  %   We say that a \rt \Nat\ $t$ is associated to a $\SFP$ function $M$ and
  %   input $x$ if and only if $\mathit{cylp}(t)= C(s^x_0), \ldots,  C(s^x_n)$
  %   and $M(x,\bigcap_{i=0}^n C(s^x_i))=$ is a singleton. In this case we write
  %   $t \in \RT\SFP M x$.
  % \end{defn}

  Finally, these definitions allow us to state the notion of implementability
  modulo random choices and the statement which we will prove
  in the following section:

\begin{restatable}{prop}{PORimplSFP}
  \label{prop:PORimplSFP}
  For every $M: \Ss \times \Bool^\Nat \in \SFP$ there exists a $f_M \in \POR$ such that
  for every $x \in \Ss$ there exists a Reduction Tree $t \in \RT{\SFP} M x$ and a
  Reduction Tree $\overline t \in \RT{\POR} {f_M} {x}$ such that $\overline t$
  is structurally identical to $t$ and for every path $C$ in $\mathit{cylp}(t)$,
  the corresponding path $D$ in $\mathit{cylp}(\overline t)$ is such that
  $M(x, C) = f_M(x, D) = \{\tau\}$ for some $\tau\in \Ss$.
\end{restatable}

  Instead, the backward reduction is divided in four subreductions, but only one
  of those uses Reduction Trees explicitly, all the others prove stronger results.


  Reduction Trees have been introduced to capture the measure of the set of
  oracle functions $\psi$ which drive a certain function, together with its
  inputs to produce a certain output. For this reason, they are almost
  useless without a notion of measure of an output value with
  respect to a tree, a function and an input.
  %
  Fortunately, given a function
  $f: B^n\times (\{\zzero, \oone\}^A)\longrightarrow C$
  and, Reduction Tree $t \in \RT{A} {f} {\vec x}$ there is a quite
  natural way to associate a measure to each possible input.

  \begin{defn}
    For each $f: B^n\times (\{\zzero, \oone\}^A)\longrightarrow C$
    and for each Reduction Tree $t \in \RT{A} {f} {\vec x}$, we define
    the measure of an output with respect to a Reduction Tree and an input
    $y \in C$ as follows:
    \[
      q(f, \vec x, y, t) := \sum_{S \in W(f, x, y, t)}\mu(\bigcap_{c \in S} c)
    \]
    where
    \[
    W (f, x, y, t) \coloneqq \{C(a_1), \ldots, C(a_m) \in \mathit{cylp}(t)|
    f(\vec x, \bigcap_i C(a_i))=\{y\}\}
    \]
  \end{defn}

  Lastly, we have to show that the measure $q(f, \vec x, y, t)$
  which we have introduced is not an
  arbitrary value, but is equal to the measure of the
  set of functions which drive
  $f$ to output $y$ on input $\vec x$.

  \begin{lemma}
    \label{lemma:treetomeasure}
    For each function $f: B^n\times (\{\zzero, \oone\}^A)\longrightarrow C$
    and for each Reduction Tree $t \in \RT{A} {f} {\vec x}$, for each
    $\vec x \in B^n$,
    $\mu(\{\psi \in \{\zzero, \oone\}^A | f(\vec x, \psi)=y\})= q(f, \vec x, y, t)$
  \end{lemma}

  \begin{proof}
    The claim comes from two observations:
    \begin{enumerate}
      \item $\forall \overline t.
      \forall S_1, S_2 \in \mathit{cylp}(\overline t).
      S_1 \neq S_2 \to \left( \bigcap_{s \in S_1} s\right) \cap
      \left( \bigcap_{s \in S_2} s\right)= \emptyset$.
      \item $\forall \overline t \in \RT{A} {f} {\vec x}.\forall \psi \in \{\zzero, \oone\}^A.
       \exists S \in \mathit{cylp}(\overline t). \psi \in \bigcap_{s \in S} s$.
    \end{enumerate}
    The first conclusion can be obtained by induction on the definition of $\overline t$:
    for $\mathit{nil}$ the conclusion is trivial since
    $\mathit{cylp}(\mathit{nil})=\{\varepsilon\}$,
    while for the inductive case, it comes from the induction hypothesis
    and the fact that we append disjoint sets (complementary cylinders)
    to the sequences.
    The second conclusion comes from induction on $\overline t$ too:
    suppose $\overline t=\mathit{nil}$: the intersection of no cylinders is
    $\{\zzero, \oone\}^A$, so the conclusion is trivial.
    The induction hypothesis comes from the fact that for a node
    $T\ a\ t_1\ t_2$ it's always true that $\psi \in P(a) \lor \psi \in N(a)$.
    By cases on this premise: if $\psi \in P(a)$, then we conclude that
    $\psi \in \left(\bigcap_{C \in t_1} C \right)\cap P(a)$, analogously for
    the other case.
    These results allow us to write:
    \begin{align*}
      q(f, \vec x, y, t) = \mu\left(\bigcup_{S \in W(f, x, y, t)}\bigcap_{c \in S} c\right)=\mu\left(\{\psi \in \{\zzero, \oone\}^A | f(\vec x, \psi)=y\}\right)
    \end{align*}


  \end{proof}









\end{conditional}










%%% SUBSUBSECTION
%%% Proving the Lemma
\subsection{From $\SFP$ to $\POR$ functions}
\label{sec:SFPtoPOR}


\begin{conditional}{\notappendix}
  Suppose that we want to implement $\SFP$ in $\POR$
  %on a formalism $B \subseteq\Ss^k \times \Os \longrightarrow \Ss$
  %\footnote{Ideally, such formalism is $\POR$}.
  %For doing so,  it suffices to show that there exists a set of funcions $K_\SFP$ (along with their specifications) for which $K_\SFP \subseteq B$ entails Proposition \ref{prop:PORimplSFP}.
  %that $\SFP$ can be implemented in $B$.
  %
  %
  %Ideally, our notion of \emph{being implementable} can be thought as a belonging relation, but unfortunately, this is not the case because the superset of $B$, i.e. $\Ss^k \times \Os \longrightarrow \Ss$ and the superset of $\SFP$ i.e. $\Ss^k \times \{\zzero, \oone\}^\Nat \longrightarrow \Ss$ are disjoint.
  %
  %For this reason, when we say \emph{being implementable} we mean  something similar to what we stated in Proposition \ref{prop:SFPimplPOR}.  Namely, that the implementation of $\SFP$ in $B$ preserves the measure of  the set of oracle functions causing a starting function $M \in \SFP$ and  its corresponding function $f_M \in B$ to compute the same output n the same input(s).
  %
  %
  The first issue we find is that
  the definition of $\SFP$ is not grounded on an evident inductive basis, so
  it would be difficult to prove such result directly.
  For this reason we need to find an alternative
  claim. Definition \ref{def:smval} states that the value computed by a
  Stream Machine is defined by means of the transitive closure of the machine's
  transition function which, itself, is defined by induction.
  %
  For this reason we need to extrapolate the reachability function from the
  definition of $\SFP$ function. As we will show, this will drive
  to a statement which is
  stronger than Proposition \ref{prop:PORimplSFP} but easier to prove.

  For these reasons, we will structure the proof of Proposition \ref{prop:PORimplSFP}
  as follows:

  \begin{itemize}
    \item We will do some work on the definition of $\SFP$ to extract an \emph{inductive}
    claim which entails Proposition \ref{prop:PORimplSFP}, namely Proposition
    \ref{prop:PORimplreach}.
    \item We will identify the set of functions $K_\SFP$, such that
    $K_\SFP \subseteq \POR$ entails Proposition \ref{prop:PORimplreach}.
%    \item We will state the notion of lossy probabilitic implementability    and prove that $\SFP$ is lossly probabilitic implementable in each $B$ such that    $K_\SFP \subseteq B$.
    \item We will prove that $K_\SFP \subseteq \POR$.
    \item We will prove that Proposition \ref{prop:PORimplreach} holds.
    \item We will prove Proposition \ref{prop:PORimplSFP} as a corollary of Proposition \ref{prop:PORimplreach}.
  \end{itemize}

  \subsubsection{The induction behind $\SFP$}
  \label{subsub:iductivesfp}

  As we stated above, the definition of $\SFP$ is intrinsically inductive, but
  this is hidden by some layers of definitions which hide this fact.

  We also anticipated that the inductive element of the $\SFP$ functions is the
  transitive closure of the Stream Machine's transition function. For this reason,
  in order to accomplish our goal we could find a characterization of $\SFP$
  function which relies \emph{directly} on the transitive closure of a function.

  The first obstacle is the fact that the Machine's transition function may be
  undefined on some values, to solve this issue, we can give an alternate definition
  of the Machine's transition function.

  %%% DF
  %%% Stream Machine Reachability Function
  \begin{defn}[Stream Machine Total Transition Function]
    \label{def:smtotaltransfun}
  Given a stream machine $M=\langle \Qs,
  \Sigma, \delta, q\rangle$,
  we define the \emph{total} transition function
  $\vdash_{\delta} \Sigmab^* \times \Qs
  \times \Sigmab^* \times \{\zzero,
  \oone\}^{\Nat} \longrightarrow \Sigmab^*
  \times \Qs \times \Sigmab^* \times \{\zzero,
  \oone\}^{\Nat}$
  between two configurations of $M_S$ as:
  %
  \begin{align*}
  \vdash_{\delta}'(\langle \sigma, q, \tau, \eta\rangle):= \begin{cases}
    \langle \sigma, q, \tau, \eta\rangle & \text{if } \langle \sigma, q, \tau, \eta\rangle \not \vdash_{\delta}\\
    \vdash_{\delta}(\langle \sigma, q, \tau, \eta\rangle) & \text{otherwise}
  \end{cases}
  \end{align*}
  \end{defn}

  Thanks to this definition, we can lift $\vdash_{\delta}'$ to a family of
  total reachability functions:

  \begin{defn}[Stream Machine Total Reachability Functions]
    \label{def:smtotalreachfuns}
  Given a stream machine $M:=\langle \Qs,
  \Sigma, \delta, q_0\rangle$,
  we denote with $\{{\reachesf {n} {\delta}}\}_n$
  the smallest family of relations
  for which:
  \begin{align*}
  \langle \sigma, q, \tau, \eta \rangle
  &{\reachesf {0} {\delta}}
  \langle \sigma, q, \tau, \eta\rangle \\
  %
  \big(\langle \sigma, q, \tau, \eta\rangle
  {\reachesf {n} {\delta}} \langle \sigma',
  q', \tau',\eta'\rangle
  \wedge \langle \sigma', q',
  \tau', \eta'\rangle
  &\vdash_{\delta}'
  \langle \sigma'', q', \tau'',
  \eta'' \rangle \big)\rightarrow\big(
  \langle \sigma,q,\tau, \eta\rangle
  {\reachesf {n} {\delta}}\langle
  \sigma'', q'\tau'',\eta''\rangle\big)
  \end{align*}
  \end{defn}

  This outlines an alternative characterization of $\SFP$, which is the following.

  \begin{characterization}[$\SFP$ function]
    \label{char:sfp}
    A function $M$ is in $\SFP$ if and only if:
    \begin{itemize}
      \item There exist a transition function $\delta$ and an initial state $q$
      \item There exists a polynomial $p$.
    \end{itemize}
    Such that
    \[
    \forall \sigma, \eta. \forall k \in \Nat. \langle \sigma,q,\tau, \eta\rangle {\reachesf {p(|\sigma|)} {\delta}} \langle \sigma',q',\tau', \eta'\rangle {\reachesf {k} {\delta}} \langle \sigma',q',\tau', \eta'\rangle\land \sigma''=M(\sigma, \eta)
    \]
    Where $\sigma''$ is the longest sufix of $\sigma'$ without $\circledast$.
  \end{characterization}
  \begin{proof}
    The direction from left to right is trivial, it suffices to use as $\delta$
    the transition function of the machine used for the definition of $M$
    and $q$ its initial state such objects exist according to Definitions
    \ref{def:sfpmachine}, \ref{def:sfp} and \ref{def:sm}.
    The polynomial $p$ is the time bound of $M$ which
    exists according to Definition \ref{def:sfpmachine}.

    The entailment from right to left holds because our characterization
    ensures that the $\reachesf \delta n$ is stationary after a polynomial number of steps,
    thanks to this fact we can build a $\delta'$ function which is obtained
    from $\delta$ pruning the self-loops between states.
    $\delta'$ and $q$ allow us to synthesize a Stream machine $M'$ which is in
    $\SFP$ for Definitions \ref{def:sfpmachine}, \ref{def:sfp} and \ref{def:sm}.
  \end{proof}

  Characterization \ref{char:sfp} outlines a possible proof of
  Proposition \ref{prop:PORimplSFP}.
  Indeed, we can state a proposition which is very similar
  to Proposition \ref{prop:PORimplSFP}, but dealing with $\reachesf {}{}$ instead of
  the definition of $\SFP$. Then according to Characterization \ref{char:sfp},
  Proposition \ref{prop:PORimplSFP} will be a consequence of that result.
  Moreover we are not directly interested in the whole configuration: in $\POR$
  we already have access to an oracle $\omega$ as source of randomness and there
  is no way to represent such function within a finite term, so
  we can bound our statement to ste configuration of the tape and the
  current state only. To do so, we define $\reachesw$ as follows:

  \begin{defn}
    Define $\reachesw^n_\delta$ as follows:
    \[
      \reachesw^n_\delta(\sigma, q, \tau, \eta):= \langle
      \pi_1(\reachesf n \delta(\langle \sigma, q, \tau, \eta\rangle)),
      \pi_2(\reachesf n \delta(\langle \sigma, q, \tau, \eta\rangle)),
      \pi_3(\reachesf n \delta(\langle \sigma, q, \tau, \eta\rangle))\rangle
    \]
  \end{defn}
  At this point,
  we need to prove the following proposition.

  \begin{prop}
    \label{prop:PORimplreach}
    There exist a surjective function
    $\alpha :\Ss \longrightarrow \Sigmab^* \times \Qs \times \Sigmab^*$,
    an injection $\beta :\Qs \longrightarrow \Ss$,
    an injection $\gamma: \Nat \longrightarrow \Ss$ such that
    for every $\delta: \Qs \times \Sigmab \times \{\zzero, \oone\} \longrightarrow \Qs \times \Sigmab \times \{L,R\}$
    %for every $\SFP$ machine $M:=\langle \Qs,\Sigma, \delta,q_0\rangle$ there is
    there is a function $f_\delta \in \POR$ such that
    %
    for every $n \in \Nat$,  $\sigma \in \Ss, q \in \Qs$ there are
    two Reduction Trees
    $t \in \RT{\Nat}{ \reachesw^n_\delta}{\sigma, q, \tau}$ and
    $\overline t \in \RT{\POR} {f_\delta} {\gamma(n),\sigma, \beta(q), \tau}$
    such that $\overline t$ is structurally identical to $t$ and
    for every path $C$ in $\mathit{cylp}(t)$,
    the corresponding path $D$ in $\mathit{cylp}(\overline t)$ is such that
    $\pi_i(\reachesw^n_\delta(\langle \sigma, q, \tau, C\rangle)) = \alpha
    (f_\delta(\gamma (n),\sigma, \beta(q), \tau, D))$.
  \end{prop}

  % \begin{prop}
  %   \label{prop:PORimplreach}
  %   Define $\reachesw$ as follows:
  %   \[
  %     \reachesw^n_\delta(\sigma, q, \tau, \eta):= \langle
  %     \pi_1(\reachesf n \delta(\langle \sigma, q, \tau, \eta\rangle)),
  %     \pi_2(\reachesf n \delta(\langle \sigma, q, \tau, \eta\rangle)),
  %     \pi_3(\reachesf n \delta(\langle \sigma, q, \tau, \eta\rangle))\rangle
  %   \]
  %   There exist a surjective function
  %   $\alpha :\Ss \longrightarrow \Sigmab^* \times \Qs \times \Sigmab^*$,
  %   an injection $\beta :\Qs \longrightarrow \Ss$,
  %   an injection $\gamma: \Nat \longrightarrow \Ss$ such that
  %   for every $\delta: \Qs \times \Sigmab \times \{\zzero, \oone\} \longrightarrow \Qs \times \Sigmab \times \{L,R\}$
  %   %for every $\SFP$ machine $M:=\langle \Qs,\Sigma, \delta,q_0\rangle$ there is
  %   there is a function $f_\delta \in \POR$ such that
  %   %
  %   for every $n \in \Nat$,  $\sigma \in \Ss, q \in \Qs$ , there are
  %   two Reduction Trees
  %   $t \in \RT{\Nat}{ \lambda \sigma, q, \tau, \eta. \reachesf n \delta
  %   (\langle \sigma, q, \tau, \eta\rangle)}{\sigma, q, \tau}$ and
  %   $\overline t \in \RT{\POR} {f_\delta} {\gamma(n),\sigma, \beta(q), \tau}$
  %   such that $\overline t$ is structurally identical to $t$ and
  %   for every path $C$ in $\mathit{cylp}(t)$,
  %   the corresponding path $D$ in $\mathit{cylp}(\overline t)$ is such that
  %   $\pi_i(\reachesf n \delta(\langle \sigma, q, \tau, C\rangle)) = \pi_i(\alpha
  %   (f_\delta(\gamma (n),\sigma, \beta(q), \tau, D)))$ for $i \in\{1,2,3\}$.
  % \end{prop}

  Now, it should not be difficult to see that Proposition \ref{prop:PORimplreach}
  entails Proposition \ref{prop:PORimplSFP}:
  if we instantiate $n$ with $p(|\sigma|)$, $\tau$ with
  the empty string and $q$ with the initial state, the claim is exactly
%
  \begin{equation}
    \label{eq:1}
%    \pi_i(\reachesf {p(|\sigma|)} \delta(\langle \sigma, q_0, \eepsilon, C\rangle)) =
    \reachesw^{p(|\sigma|)}_\delta(\langle \sigma, q_0, \eepsilon, C\rangle) =
    \alpha(f_\delta(\gamma (p(|\sigma|)),\sigma, \beta(q_0), \eepsilon, D))
  \end{equation}

  Due to Characterization \ref{char:sfp}, and supposing that we are able to show that
  there is some function $\phi \in \POR$ such that \eqref{eq:2} below holds,
  the claim \eqref{eq:1} entails Proposition \ref{prop:PORimplSFP}.
%
  \begin{equation}
    \label{eq:2}
    \pi_1(\alpha(f_\delta(\gamma (p(|\sigma|),\sigma, \beta(q_0), \eepsilon, D)))= \phi(f_\delta(\gamma (p(|\sigma|)),\sigma, \beta(q_0), \eepsilon, D))
  \end{equation}

  This should not be too much of a problem, since it basically requires to
  extract some values from the encoding of a tuple, which is the result of $f_\delta$.


  Moreover, we have made the inductive ground of a Stream Machine explicit, reducing it
  to the inductive family of functions $\reachesw n \delta$, so we can leverage
  this fact to produce an inductive proof of Proposition \ref{prop:PORimplreach}.

  The statement of Proposition \ref{prop:PORimplreach} uses
  some encodings: namely $\beta$ and $\gamma$, which
  map respectively natural numbers and states to binary strings.
  Similarly, the function $\alpha$ is a decoding from $\Ss$ to triples.
  For this reason
  we deduce that we need to define the encodings of some
  data and collections in $\POR$.
  %
  Another encoding which we will introduce is
  $\delta$'s. Indeed, we expect to define all the functions $f_\delta$ with a common
  schema, which varies on $\delta$'s encoding, such data will be used by the function
  to simulate the machine's transition and to emulate $\reachesf{\cdot}{\delta}$.
  Finally, we observe that we can reduce the encoding $\gamma$ in Proposition
  \ref{prop:PORimplreach} to $\beta$: as a consequence of
  Definition \ref{def:sm}, we can suppose $\Qs \subseteq \Nat$, because a machine's
  states are indexed with natural numbers.















  \subsubsection{Some encodings}
  \label{subsub:encodings}

  Proposition \ref{prop:PORimplreach} outlines some information about how we can
  implement $\SFP$ in $\POR$. For example, we already observed that we need encodings
  for tuples, and natural numbers. But, since the $f_\delta$ function
  described in Proposition \ref{prop:PORimplreach} takes choices
  depending on the value of $\delta$, we an also expect that we will need an
  encoding for Boolean values, to implement control structure, too.

  Before getting into more complex encondings, we start with a toy problem:
  the encoding of the constant strings. We did not mention such values before,
  but we need them, to write some form
  of values directly into $\POR$ function.
  It is not strictly necessary
  to show that there's a $\POR$ function for all the constant strings,
  but it will be useful to
  introduce the same pattern which we will follow later for the definition of more
  complex encodings.

  \begin{defn}[Encoding of Constants]
    We define the injection $\ovverline \cdot \Ss:  \Ss \longrightarrow \Ss$ as
    follows:
    \[
    \ovverline \sigma \Ss:= \sigma
    \]
  \end{defn}

  Now we should show that this encoding is suitable for $\POR$,
  which means that when we will insert a constant inside the definition of a
  $\POR$ function, it preserves the fact that the overall function is in $\POR$.
  If we show that for each constant there is a functions in
  $\POR$ which compute it,
  then the composition of $\POR$ functions with strings
  is in $\POR$ for compositionality.

  \begin{remark}[Representability of $\Ss$ in $\POR$]
    $\forall \sigma \in \Ss. \exists f_\sigma \in \POR. \forall x, \omega.
    f_\sigma(x, \omega)= \ovverline \sigma \Ss$
  \end{remark}
  \begin{proof}
    Take as $f_\sigma$:
    \begin{align*}
      {f_{\eepsilon}}(x, \omega) &:= E(x, \omega) \\
      {f_{\tau\bbool}}(x, \omega)&:= \Sf_\bbool(f_\tau(x, \omega),\omega)
    \end{align*}
    The claim can be obtained by induction on $\sigma$.
  \end{proof}


  We choose to represent the natural number $n$ as a string composed by $n+1$
  $\oone$s
  \footnote{We took this decision because we do not want $\eepsilon$ to be neither
  the encoding of a natural number nor of any other value (indexes, Booleans, tuples, ...).
  This will allow us to use it as return value in case of errors, if necessary.},
  in this way, definitions of arithmetical functions will be simpler.

  \begin{defn}[Encoding of Natural numbers]
    We define the injection $\ovverline \cdot \Nat:  \Nat \longrightarrow \Ss$ as
    follows:
    \[
    \ovverline n \Nat:= \oone^{n+1}
    \]
  \end{defn}

  This encoding is suitable for $\POR$, because we can show that each string
  which is the encoding of a natural number can be represented by a term in $\POR$,
  formally:

  \begin{remark}[Representability of $\Nat$ in $\POR$]
    $\forall n \in \Nat. \exists f_n \in \POR. \forall x, \omega.
    f_n(x, \omega)= \ovverline n \Nat$
  \end{remark}
  \begin{proof}
    Take as $f_n$:
    \begin{align*}
      {f_0}(x, \omega) &:= \Sf_\oone(E(x, \omega),\omega) \\
      {f_{n+1}}(x, \omega)&:= \Sf_\oone(f_n(x, \omega),\omega)
    \end{align*}
    The claim can be obtained by induction on $n$.
  \end{proof}

  Conventionally, the true Boolean value is always represented with $\oone$ and
  the false value is represented with $\zzero$.
  We will follow this convention.

  \begin{defn}[Encoding of Boolean values]
    We define the injection $\ovverline \cdot \Bool:  \Bool \longrightarrow \Ss$
    as follows:
    \begin{align*}
      \ovverline \zzero \Bool &:= \zzero\\
      \ovverline \oone \Bool &:= \oone
    \end{align*}
  \end{defn}

  \begin{remark}[Representability of $\Bool$ in $\POR$]
    $\forall \bbool \in \Bool. \exists f_\bbool \in \POR. \forall x, \omega.
    f_\bbool(x, \omega)= \ovverline n \Bool$
  \end{remark}
  \begin{proof}
    Take as $f_n$:
    \begin{align*}
      {f_{\zzero}}(x, \omega)&:= \Sf_\zzero(E(x, \omega),\omega)\\
      {f_\oone}(x, \omega) &:= \Sf_\oone(E(x, \omega),\omega)
    \end{align*}
    The claim is correct by definition of the functions $f_\zzero$ and $f_\oone$.
  \end{proof}

  As we have shown, we need to represent some complex data structures: we argued
  that the function $f_\delta$ presented in Proposition \ref{prop:PORimplreach}
  should depend on some encoding of the \emph{finite} function $\delta$ and that
  its output will be the encoding of a tuple with at least three elements.

  For sake of simplicity, we will represent all these different data structures
  as untyped lists. This works because lists are a generalization of sets,
  tuples and thus of functions, too.
\linebreak


  \paragraph{\emph{Lists}}


  In order to represent lists, we will adapt an encoding
  from~\cite[p. 183]{Odifreddi} which was introduced as a representation of tuples.

  Before doing so, we would like to formally define the set of lists, in order
  to clarify which kind of data we will be working on.

  \begin{defn}[Lists of strings]
    \label{def:enclists}
    We say that $l$ is a list of strings if and only if $l \in \Lists$, where
    $\Lists := \bigcup_{i\in \Nat} \Ss^i$.
  \end{defn}

  Before presenting the encoding, we need to introduce two auxiliary functions,
  the \emph{doubling} function $\Df$ and the \emph{halving} function $\Hf$,
  such epithets are due to the fact that they respectively double and halve the length
  of their input. $\Df$ interleaves the bits in its input with $\oone$s and $\Hf$
  removes those characters.

  $\Df$ can be seen as the mapping of a string $\sigma$ through an
  encoding $\Bool \longrightarrow \Bool^2$, and $\Hf$ as
  its left inverse. In this way we can represent lists as sequences of characters
  $c \in \Bool^2$. Two of those four characters are used to encode the
  values in $\Bool$ which compose the strings in the list, while
  one of the two remaining characters (we chose $\zzero\zzero$) is used
  as separator. In this way we will be able to embed multiple strings in a single
  sequence of bits encoding a lists and to extract the original values.

  \begin{defn}[Encoding and Decoding Functions]
    \label{def:df}
  Encoding and decoding functions
  are defined as follows:
  \begin{align*}
  \Df(\sigma\zzero) &:= \Df(\sigma)\oone\zzero \\
  %
  \Df(\sigma\oone) &:= \Df(\sigma)\oone\oone \\
  \\
  %
  \Hf(\sigma\oone\zzero) \ &{:=} \
  \Hf(\sigma)\zzero \\
  %
  \Hf(\sigma\oone\oone) \ &{:=} \ \Hf(\sigma)\oone.
  \end{align*}
  \end{defn}
  %
  %
  \noindent

  We can finally define the encoding
  of lists.


  %% defn
  %% Tuple Constructors
  \begin{defn}[List Encoding]
  The family of List encoding injections
  $\listenc {\cdot, \ldots, \cdot}{n}: \Ss^n \longrightarrow \Ss$
  is defined
  as the family of functions described below:
  $$
  \listenc {\cdot, \ldots, \cdot}{n}
  := {\zzero\zzero \Df (x_n)
  \zzero\zzero
  \dots \zzero \zzero \Df(x_1) \zzero\zzero
  \Df(x_0)\zzero\zzero\Df(\ovverline{n}\Nat)
  \zzero\zzero}
  $$
  \end{defn}
  %
  %
  Following the pattern which we used for the previous encodings we should show
  that all the values which encode tuples can be represented by functions in
  $\POR$. To do so, we need to show that $\Df$ and $\Hf$ are in $\POR$, together
  with the function which computes the concatenation, too.

  \begin{defn}[String Concatenation function]
    \label{def:concat}
    \begin{align*}
      \concat(x, \eepsilon, \omega) &:= x\\
      \concat(x, y\bbool, \omega) &:= \Sf_\bbool(\concat(x, y, \omega), \omega)|_{xy}
    \end{align*}
  \end{defn}

  \begin{lemma}[String concatenation is in $\POR$]
    Formally: $\concat \in \POR\land \forall x_1, x_2, \omega. \concat(x_1, x_2, \omega)=x_1x_2$
  \end{lemma}
  \begin{proof}
    Such function can is defined by bounded recursion, the result can be proven
    by induction on $x_2$.
  \end{proof}

  \begin{lemma}[$\Df$ is in $\POR$]
    \label{lemma:dfinpor}
    $\Df$ is in $\POR$.
  \end{lemma}
  \begin{proof}

    It can be shown that the
    {doubling function,
    $\Df$,} is a $\POR$ function, because it can be defined by bounded recursion:
    \begin{align*}
    \Df(\eepsilon,\omega) &:= \eepsilon \\
    %
    \Df(y\oone,\omega) &:=
    {\Sf_\oone(\Sf_\oone(\Df(y,\omega),
    \omega))}|_{(\oone\oone)\times (y\oone)} \\
    %
    \Df(y\zzero,\omega) &:=
    {\Sf_\zzero(\Sf_\oone
    (\Df(y,\omega),\omega))}|_{(\oone\oone)\times
    (y\oone)}.
    \end{align*}
  \end{proof}

  \begin{remark}
    \label{rem:listrepr}
    All the constant lists can be represented by functions in $\POR$. Namely:
    $\forall l \in \Lists. \exists f_l \in \POR. \forall x, \omega.
    f_l(x, \omega) = \listenc l {|l|}$.
  \end{remark}
  \begin{proof}
    This comes form the fact that $\listenc l n$ can be defined by composition
    of functions which are in $\POR$, namely:
    of constant functions (e.g. $f_{\zzero\zzero}$),  $\concat$, $f_n$, $D_f$.
  \end{proof}

  We can also state representability results dealing with
  functions and sets, instead of lists. We will not state a similar result for tuples directly
  because, according to Definition \ref{def:enclists}, tuples are \emph{exactly}
  specific cases of lists.
  %
  Concerning sets and functions, basically we can represents sets as specific
  lists with at most
  one copy per element, and finite functions from $\Ss$ to $\Ss$ (but not only)
  with their graph: using lists as particular cases of couples and sets.
  %
  \begin{defn}[Finite Set Encoding]
    \label{def:setenc}
  The family of Set encoding injections
  $\ovverline \cdot {\mathcal P_\mathit{fin}(\Ss)}:   \mathcal P_\mathit{fin}(\Ss) \longrightarrow \Ss$
  is defined as the family of function described below:
  $$
  \ovverline {\{x_1,\ldots, x_n\}} {\mathcal P_\mathit{fin}(\Ss)}
  := \listenc {x_1,\ldots, x_n} {n}
  $$
  Where $x_1, \ldots, x_n$ are taken in ascending order accordig to the value
  of the natural number encoded by $\oone x_i$. This definition il well-founded
  becasue sets do not contain repetitions.
  \end{defn}

  \begin{defn}[Function Encoding]
    \label{def:funenc}
  The family of Finite Function Encoding injections
  $\ovverline \cdot {\Ss^\Ss}: \Ss^\Ss \longrightarrow \Ss$
  is defined as the family of function described below:
  $$
  \ovverline {\{\langle x_1, y_1\rangle,\ldots, \langle x_n, y_n\rangle\}} {\Ss^\Ss}
  := \listenc {\listenc {x_1, y_1} 2,\ldots, \listenc {x_n, y_n} 2} {n}
  $$
  \end{defn}

  \begin{cor}
    \label{cor:funsetrepr}
    Each finite function from $\Ss$ to $\Ss$ and each set included in $\Ss$ can
    be represented by functions in $\POR$. Namely:
    \[
    \forall g \in \mathit{fin}(\Ss^\Ss).
    \exists f_g \in \POR. \forall x, \omega.
     f_g(x, \omega) = \ovverline g {\Ss^\Ss}
    \]
    \[
    \forall s \in \mathcal P_\mathit{fin}(\Ss).
    \exists f_s \in \POR. \forall x, \omega.
     f_s(x, \omega) = \ovverline s {P_\mathit{fin}(\Ss)}
    \]

  \end{cor}
  \begin{proof}
    This claim is a direct consequence of Definitions \ref{def:funenc} and \ref{def:setenc}
    and of Remark \ref{rem:listrepr}.
  \end{proof}

  Another result which we need to state is that the graph of any function
  $\delta:\Qs \times \Sigmab \times
  \{\zzero, \oone\} \longrightarrow \Qs
  \times \Sigmab \times \{L,R\}$
  can be represented by a term in $\Ss$ Formally

  \begin{cor}[Representability of $\delta$]
    \label{cor:deltarepr}
    There is an injection $f: (\Qs \times \Sigmab \times
    \{\zzero, \oone\} \longrightarrow \Qs
    \times \Sigmab \times \{L,R\}) \longrightarrow \Ss$.
  \end{cor}
  \begin{proof}
    We have suggested that the constants $L$ and $R$ can be represented by means of
    $\zzero$ and $\oone$ respectively, so it identifies an injection
    $i_1:\{L, R\} \longrightarrow \Ss$.
    Similarly, we have suggested that we can represented through their indexes.
    This identifies an injection $i_2: \Qs \longrightarrow \Nat$,
    we have also showed that there exists a natural injection
    $\ovverline \cdot \Nat:\Nat \longrightarrow \Ss$; so, the composition of
    $i_2$ and $\ovverline \cdot \Nat$ is an injection $\Qs\longrightarrow \Ss$.
    since $\Sigmab$ is a finite set, it's countable too, so there is a bijection
    $i_3: \Sigmab \longrightarrow \Nat$, which composed with $\ovverline \cdot \Nat$
    yields another injection $\Sigmab \longrightarrow \Ss$.
    These observations, together with Remark \ref{rem:listrepr} prove that
    there is an injection
    $i_4:\left(\Qs \times \Sigmab \times \{\zzero, \oone\}\right) \longrightarrow \Ss$
    and another injection
    $i_5:\left(\Qs \times \Sigmab \times \{L, R\}\right) \longrightarrow \Ss$
    Finally, the composition of these injection with the one described by
    Corollary \ref{cor:funsetrepr} yields the desired injection.
  \end{proof}

  Together with the previous result, we need to state
  that there exists an injection
  from an exhaustive representation of a Stream Machine's
  configuration and the set of strings because we want to simulate a
  Stream Machine $M$ recurring to its configuration. As we argued before,
  we do not want a complete dscription of the machine's configuration
  due to the fact that a configuration contains
  a total and generic function $\Nat \longrightarrow \Ss$.


  \begin{cor}[(Partial) Representability of Machine's Configurations]
    \label{cor:confrepr}
    There is an injection $f: (\Sigmab^* \times \Qs \times \Sigmab^*)
    \longrightarrow  \Ss$.
  \end{cor}
  \begin{proof}
    As for the proof of Corollary \ref{cor:deltarepr}, we observe that there is
    an injection $i_2: \Qs \longrightarrow \Nat$.
    Since $\Sigmab$ is a finite set, it's countable too, so there is a bijection
    $i_3: \Sigmab \longrightarrow \Nat$, which composed with $\ovverline \cdot \Nat$
    yields another injection $\Sigmab \longrightarrow \Ss$. There is another
    injection $i_1: \Sigmab^* \longrightarrow \Lists$ defined as follows:
    \begin{align*}
    i_1(\eepsilon)&:=\listenc {\ovverline {i_3(\circledast)}\Nat} 1\\
    i_1(c_0c_1\ldots c_n)&:=\listenc {\ovverline {i_3(c_n)}\Nat,\ldots,
    \ovverline {i_3(c_1)}\Nat, \ovverline {i_3(c_0)}\Nat} {n+1}
    \end{align*}
    In other words,
    for each $\sigma\in \Sigmab^*$, it suffices to take the list which contains
    in position $k$ the mapping of the $k$-th element of $\sigma$ through
    $i_1$, and as encoding of the empty tape a list with a single instance of
    the blank character. We tok this decision for a technical reason:
    the rightmost and the leftmost characters in an empty tape exist and are
    $\circledast$, this will turn out to be useful in the definition of
    the machine's simulation in $\POR$. We also know that there is an injection
    $\listenc \cdot {|\sigma|}: \Ss^{|\sigma|}\longrightarrow \Ss$.
    The composition of the afore mentioned injections with
    $\listenc \cdot 3$ yields the claimed one.
  \end{proof}

  We are interested in capturing $\SFP$ so, before going further,
  we want to instantiate encodings described in
  Corollaries \ref{cor:confrepr} and \ref{cor:deltarepr} for the class of the
  Canonical Stream Machines.

  \begin{defn}[Encodings for Canonical Stream Machines]
    \label{def:canencs}
    The Encodings for Canonical Stream Machines are defined from
    the one described in Corollaries \ref{cor:confrepr} and \ref{cor:deltarepr},
    choosing in particular:
    \begin{itemize}
      \item $q_i \mapsto i$ for $i_2$.
      \item $L\mapsto \zzero, R\mapsto \oone$.
      \item For $i_3$: $\zzero \mapsto 0, \oone \mapsto 1, \circledast \mapsto 2$
    \end{itemize}
  \end{defn}


  \subsubsection{The set $K_\SFP$}

  A Stream Machine works thanks to the manipulation of some tape's characters.
  Depending on the values of these characters, the Stream Machine rewrites them
  with different values and changes its current states.
  %
  All this work can be encoded by the Machine's transition function, which maps
  a Machine's configuration to another depending on the value of the $\delta$ function.
  %
  If we can represent the functions $\vdash_\delta'$ and $\reachesf {}{}$ in
  $\POR$ by means of two functions $\apply$ and $\step$,
  we will be able to define each $f_\delta$ as
  a composition of one of those functions.
  %
  Before doing so, we should give a formal definition of how $\apply$ and $\step$
  should behave. Intuitively they should be the counterpart of $\vdash_\delta'$
  and $\reachesf {n}{\delta}$, but which work on the values' encoding we have defined
  in Section \ref{subsub:encodings}. So, supposing that the inputs of $\apply$ and $\step$
  are properly shaped, their output must be
  the encoding of $\vdash_\delta'$
  and $\reachesf {n}{\delta}$ outputs. Formally:

  \begin{defn}[Counterpart of $\vdash_\delta'$]
    \label{def:vdashcounter}
    Let $\ovverline \cdot \Tapes$ be the encoding for tapes described in
    Corollary \ref{cor:confrepr}.
    A function $f : \Ss\times \Ss \times \Os \longrightarrow \Ss$ is the counterpart
    of $\vdash_\delta'$ if and only if:
    \begin{align*}
      &\forall \delta: \Qs \times \Sigmab \times \{\zzero, \oone\} \longrightarrow \Qs \times \Sigmab \times \{L,R\}. \\
      &\quad\forall \sigma \in \Ss.\forall q_i \in \Qs.\forall\tau \in \Ss.\forall \eta: \Nat\longrightarrow\Bool .\\
      &\quad\quad  \forall \sigma' \in \Ss, q_j\in \Qs,\tau'\in \Ss.\\
      &\quad\quad\quad  \forall x_c \in \Ss, x_\delta \in \Ss.\forall\omega: \Ss\longrightarrow\Bool. \forall k \in \Nat. \\
      &\quad\quad\quad\quad  x_c = \listenc {\ovverline \sigma \Tapes, \ovverline i \Nat, \ovverline \tau \Tapes, \ovverline k \Nat} 4 \to\\
      &\quad\quad\quad\quad\quad  x_\delta \text{ is the encoding of the graph of }\delta  \to\\
      &\quad\quad\quad\quad\quad\quad \vdash_\delta'(\langle \sigma, q_i, \tau, \bbool\eta\rangle)
      = \langle \sigma', q_j, \tau', \eta\rangle \to\\
      &\quad\quad\quad\quad\quad\quad\quad \left(\omega(\ovverline k \Nat)=\bbool \to
      f(x_c, x_\delta, \omega) = \listenc {\ovverline {\sigma'}\Tapes,
      \ovverline j \Nat, \ovverline {\tau'}\Tapes, \ovverline {k+1}\Nat} 4\right)\land\\
      &\quad\quad\quad\quad\quad\quad \vdash_\delta'(\langle \sigma, q_i, \tau, \eta\rangle)
      = \langle \sigma, q_i, \tau, \eta\rangle \to\\
      &\quad\quad\quad\quad\quad\quad\quad
      f(x_c, x_\delta, \omega) = \listenc {\ovverline {\sigma}\Tapes,
      \ovverline i \Nat, \ovverline {\tau}\Tapes, \ovverline {k}\Nat} 4\\
    \end{align*}
  \end{defn}

  Basically, this definition states that the counterpart of $\vdash_\delta'$
  must mimic it, mapping the encoding of its input to the encoding of its output,
  given that the first bit on the random tape and a certain coordinate on
  $\omega$ are identical.
  %
  Moreover, if $\vdash_\delta$ is undefined on the input configuration, $\vdash_\delta'$
  is constant by definition. For this reason, we want $\apply$ to be consant, too.
  This definition can be extended to its indexed transitive closure,
  lifting the point-to-point identity between the two oracles to a bijection.

  % \begin{defn}[Counterpart of $\vdash_\delta'$]
  %   \label{def:vdashcounter}
  %   A function $f : \Ss\times \Ss \times \Os \longrightarrow \Ss$ is the counterpart
  %   of $\vdash_\delta'$ if and only if:
  %   \begin{align*}
  %     &\forall \delta. \forall \sigma, q_i,\tau, \eta.\\
  %     &\quad  \forall \sigma', q_j,\tau',.\forall \sigma'', q_l,\tau'',\\
  %     &\quad\quad  \forall x_c, x_\delta.\forall\omega. \forall k. \\
  %     &\quad\quad\quad  x_c = \listenc {\sigma, \ovverline i \Nat, \tau, \ovverline k \Nat} 4 \to\\
  %     &\quad\quad\quad\quad  x_\delta \text{ is the encoding of the graph of }\delta \to\\
  %     &\quad\quad\quad\quad\quad \vdash_\delta'(\langle \sigma, q_i, \tau, \zzero\eta\rangle)
  %     = \langle \sigma', q_j, \tau', \eta\rangle \land\\
  %     &\quad\quad\quad\quad\quad \vdash_\delta'(\langle \sigma, q_i, \tau, \oone\eta\rangle)
  %     = \langle \sigma'', q_l, \tau'', \eta\rangle \to\\
  %     &\quad\quad\quad\quad\quad\quad \left(\omega(\ovverline k \Nat)=\zzero \to
  %     f(x_c, x_\delta, \omega) = \listenc {\sigma', \ovverline j \Nat, \tau', \ovverline {k+1}\Nat} 4\right)\\
  %     &\quad\quad\quad\quad\quad\quad \left(\omega(\ovverline k \Nat)=\oone \to
  %     f(x_c, x_\delta, \omega) = \listenc {\sigma'', \ovverline l \Nat, \tau'', \ovverline {k+1}\Nat} 4\right)\\
  %   \end{align*}
  % \end{defn}

  % The lifting of the counterpart of $\vdash_\delta'$
  % to its \emph{bounded} transitive closure, will end up with the counterprart of
  % $\reachesf {n}{\delta}$, since it is defined as the transitive closure of
  % $\vdash_\delta'$.

  \begin{defn}[Counterpart of $\reachesf n \delta$]
    \label{def:reachcounter}
    Let $\ovverline \cdot \Tapes$ be the encoding for tapes described in
    Corollary \ref{cor:confrepr}.
    A function $f : \Ss \times \Ss \times \Ss \times \Os \longrightarrow \Ss$
    is the counterpart
    of $\reachesf n \delta$ if and only if:
    \begin{align*}
      &\exists \text{ a bijection } b: \Nat \longrightarrow \Ss.\\
      &\quad\forall \delta: \Qs \times \Sigmab \times \{\zzero, \oone\} \longrightarrow \Qs \times \Sigmab \times \{L,R\}. \\
      &\quad\quad \forall n \in \Nat. \forall \sigma \in \Ss.\forall q_i \in \Qs.\forall \tau \in \Ss.\forall \eta: \Nat \longrightarrow \Bool.\\
      &\quad\quad\quad  \forall \sigma'\in \Ss.\forall q_j\in \Qs.\forall\tau'\in \Ss.\forall \eta': \Nat \longrightarrow \Bool\\
      &\quad\quad\quad\quad  \forall x_c , x_\delta\in \Ss.\forall\omega: \Ss\longrightarrow\Bool. \forall k \in \Nat. \\
      &\quad\quad\quad\quad\quad \exists N\subseteq \Nat.
        \forall x_N \in N. \eta(x_N)= \omega(b(x_N))\\
      &\quad\quad\quad\quad\quad\quad  x_c = \listenc {\ovverline \sigma \Tapes, \ovverline i \Nat, \ovverline \tau \Tapes, \ovverline k \Nat} 4 \to\\
      &\quad\quad\quad\quad\quad\quad\quad  x_\delta \text{ is the encoding of the graph of }\delta \to\\
      &\quad\quad\quad\quad\quad\quad\quad\quad \reachesf n \delta(\langle \sigma, q_i, \tau, \eta\rangle)
      = \langle \sigma', q_j, \tau', \eta'\rangle \to
      f(x_c, x_\delta, \ovverline n \Nat, \omega) = \listenc {\ovverline {\sigma'}\Tapes
      , \ovverline j \Nat, \ovverline{\tau'}\Tapes, \ovverline {k+n}\Nat} 4
    \end{align*}
  \end{defn}

  % \begin{defn}[Counterpart of $\reachesf n \delta$]
  %   \label{def:reachcounter}
  %   A function $f : \Ss \times \Ss \times \Ss \times \Os \longrightarrow \Ss$ is the counterpart
  %   of $\reachesf n \delta$ if and only if:
  %   \begin{align*}
  %     &\forall \delta, n. \forall \sigma, q_i,\tau, \eta.\\
  %     &\quad  \forall \sigma', q_j,\tau', \eta'.\\
  %     &\quad\quad  \forall x_c, x_\delta.\forall\omega. \forall k. \\
  %     &\quad\quad\quad \forall \nu \in \Ss. (\forall h \le n. \nu(h)= \eta(h)) \to\\
  %     &\quad\quad\quad\quad  x_c = \listenc {\sigma, \ovverline i \Nat, \tau, \ovverline k \Nat} 4 \to\\
  %     &\quad\quad\quad\quad\quad  x_\delta \text{ is the encoding of the graph of }\delta \to\\
  %     &\quad\quad\quad\quad\quad\quad \reachesf n \delta(\langle \sigma, q_i, \tau, \eta\rangle)
  %     = \langle \sigma', q_j, \tau', \eta'\rangle \to
  %     f(x_c, x_\delta, \nu, \omega) = \listenc {\sigma', \ovverline j \Nat, \tau', \ovverline {k+n}\Nat} 4
  %   \end{align*}
  % \end{defn}

  This definition comes as a natural extension of its previous,
  where the condition is basically the same, but the point-wise identity between
  $\eta$ and $omega$ is extended from a single pair of points to a set of
  pairs, which is the bijection $b$.

  If we show that that there exist
  \begin{itemize}
    \item function $\apply \in \POR$ which is the
    Counterpart of $\vdash_\delta '$ according to Definition \ref{def:vdashcounter}.
    \item a function $\step \in \POR$ which is the Counterpart of $\reachesf n \delta$
    according to Definition \ref{def:reachcounter}.
  \end{itemize}

  We would be able to prove Proposition \ref{prop:PORimplreach}, and with few effort,
  to show that Proposition \ref{prop:PORimplSFP} holds, too.

  For seek of completeness, let us define the set $K_\SFP$:

  \begin{defn}[$K_\SFP$]
    $K_\SFP:=\{\apply, \step\}$.
  \end{defn}


























  \subsubsection{$K_\SFP\subseteq \POR$}


  In order to prove that $K_\SFP \subseteq \POR$,
  we need some low level work: we have shown that there are some injections
  which allow us to represent at least lists, naturals and
  Boolean values in $\POR$, but
  without any manipulator, we cannot leverage those data to define the
  functions $\apply$ and $\step$ and so, neither the function $f_\delta$
  of Proposition \ref{prop:PORimplreach}.
  %
  The first operations we need are some control structures, and predicates.

  \paragraph{Boolean Algebra.}
  Since we choose to use $\zzero$ and
  $\oone$ to represent boolean values,
  it's natural to represent predicates
  with functions $\Ss^n \times \Os \longrightarrow \Bool$.
  %
  Given two values, $x_1$ and $x_2$,
  we can define a function that
  returns $x_1$ if a condition $y$
  is met, $x_2$ if such condition is false,
  and $\eepsilon$ otherwise.
  Such function behaves as an $\mathtt{if}$-expression.


  \begin{defn}[Expression $\mathtt{if}$]
  The $\mathtt{if}$ expression is defined as follows:
  \begin{align*}
  \mathtt{if}(x_1,x_2,\eepsilon, \omega) &:= \eepsilon \\
  \mathtt{if}(x_1,x_2,y\zzero, \omega) &:= x_2|_{x_1x_2} \\
  \mathtt{if}(x_1,x_2,y\oone, \omega) &:= x_1|_{x_1x_2} \\
  %\mathtt{if}(t,f,c,\omega) &:= \mathtt{if}'(t,f,c,\omega).
  \end{align*}
  \end{defn}
  %
  %
  \begin{remark}
    $\mathtt{if} \in\POR$
  \end{remark}
  \begin{proof}
    Trivial: the definition of the function is given by bounded recursion.
  \end{proof}
  %
  From now on, we will omit similar proofs.
  \noindent
  Thanks to the $\mathtt{if}$ function we can now
  also easily define some basic connectives
  of classical $\PL$.

  \begin{defn}[Logical Connectives]
  Conjunction, disjunction and negation are
  defined as follows:
  \begin{align*}
  (P_1\wedge P_2)(\vec{x},\omega) &:=
  \mathtt{if}(P_2(\vec{x},\omega),\zzero,P_1(\vec{x},\omega),
  \omega) \\
  %
  (P_1\vee P_2)(\vec{x},\omega) &:= \mathtt{if}(\oone,
  P_2(\vec{x},\omega), P_1(\vec{x},\omega), \omega) \\
  %
  (\neg P)(\vec{x},\omega) &:= \mathtt{if}(\zzero,\oone,P(\vec{x},\omega),
  \omega).
  \end{align*}
  \end{defn}

  Let us define some predicates which
  help to develop the encoding of list.
  In particular, in order to show that $\Hf \in \POR$ it will be useful
  to show that there is a predicate $\odd \in \POR$
  which is $\oone$ if and only if the length of the remaining
  part of such value is even or odd,
  depending on the value of this predicate, proceeding by
  iteration it will be possible to define whether to keep or remove
  a certain bit.

  %% definition
  \begin{defn}
  {Basic logical predicates in $\POR$
  are defined by the functions below:}
  \begin{align*}
  \odd(\eepsilon,\omega) &:= \zzero \\
  %
  \odd(y\bbool,\omega) &:= \neg\big(\even(y)\big)|_\zzero \\
  %
  \even(x,\omega) &:= \neg\big(\odd(x,\omega)\big) \\
  %
  \eq(x, y, \omega) &:= S(x, y, \omega) \land S(y, x, \omega)
  \end{align*}
  \end{defn}
  %
  %

  \begin{remark}
  Observe that the $\odd$ and $\even$
  predicates work as their opposites
  for the encoding of natural numbers:
  \begin{align*}
  \forall \sigma \in {\Ss}.\forall \bbool
  \in \Bool. \odd(\sigma) &\leftrightarrow
  \even(\sigma b) \\
  %
  \forall n\in \Nat.\odd{(\ovverline{n}{\Nat})} &\leftrightarrow
  n \text{ is even.}
  \end{align*}
  \end{remark}

  Finally, when defining $\apply$ it will often be the case to
  test the rightmost or leftmost bit of a string.
  In order to do so, we need to define two other predicates:

  \begin{defn}
  Given a string, predicates
  \begin{itemize}
    \item $\res$, i.e. Right Most Element String
    \item $\les$, i.e. Left Most Element String
  \end{itemize}
  are defined as follows:
  \begin{align*}
  \res(\eepsilon,\omega) &:= \eepsilon \\
  \res(y\zzero, \omega) &:= \zzero|_\oone \\
  \res(y\oone,\omega) &:= \oone|_\oone \\
  \\
  \les(\eepsilon,\omega) &:= \eepsilon \\
  \les(y\zzero,\omega) &:= \mathtt{if}\big(\zzero, \les(y,\omega),
  {\Cf}(y,\eepsilon,\omega),\omega\big)|_{\oone} \\
  \les(y\oone,\omega) &:= \mathtt{if}\big(\oone,
  \les(y,\omega), S(y,\eepsilon,\omega),\omega\big)|_{\oone}.
  \end{align*}
  \end{defn}

  \begin{remark}
  \begin{align*}\
  \forall \sigma \in {\Ss}.\res(\sigma \oone) &=
  \oone \wedge \res(\sigma\oone)=\oone \\
  %
  \forall \sigma \in {\Ss}.\les(\oone\sigma) &=
  \oone \wedge \res(\zzero\sigma)=\zzero.
  \end{align*}
  \end{remark}

  \paragraph{Strings}
  \label{par:strings}

  The Stream Machines' reachability function is defined on top of
  configurations, in particular, the strings which represent the tape are
  obtained from the strings in the initial configuration, applying some of the
  following transformations:
  %
  \begin{itemize}
    \item Appending on the left or on the right.
    \item Deleting a character on the left or on the right.
  \end{itemize}
  %behavior
  If we show that there are functions with a similar behaviour
  in $\POR$ we can compose them to define $\apply$, $\step$ and thus $f_\delta$.
  %
  \begin{defn}[String Appenders and Removers]
    \label{def:apprems}
      We define string appenders
      \begin{itemize}
        \item $\ras$, i.e. \emph{Right Appender for Strings}
        \item $\las$, i.e. \emph{Left Appender for Strings}
        \item $\rrs$, i.e. \emph{Right Remover for Strings}
        \item $\lrs$, i.e. \emph{Left Remover for Strings}
      \end{itemize}
      as follows:
      \begin{align*}
        \reverse(\eepsilon, \omega) &:= E(x, \omega)\\
        \reverse(x\bbool, \omega) &:= \concat(\bbool, \reverse (x, \omega), \omega)\\%[2ex]
        \ras(x, y, \omega) &:= \concat(x, y, \omega)\\%[2ex]
        \las(x, y, \omega) &:=  \reverse (\ras(\reverse(x, \omega), \omega), \omega)\\%[2ex]
        \rrs(\eepsilon,\omega) &:=  E(x, \omega)\\
        \rrs(x\bbool, \omega) &:=  x|_{x}\\%[2ex]
        \lrs(\eepsilon, \omega) &:= \reverse (\rrs(\reverse(x, \omega), \omega), \omega)
      \end{align*}
  \end{defn}

  \paragraph{Natural Numbers}

  Comparing Propositions \ref{prop:PORimplreach} and \ref{prop:PORimplSFP},
  we see that in the first case $f_\delta$ depends on a parameter which expresses
  the number of steps we want to run the simulation, while $f_M$ does not
  depend on any similar parameter. This because it's possible to fix the
  time parameter $x_m$ and to make it dependent on the input
  and the machine $M$. To do so, we must show that all the polynomials are in
  $\POR$, this way we may compute an appropriate time bound for any
  $\SFP$ function.

  \begin{defn}[Successor]
  We define a successor function
  $\Succ : \Ss_\Nat \longrightarrow \Ss_\Nat$
  that computes the successor of a number:
  \begin{align*}
  \Succ(\eepsilon, \omega) &:= \eepsilon \\
  \Succ(y\bbool, \omega) &:= \Sf_\oone(y,\omega)|_{y\oone}
  \end{align*}
  \end{defn}
  \noindent


  \begin{defn}[Predecessor]\label{df:predecessor}
  If $y\in \Ss_\Nat$ is the encoding
  of a number,
  the $\pd$ function calculates
  its predecessor y simply removing its
  last digit (if present):
  \begin{align*}
  \pd(\eepsilon,\omega) &:= \eepsilon \\
  \pd(y\bbool,\omega) &:= y|_y
  \end{align*}
  \end{defn}

  \begin{remark}
  $\forall \sigma,c_1,c_2.\pd(\pd(\sigma c_1c_2))=\sigma$.
\end{remark}
  \begin{proof}
  The claim is a trivial consequence of Definition~\ref{df:predecessor}.
  \end{proof}


  %% def
  \begin{defn}[Sum]
  The sum of two numbers $\mathit{sum}$
  is implemented using the operation of concatenation
  $\concat$ introduced in Definition \ref{def:concat} as:
  \[
  \mathit{sum}(x, y, \omega) := \pd(\concat(x, y, \omega), \omega)
  \].
  \end{defn}


  The $\POR$-encoding of the difference
  between two numbers is cumbersome
  because it recurs on the definition of
  the $\sa$ functor.
  Intuitively, it applies $\rrs$ $n$ times to $x$,
  where $\ovverline n\Nat$ is $y$.

  %% defn
  %% difference
  \begin{defn}[Difference]
  The function $\mathit{diff}$, which computes
  the difference between two natural numbers,
  is defined as follows:
  \begin{align*}
  \mathit{diff}(x, y, \omega) &:= \sa_{\rrs, x}(x, y, omega)
  \end{align*}
  \end{defn}
  %
  \begin{remark}
    The function $\mathit{diff}$ is in $\POR$ and follows its intended semantics.
  \end{remark}
  \begin{proof}
      Lemma \ref{lemma:saPOR} states that the function $\sa_{\rrs, x}$ is in
      $\POR$ and that $\sa_{\rrs, x}(x, \ovverline n \Nat, \omega)=\rrs^n(x, \omega)$
      this is sufficient to prove the claim, in accoradance with the definition
      of $\rrs$ (Definition \ref{def:apprems}).
  \end{proof}

  %
  %
  \noindent
  In order to multiply two values $x,y$,
  we can remove their last digit -- so that their size
  is equal to the number that they encode --
  concatenate $x$ to itself $y$-times and
  return the successor of the number we get.

  %% defn
  %% multiplication
  \begin{defn}[Multiplication]
  Multiplication between two natural numbers,
  $\mult$, is defined
  as follows:
  \begin{align*}
  {\mult^*}(x,  \eepsilon) &:= \eepsilon \\
  {\mult^*}(x, y\bbool) &:= \big(\mathit{sum}(\mult(x, y, \omega)
  x, \omega)\big)|_{x\times y\oone} \\
  \mult(x, y, \omega) &:= \Succ\big( \mult^*(\pd(x,\omega),
  \pd(y,\omega))\big).
  \end{align*}
  \end{defn}
  %
  %
  \noindent
  With this encoding the computation of an exponential function
  would require an exponential size for the representation
  of the output, but our iteration is bounded by a term $\Lpw$
  and the size of the number in our encoding is
  linear in its value\footnote{We prove such result in Lemma \ref{lemma:size}}.
  Nevertheless, we can show how to compute an exponentiation, and so
  how to represent monomials and polynomials.

  \begin{defn}[Exponentiation]
  Given a $k\in \Nat$, the function computing
  the $k$-th exponentiation of such value
  is defined as follows:
  \begin{align*}
    @0(x, \omega)&:= \ovverline 1 \Nat\\
    @(n+1)(x, \omega)&:= \mult(@n(x), x)\\
  \end{align*}
  \end{defn}

  \begin{remark}[Correctness of the operations on Natural Numbers]
    It holds that:
    \begin{align*}
      \forall n, m \in \Nat.\forall \omega. \Succ (\ovverline n \Nat, \omega) &=\ovverline {n+1} \Nat \\
      n>0\to  \pd (\ovverline n \Nat, \omega) &=\ovverline {n-1} \Nat \\
      \mathit{sum}(\ovverline n \Nat, \ovverline m \Nat, \omega)= \ovverline {n+m}\Nat\\
      n\ge m \to \mathit{diff}(\ovverline n \Nat, \ovverline m \Nat, \omega)= \ovverline {n-m}\Nat\\
      \mathit{mult}(\ovverline n \Nat, \ovverline m \Nat, \omega)= \ovverline {n\cdot m}\Nat\\
      @m(\ovverline {n}\Nat,\omega)= \ovverline {n^m}\Nat
    \end{align*}

  \end{remark}



  \paragraph{Lists}

  Finally, the functions $f_\delta$ of Proposition \ref{prop:PORimplreach},
  $\apply$ and $\step$ defined before work on tuples, which are represented as
  lists, so we need some functions for manipulating lists as well.
  %
  Basically we can define an adequate set of manipulators
  lifting the functions identified in Paragraph \ref{par:strings} from strings
  to list. Their composition will drive to generalized
  projectors and inseters.
  But before doing so, we must show that the function $\Hf$ is in $\POR$,
  because we need it to build projectors\footnote{We
   have already argued that $\Df$ was a $\POR$ function in Remark
  \ref{lemma:dfinpor}.}.
  %
  \begin{lemma}
    $\Hf$ is in $\POR$.
  \end{lemma}
  \begin{proof}
    It can be shown giving the following definition:

    \begin{align*}
    \Hf(\eepsilon,\omega) &:= \eepsilon \\
    \Hf(y\zzero, \omega) &:= \concat\big(\Hf(y,\omega),
    {\mathtt{if}}(\zzero,\eepsilon,
    \odd(y,\omega),\omega)\big){|_{y\zzero}} \\
    %
    \Hf(y\oone,\omega) &:=
    \concat\big(\Hf(y,\omega), {\mathtt{if}}
    (\oone,\eepsilon,\odd(y,\omega),\omega)\big)
    {|_{y\zzero}}.
    \end{align*}
  \end{proof}
  %
  Moreover, we ought show that it's the left-inverse of $\Df$, as stated by
  the following lemma.

  \begin{lemma}[Left-Inverse of $\Df$]
    \label{lemma:dhleftinverse}
  $\forall \sigma \in {\Ss},
  \omega \ { \in \Os.} \Hf\big(\Df(\sigma,\omega),\omega\big)
  =\sigma$.
  \end{lemma}
  \begin{proof}
  The proof is by (right) induction on $\sigma$.
  \begin{itemize}
  \itemsep0em

  \item[$\eepsilon.$] The thesis comes from a trivial
  rewriting of the two functions' bodies.

  \item[$\tau c.$] The thesis is
  \begin{align*}
  \Hf\big(\Df(\tau c,\omega),\omega\big) &= \tau c \\
  %
  \Hf\big(\Df(\tau,\omega)\oone c, \omega\big) &=
  \tau c.
  \end{align*}
  By induction on $\sigma$ we can
  also prove that
  $\forall \sigma.\odd\big(\Df(\sigma)\big)=
  {\zzero}$.
  So we can simplify our claim as follows:
  \begin{align*}
  \Hf\big(\Df(\tau,\omega)\oone c,\omega\big) &=
  \tau c \\
  %
  \Hf\big(\Df(\tau,\omega)\oone,\omega\big)c
  &= \tau c \\
  %
  \Hf\big(\Df(\tau,\omega)\oone,\omega\big)
  &= \tau.
  \end{align*}
  We argued that $\forall \sigma.\odd\big(\Df(\sigma)\big)
  ={\zzero}$.
  So, we can state the claim as:
  \begin{align*}
  \Hf\big(\Df(\tau,\omega)\oone,\omega\big) &= \tau \\
  %
  \Hf\big(\Df(\tau,\omega),\omega\big) &= \tau
  \end{align*}
  which is IH.
  \end{itemize}
  \end{proof}

  Thanks to the previous result, we can leverage $\Hf$ to define list
  appenders, extractors and removers.


  %
  \begin{defn}[List Extractors,  Appenders and Removers]
    \label{def:listops}
      We define lists' manipulator
      \begin{itemize}
        \item $\rel$, i.e. \emph{Right Appender for Lists}
        \item $\lel$, i.e. \emph{Left Appender for Lists}
        \item $\ral$, i.e. \emph{Right Appender for Lists}
        \item $\lal$, i.e. \emph{Left Appender for Lists}
        \item $\rrl$, i.e. \emph{Right Remover for Lists}
        \item $\lrl$, i.e. \emph{Left Remover for Lists}
      \end{itemize}
      and the auxiliary functions
      \begin{itemize}
        \item $\rmsep$, i.e. the functions which removes an encoded character.
        \item $\rel'$, i.e. the functions which returns the rightmost element
        of a list (size included).
        \item $\srrl$, i.e. the right semi-remover, which given a
        string shaped as $\sigma\zzero\zzero\tau\zzero\zzero$ returns
        $\sigma\zzero\zzero$ where $\sigma$ is as long as possible.
        This function is dual with respect to $\rel$.
      \end{itemize}
      Starting from the auxiliary functions, we define them as:
      \begin{align*}
        \rmsep(x, \omega) &:= \rrs(\rrs(x, \omega), \omega)\\
        \rel'(\eepsilon,\omega) &:= E(x, \omega) \\
        %
        \rel'(y\zzero, \omega) &:= \mathtt{if}(\eepsilon,
        \concat(\rel'(y,\omega),\zzero),
        (\lnot \res(y, \omega)){\wedge}
        \odd(y, \omega),\omega)|_{y\zzero} \\
        %
        \rel'(y\oone,\omega) &:=
        \concat(\rel'(y,\omega),
        \oone,\omega))|_{y_\zzero}\\
        %
        %
        \srrl'(\eepsilon,\omega) &:= E(x, \omega)\\
        %
        \srrl'(y\zzero, \omega) &:= \mathtt{if}(y\zzero,
        \srrl'(y, \omega),
        \lnot (\res(y, \omega)){\wedge}
        \odd(y, \omega),\omega)|_{y\zzero} \\
        %
        \srrl'(y\oone,\omega) &:= \srrl'(y, \omega)|_{y_\zzero}\\
        \srrl(x, \omega) &:= \srrl'(\rmsep(x, \omega), \omega)\\
      \end{align*}

      \begin{align*}
        %
        \rel(t,\omega) &:= \Hf(\rel'(\rmsep(t),\omega),\omega)\\
        %
        \lel(x, \omega) &:= \reverse(\rel(\reverse(x, \omega), \omega), \omega)\\
        \ral(x, y, \omega) &:= \srrl(x, \omega)\zzero \zzero
                               \Df(y, \omega)\zzero \zzero
                               \Df(\rel(x,\omega)\oone, \omega)\zzero\zzero
                                \\%[2ex]
        \lal(x, y, \omega) &:= \zzero \zzero\Df(y, \omega)
                                \srrl(y, \omega)
                                \Df(\rel(x, \omega)\one, \omega)
                                \zzero\zzero\\%[2ex]
        \rrl(x,\omega) &:=  \srrl(\srrl(x, \omega), \omega)
                            \Df(\rrs(\rel(x, \omega),\omega) \omega)
                            \zzero\zzero \\
        \lrl(x,\omega) &:=  \srrl(\reverse(\srrl(\reverse(x, \omega), \omega),\omega)
                            \Df(\rrs(\rel(x, \omega),\omega) \omega)
                            \zzero\zzero \\
      \end{align*}
    \end{defn}

    \begin{remark}[Correctness of lists operators]
      \label{rem:corrlistops}
      Lists operators of Definition \ref{def:listops} follow their
      intended specification.
    \end{remark}
    \begin{proof}
      Respectively:
      \begin{itemize}
        \item [$\rmsep$] Trivial, comes from the definition od $\rrs$.
        \item [$\rel'$] Suppose that $x=\{\oone\zzero,
         \oone\oone\}^*\zzero\zzero\{\oone\zzero, \oone\oone\}^*$. The case $E$
         is useless. By cases on the input. If the input is $y\zzero$, we
         continue by cases on the guard of the $\mathtt{if}$ function:
         $\lnot (res(y, \omega))$ entails that $y=y'\zzero$, so the input of
         the function is $y'\zzero\zzero$ finding two consecutive $\zzero$s
         means that we reached the separator, indeed the output is the same
         of $\rel'$ is its input. If the guard is not true, the $\zzero$ at the end of the
         input is the second character of an encoded $\zzero$ in the rightmost
         value; even if the input is $y\oone$, the current character is the encoding
         of a value, so we get the claim by induction.
        \item[$\srrl'$] We have already argued that this function is the
        dual of the $\rel'$ function.
        The proof is a slight variation of the previous.
        \item[$\srrl$] Trivial by the proof of the correctness of $\srrl'$
        \item[$\rel$] The claim is a consequence of the correctness of $\rel'$
          and of Lemma \ref{lemma:dhleftinverse}.
        \item[$\lel$] The claim comes from the fact that the definition of $\rel$
        checks that a sequence of two characters is found and that the current
        character is in even position (the remaining part of the encoding has
        odd length) and that
        \begin{itemize}
          \item By induction on $\sigma$ we can show that
          $\forall \sigma.\Df(\sigma)$ has odd length.
          \item If $\sigma$ is the encoding of a list, the separators
          $\zzero\zzero$ are always followed by an even number of characters.
          This can be show by induction on the number of elements of the list.
        \end{itemize}
        \item[$\ral$, $\lal$] The correctness comes from the definition of
        lists' encoding and from the correctness of all the functions which
        appear in the definitions of $\ral$ and $\lal$.
        \item[$\rrl$] The correctness comes from the definition of
        lists' encoding and from the correctness of all the functions composed
        in the definition.
        \item[$\lrl$] The correctness comes from the definition of
        lists' encoding and from the fact that $\srrl$, as $\rel$ does, is
        safe with respect to the reversing of a string.
      \end{itemize}
    \end{proof}

    In order to show that $\reachesf n \delta$ is in $\POR$,
    we can show that $\vdash_\delta'$ and then that the $n$-th self
    application of a $\POR$ funciton is im $\POR$ as well.
    To do so, we show that for each $\POR$ function $f$ there exists another
    function which takes in input the encoding of a natural number $n$
    and the result is the $n$-th self-application of $f$.

    % \begin{lemma}
    %   $\forall f \in \POR.
    %   \left( f: \Ss \times \Os \longrightarrow \Ss\right) \to
    %   \left(\exists t \in \Lpw. \forall x, \omega. f(x, \omega)|_t =
    %   f(x, \omega)\right) \to
    %   \exists \sa_{f, t} : \Ss \times \Ss \times \Os \longrightarrow \Ss.
    %   \forall n \in \Nat. \forall x,  \omega.
    %   sa_{f, t}(x, \ovverline n \Nat, \omega) = f^n(x, \omega)$
    % \end{lemma}
    % \begin{proof}
    %   Let $f \in \POR$, $\sa$ is defined as follows:
    %   \begin{align*}
    %     \sa_{f, t}'(x, \eepsilon, \omega) &:= x\\
    %     \sa_{f, t}'(x, y\bbool, \omega) &:= f(\sa_{f, t}'(x, y, \omega), \omega)|_t\\
    %     \sa_{f, t}(x, y, \omega) &:= \sa_{f, t}'(x, \rrs(y, \omega), \omega)
    %   \end{align*}
    %   The correctness of $\sa$ comes from the fact that we can observe
    %   that $\ovverline n\Nat$ has size $n+1$.
    %   We prove that $|y|=n \to \sa_f'(x, y, \omega) = f^n(x, \omega)$.
    %   By induction on the value of $n$.
    %   If such value is $0$, $\sa$ reduces to $\sa'$ with argument $\eepsilon$,
    %   so the result is $x$. Otherwise, the relut comes from the IH.
    %   The observation on the size of $\ovverline n \Nat$ and the correctness of
    %   $\rrs$ entail the correctness of $\sa$.
    % \end{proof}
    %
    % We can extend these definitions to the self-application of function with
    % some additional parameters

    \begin{lemma}
      \label{lemma:saPOR}
      $\forall k \in\Nat.\forall f \in \POR.
      \left( f: \Ss^{k+1} \times \Os \longrightarrow \Ss\right) \to
      \left(\exists t \in \Lpw. \forall x, \vec z, \omega. f(x, \vec z, \omega)|_t =
      f(x, \vec z, \omega)\right) \to
      \exists \sa_{f, t} : \Ss^{k+2} \times \Os \longrightarrow \Ss.
      \forall n \in \Nat. \forall x,  \omega.
      sa_{f, t}(x, \ovverline n \Nat, \vec z, \omega) =
      \underbrace{f(f(f(x, \vec z,  \omega), \vec z, \omega), \ldots)}_{n\text{ times}} \land \sa_{f, t}\in \POR$.
    \end{lemma}

    \begin{proof}
      Let $f \in \POR$, $\sa$ is defined as follows:
      \begin{align*}
        \sa_{f, t}'(x, \eepsilon,\vec z, \omega) &:= x\\
        \sa_{f, t}'(x, y\bbool,\vec z, \omega) &:= f(\sa_{f, t}'(x, y, \omega),\vec z, \omega)|_t\\
        \sa_{f, t}(x, y, \vec z, \omega) &:= \sa_{f, t}'(x, \rrs(y, \omega),\vec z, \omega)
      \end{align*}
      The correctness of $\sa$ comes from the fact that we can observe
      that $\ovverline n\Nat$ has size $n+1$.
      We prove that $|y|=n \to \sa_f'(x, y, \vec z, \omega) =
      f(f(f(x, \vec z,  \omega), \vec z, \omega), \ldots)$, nested $n$ times.
      By induction on the value of $n$.
      If such value is $0$, $\sa$ reduces to $\sa'$ with argument $\eepsilon$,
      so the result is $x$. Otherwise, the result comes from the IH
      and the definition of $\sa'$.
      The observation on the size of $\ovverline n \Nat$ and the definition of
      $\rrs$ entail the correctness of $\sa$.
    \end{proof}


    This family of functions allows us to define the list extractors:

    \begin{defn}[Family of Constant Projectors]
    A family of \emph{constant} projectors, $\pi_n$ for $n \in \Nat$, is defined
    as follows:
    \begin{align*}
    \pi_n (x, \omega) : = \rel(\sa_{\rrl, x}(x, {\ovverline n \Nat}, \omega), \omega)
    \end{align*}
    \end{defn}

    \begin{defn}[Family of Parametric Projectors]
    A family of \emph{parametric} projectors, $\pi_n$ for $n \in \Nat$, is defined
    as follows:
    \begin{align*}
    \pi (x, n, \omega) : = \rel(\sa_{\rrl, x}(x, n, \omega), \omega)
    \end{align*}
    \end{defn}

    \begin{remark}[Correctness of projectors]
      Constant and Parametric projectors with index $i>0$ such that
      are correct according to their intended
      specification. Moreover, $\pi_0$ returns
      the number of elements in the list and
      for indexes of projections $j$ greater than
      the number of elements in the list, $pi_j$ returns $\eepsilon$.
    \end{remark}
    \begin{proof}
      Correctness is a consequence of the correctness of $\sa, \rrl$ and
      $\rel$ functions which has already been proved.
    \end{proof}

    The last function which we need to introduce in order to define $\apply$
    is a function which, given the encoding of the graph of a finite function
    $\Ss \longrightarrow \Ss$, calculates the image of a string $\sigma \in \Ss$,
    if such string is part of the graph.

    \begin{defn}[Total Function Simulator]
      We define the Total Function Simulator $\simulate(x, x_g, \omega) \in \POR$ as follows:

      \begin{align*}
        \simulate'(x_g, x, \epsilon, \omega) &:= \epsilon \\
        \simulate'(x_g, x, y\bbool, \omega) &:= \mathtt{if}(\pi_2(\pi(x_g,
        y\bbool,
        \omega), \omega), \simulate'(x_g, x, y, \omega),
        \eq(\pi_1(\pi(x_g,
        y\bbool,
        \omega), \omega), x, \omega), \omega) \\
        \simulate(x, x_g, \omega) &:= \simulate'(x_g, x, \pi_0(x_g, \omega), \omega)
      \end{align*}
    \end{defn}

    The correctness of the function $\simulate$ is formalized as follows

    \begin{lemma}
      \label{lemma:simcorr}
      If $\gamma$ is a function $\Ss \longrightarrow \Ss$ such that $|\gamma|=n$,
       define $x_\gamma = \listenc {\listenc {x_1, y_1} 2, \ldots,
      \listenc {x_n, y_n} 2} n$,  then
      $\simulate(x, x_\gamma, \omega)=\gamma(x)$,
      otherwise $\simulate(x, x_\gamma, \omega)=\eepsilon$.
    \end{lemma}
    \begin{proof}
      Suppose $\overline x$ is in $\gamma$'s domain. It means that there is a tuple
      $t=\listenc{ \overline x, \overline y} 2$ in $x_\gamma$, so there exists
      $k \in \Nat$ such that $t=\pi_k(x_\gamma, \omega)$.
      Thus we can prove that if the third argument of $\simulate'$
      is the number of elements in $t$, then
      $\forall k\le m < |t|. \simulate'(x_\gamma, x,
      \ovverline m \Nat, \omega)=\overline y$; this result can be proven by induction
      on $m$.
      Then, the correctness of $\simulate$ comes as consequence because it is
      an instance of $simulate'$ with a value which is greater or equal to any
      possible value of $k$, namely the number of pairs in $x_\gamma$.
    \end{proof}

    Before proceeding with the remaining part, we want to show a result which will
    be used in Section \ref{subsub:sifpratosifpla}. That $\simulate$ is identical
    if the graph of $\gamma$ is encoded as a list $l$ or a permutation $l'$ of $l$

    \begin{cor}
      \label{cor:simperminvariance}
      If $\gamma$ is a function $\Ss \longrightarrow \Ss$ such that $|\gamma|=n$,
       define $x_\gamma = \listenc {\listenc {x_1, y_1} 2, \ldots,
      \listenc {x_n, y_n} 2} n$ and
      $x_\gamma' = \listenc {\listenc {x_{f(1)}, y_{f(1)}} 2, \ldots,
     \listenc {x_{f(n)}, y_{f(n)}} 2} n$ then
      $\simulate(x, x_\gamma, \omega)=\simulate(x, x_\gamma', \omega)$,
      otherwise $\simulate(x, x_\gamma, \omega)=\eepsilon$.
    \end{cor}
    \begin{proof}
      Suppose that $x$ is an input in the graph of $\gamma$ it means that
      $\exists 1 \le i\le n.\exists y_i.$ such that $\langle x_i, y_i\rangle \in \gamma$.
      by definition these elements appear uniquely in $x_\gamma$ and by the
      fact that $f$ is a permutation, they appear uniquely in $x_\gamma'$, too.
      We can move the same argument of the proof of Lemma \ref{lemma:simcorr},
      showing that the function $\simulate'(x_\gamma, x_i, \ovverline{|t|}\Nat, \omega)$
      and $\simulate'(x_\gamma', x_i, \ovverline{|t|}\Nat, \omega)$
      will both return $y_i$ because $\exists ! j\le |t|. f(j)=i$.
    \end{proof}


    At this point, we can finally show that the set of basic functions which
    we identified is expressive enough to express the counterparts of
    $\vdash_\delta'$ and $\reaches n \delta$:

    \begin{lemma}[$\apply \in \POR$]
      \label{lemma:applyinPOR}
      There exists a function $\apply\in \POR$ which is the counterpart of
      $\vdash_\delta'$, according to Definition \ref{def:vdashcounter}.
    \end{lemma}

    The function which verifies the claim is $\apply$.

    \begin{defn}[$\apply$]
      The function $\apply$ is defined as follows:
      \begin{align*}
        \apply(x_c, x_\delta, \omega) = &\mathtt{if}(
%        \listenc{\pi_1(x_c, \omega), \pi_2(x_c, \omega), \pi_3(x_c, \omega),
%        \pi_4(x_c, \omega)\oone}4,
        x_c,
        \mathtt{if}(\\
        &\quad\langle\ \rho(\rrl(\pi_1(x_c,\omega),\omega), \omega),\\
        &\quad \quad\pi_3(\chi(x_c, x_\delta, \omega),\omega),\\
        &\quad \quad\lal(\lal(\lrl(\pi_3(x_c,\omega), \omega),
        \pi_1(\chi(x_c, x_\delta, \omega)),
        \omega), \rel(\pi_1(x_c,\omega),\omega),\omega),\\
        &\quad \quad \pi_4(x_c,\omega)\oone
        \rangle^4_\Lists,\\
        %
        %
        &\quad\langle\ \ral(\rrl(\pi_1(x_c,\omega),\omega),
       \pi_1(\chi(x_c, x_\delta, \omega),\omega), \omega),\\
       &\quad\quad \pi_3(\chi(x_c, x_\delta, \omega),\omega),\\
       &\quad\quad \rho(\lrl(\pi_3(x_c,\omega),\omega), \omega),\\
       &\quad\quad \pi_4(x_c,\omega)\oone\rangle^4_\Lists,  \\
       &\quad\eq(\pi_3(\chi(x_c, x_\delta, \omega), \omega), \zzero), \omega),
       \lnot \eq(\chi(x_c, x_\delta, \omega),\eepsilon, \omega),\omega)
      \end{align*}
      The auxiliary function $\chi$ and $\rho$ are defined as follows:
      %
      \begin{align*}
        \rho(t,\omega) &:= \mathtt{if}(\ovverline \circledast \Tapes,
        t, \eq(\pi_0(t, \omega), \ovverline 0 \Nat, \omega), \omega)\\
        \chi(x_c, x_\delta, \omega) &:= \simulate(x_\delta,
                    \listenc{ \pi_2(x_c, \omega),
                              \lel(\rho(\pi_3(x_c, \omega), \omega), \omega),
                              Q(\pi_4(x_c, \omega),\omega)} 3, \omega\rangle
      \end{align*}
    \end{defn}
    \begin{proof}
      It should not be too much of a problem to see
      that the function $\rho$ return a tape which contains an instance of the
      blank character if and only if the tape passed as argument is empty,
      otherwise it returns its agument.
      %
      Thanks to this observation, we prove that $\chi$ is defined as the
      invoking of $\simulate$ on the tuple which contains:
      \begin{enumerate}
        \item the current state $\pi_2(x_c, \omega)$
        \item current character $\lel(\rho(\pi_3(x_c, \omega), \omega), \omega)$
        \item the simulated oracle bit $Q(\pi_4(x_c, \omega),\omega)$
      \end{enumerate} to
      $\simulate$ which returns either the encoding of the image of the tuple
      through $\delta$ (if defined), or $\eepsilon$ as stated by Lemma
      \ref{lemma:simcorr}.
      %
      Moreover, the random bit in the tuple inside $\chi$
      is obtained querying $\omega$ on the fourth projection
      of the configuration as required by Definition \ref{def:vdashcounter}.
      %
      Suppose that the result of $\chi$ is $\eepsilon$, then the claim is
      trivially true, since the function returns exactly its input, but with
      the counter increased by one, as required by Definition
      \ref{def:vdashcounter} and by the Definition \ref{def:smtransfun}.
      %
      Otherwise, suppose that $\chi$ returns a value different from $\eepsilon$.
      It means that $\delta$ is defined on its input, so, the guard of the inner
      $\mathtt{if}$ expression checks whether the result describes a right or
      left movement of the head and, depending on the response, behaves
      differently. Observe that the constant $L$ is represented by $\zzero$
      as stated in Definition \ref{def:canencs}.
      %
       We will show only the case in which the head moves right, for the left
       movement the proof is analogous. The configuration is made up as follows:
       \begin{enumerate}
         \item The left tape $\ral(\rrl(\pi_1(x_c,\omega),\omega),
        \pi_1(\chi(x_c, x_\delta, \omega),\omega))$
         is obtained removing the current character by means of
         $\rrl(\pi_1(x_c,\omega),\omega)$, appending
         the character which is written by the head
         $\pi_1(\chi(x_c, x_\delta, \omega),\omega)$ by means of $\ral$.
         \item The current state is obtained projecting
         the third element of $\chi$.
         \item The right tape loses its leftmost element, becoming
         $\ovverline \circledast \Tapes$ if empty, as described by
         \linebreak
         $\rho(\lrl(\pi_3(x_c,\omega),\omega), \omega)$.
         \item the counter is increased by one.
       \end{enumerate}
       %
       This behavior corresponds to what described by
       Definition \ref{def:smtransfun}.
       If $Q(\pi_4(x_c, \omega),\omega)=\eta(0)$ the move obtained througout
       $\simulate$ coincides with the move taken by the machine.
       If we suppose that $x_c = \listenc
       {\ovverline \sigma \Tapes, \ovverline i \Nat,
        \ovverline \tau \Tapes, \ovverline k \Nat} 4$
        we get that
        \begin{align*}
          Q(\pi_4(x_c, \omega),\omega)&=\eta(0)\\
          Q(\ovverline k \Nat, \omega)&=\eta(0)
        \end{align*}
        This condition is equal to the condition required by Definition
        \ref{def:vdashcounter}.
        Finally, if we suppose that $\delta$ is undefined on the current transition,
        we know by correctness of $\simulate$ (Lemma \ref{lemma:simcorr}) that
        $\chi(x_c, x_\delta, \omega)$ returns $\eepsilon$. According to the
        Definition of $\apply$, the overall function returns $x_c$ unchanged.
        Even in this case, $\apply$ behaves as required by Definition
        \ref{def:vdashcounter}.
    \end{proof}

    \begin{lemma}[$\step \in \POR$]
      \label{lemma:stepinPOR}
      There exists a function $\step\in \POR$ which is the counterpart of
      $\reachesf n \delta$, according to Definition \ref{def:reachcounter}.
    \end{lemma}

    The function which verifies the claim is defined as follows:

    \begin{defn}[$\step$]
      The function $\step$ is defined as follows:
      \begin{align*}
        \step(x_c, x_\delta, y, \omega) := \sa_{\apply, x_c\oone^6}(x_c, y, x_\delta, \omega)
      \end{align*}
    \end{defn}
    \begin{proof}
      Definition \ref{def:reachcounter} requires us to identify the bijection
      which relates the queries made by the Stream Machine to the queries
      made by the counterpart of $\reachesf n \delta$, namely $\step$.
      Such function $b$ is exactly $\ovverline n \Nat$.
      Now we fix $\delta$ and prove by induction on $n$ that the claim holds
      \begin{itemize}
        \item [0] In this case, by the definition of $\sa$ we know that
        the function returns its first argument.
        \item[$n+1$] The result comes from the conjunction of the $IH$, which
        states that a similar result holds for $n$, with the definition of
        both $\step$ and $\reachesf {n+1} \delta$ which allow us to expand both
        the definitions and extract $\vdash_\delta'$ from one side and $\apply$
        from the other, then by correctness of
        $\apply$ (Lemma \ref{lemma:applyinPOR}), we obtain that the result is
        exactly the expected claim. The possibility to express the function
        $\reachesf{}{}$ of the claim with $vdash_\delta'$, and similarly
        $\step$ with $\apply$, allows us to extend the set $N_n$ of the inductive
        hypothesis with a new entry, namely $k+n+1$, which is not in $N_n$.
      \end{itemize}
    Moreover, the size bound $x_c\oone^6$ is sufficient because at each step
    the new tape is at most two character longer than the original one,
    which become four through the encoding of lists, and the sizes of the two
    tapes grows at most by one, which, encoded, takes 2 other characters.
    \end{proof}

    \begin{lemma}
      $K_\SFP \subseteq \POR$
    \end{lemma}
    \begin{proof}
      Conjunction of Lemmas \ref{lemma:applyinPOR} and \ref{lemma:stepinPOR}.
    \end{proof}
















    \subsubsection{Proof of Proposition \ref{prop:PORimplreach}}


    We would like to re-state Proposition \ref{prop:PORimplreach},
    instantiating some existentials; this way, the IH becomes
    slightly more informative.
    %
    To do so,we ought identify some candidates for the trees
    $t$ and $\overline t$ and to prove that the claim holds for those specific
    trees, in order to introduce the existsntial of
    Proposition \ref{prop:PORimplreach} after the proof by induction.
    %
    For this reason, we introduce the notion of \emph{Canonical Reduction Tree}:
    if we are able to identify a syntactic way to build a Reduction Tree
    for the function $\reachesf n \delta$ and we manage to prove that there is
    a transformation (more precisely a relabeling) which turns this tree $t$
    into $\overline t$ and finally that for $t$ and $\overline t$
    the claim holds, the proof of Propositions \ref{prop:PORimplreach} and
    \ref{prop:PORimplSFP} are almost done.

    \begin{defn}[$n$-deep Complete and Continuous Reduction Tree]
      We say that an \rt A $t$ is an $n$-deep Complete and Continuous
      if and only if
      $\exists n. \ccrt(n)=t$, where $\ccrt$ is defined as below:
      \begin{align*}
        \mathit{addleafs}(\mathit{nil}, l) &:= T\ l\ \mathit{nil}\ \mathit{nil}\\
        \mathit{addleafs}(T\ n\ t_1\ t_2, l) &:= T\ n\ \mathit{addleafs}(t_1, l)\ \mathit{addleafs}(t_2, l)\\
        \ccrt(0) &:= \mathit{nil}\\
        \ccrt(n+1) &:= \mathit{addleafs}(\mathit{ccrt(n)}, n+1)\\
      \end{align*}
    \end{defn}

    \begin{figure}[]
      \begin{tikzpicture}[node distance=2cm]
          \node (a) {$0$};
          \node[below left = 15mm and 22.5mm of a] (b) {$1$};
          \node[below right = 15mm and 22.5mm of a] (c) {$1$};

          \node[below left = 15mm of b] (d) {$2$};
          \node[below right = 15mm of b] (e) {$2$};
          %
          \node[below left = 15mm of c] (f) {$2$};
          \node[below right = 15mm of c] (g) {$2$};


          \draw[->] (a) edge (b);
          \draw[->] (a) edge (c);

          \draw[->] (b) edge (d);
          \draw[->] (b) edge (e);
          %
          \draw[->] (c) edge (f);
          \draw[->] (c) edge (g);

      \end{tikzpicture}
      \caption{Reduction Tree equal to $\ccrt(2)$}
      \label{fig:ccrt2}
    \end{figure}


    These simple Reduction Trees, well represent the access to the random tape of
    any Stream Machine: these machines query their tape on the very first position,
    then they query it on the next position until they reach a configuration on which
    $\delta$ is undefined.
    The function $\reachesf n \delta$ works in a similar
    way: it applies the transition function as long as possible, then, when
    $\delta$ is undefined it halts, namely: the function becomes the identity.
    In this way we can identify an upper bound to the
    Stream Machine's running time and use that bound to identify all the
    possible final configuration reachable by the machine.
    %
    If we prove that $\forall n. ccrt(n)$ is a Reduction Tree for
    $\reachesw^n_\delta$, we can use this kind of Reduction Trees in the proof of
    \ref{prop:PORimplreach}.
    %
    To prove that claim, we need some auxiliary Lemmas: first we need to show that
    only the initial prefix of an oracle tape is able to determine the value
    of the function

    \begin{defn}[Prefix of an Oracle Function]
      For each $\eta: \Nat \longrightarrow \Bool$ and for each $n \in \Nat$,
      $\sigma \in \Ss$,
      $\eta_n=\sigma$ if and only if $\forall i \le n. \eta(i)=\sigma(i)$.
    \end{defn}

    \begin{lemma}[Identity on Prefix]
      \label{lemma:SFPidonprefix}
      $\forall n \in \Nat.
      \forall \eta, \psi \in \Bool^\Nat. \eta_n=\psi_n \to \forall \sigma, q, \tau.
      \langle \sigma , q, \tau, \eta\rangle \reaches n \delta
      \langle \sigma' , q', \tau', \xi\rangle \leftrightarrow
      \langle \sigma , q, \tau, \psi\rangle \reaches n \delta
      \langle \sigma' , q', \tau', \chi\rangle$ for some $\xi$ and $\chi$.
    \end{lemma}
    \begin{proof}
      By induction on $n$:
      \begin{itemize}
        \item [$0$] Trivial.
        \item [$n+1$] The results is a consequence of the IH
        and of the fact that the current state, together with the configuration
        of the tape and the character on the random tape are sufficient to
        determine the next move, if any.
      \end{itemize}
    \end{proof}

    This result scales to $\reachesf n \delta$ and to $\reachesw^n_\delta$, too.

    \begin{lemma}[Identity on Prefix, for $\reachesf n \delta$]
      \label{lemma:SFPidonprefix2}
      $\forall \eta, \psi. \eta_n=\psi_n \to \forall \sigma, q, \tau.
      \langle \sigma , q, \tau, \eta\rangle \reachesf n \delta
      \langle \sigma' , q', \tau', \xi\rangle \leftrightarrow
      \langle \sigma , q, \tau, \psi\rangle \reachesf n \delta
      \langle \sigma' , q', \tau', \chi\rangle$ for some $\xi$ and $\chi$.
    \end{lemma}
    \begin{proof}
      the argument is exactly the same of Lemma \ref{lemma:SFPidonprefix},
      except for the fact that the inductive case takes in account the case where
      if the transition is undefined, too. But in that case the transition is
      undefined for both the configurations, so $\reachesf n \delta$
      is in both cases the identity function.
    \end{proof}

    \begin{lemma}[Identity on Prefix, for $\reachesw^n_\delta$]
      \label{lemma:SFPidonprefix3}
      $\forall \eta, \psi. \eta_n=\psi_n \to \forall \sigma, q, \tau.
      \langle \sigma , q, \tau, \eta\rangle \reachesw^n_\delta
      \langle \sigma' , q', \tau'\rangle \leftrightarrow
      \langle \sigma , q, \tau, \psi\rangle \reachesw^n_\delta
      \langle \sigma' , q', \tau'\rangle$.
    \end{lemma}
    \begin{proof}
      Consequence of the definition of $\reachesw^n_\delta$ and of
      Lemma \ref{lemma:SFPidonprefix2}
    \end{proof}

    Now, we ought lift these observations concerning single oracles to cylinders.
    The first result is a natural extension of Lemma \ref{lemma:SFPidonprefix3}.
    Here, the idea is to leverage the fact that a Stream Machine, in $n$ steps
    queries at most $n$ different coordinates of its tape $\eta$, namely the
    positions in the set$\{0, \ldots, n-1\}$.

    \begin{lemma}
      \label{lemma:auxbsq1}
      If
      \[
              \reachesw^{n}_\delta(\sigma,q, \tau,\bigcap_{i=0}^{n-1} C(i))
      \]
      is a singleton for each $\sigma, q, \tau$ then also
      \[
              \reachesw^{n}_\delta(\sigma,q, \tau,\bigcap_{i=0}^{n} C(i))
      \]
      is a singleton for each $\sigma, q, \tau$.
    \end{lemma}
    \begin{proof}
         At each step, the machine consumes \emph{exactly} a new position on the
         tape, so adding the cylinder $C(n)$ does not affect the value of
         $\reachesw^{0}_\delta(\sigma,q, \tau,\cdot)$, because the cell $n$
         on the tape has not been queried yet, consequence of Lemma \ref{lemma:SFPidonprefix3}.
    \end{proof}

    These observations entail that $\ccrt(n)$ is a Reduction tree for any
    $\reachesw^n_\cdot$ function, namely:

    \begin{lemma}
      $\forall n.\forall \delta.\forall \sigma, q, \tau.ccrt(n) \in \RT{\Nat}
      { \reachesw^n_\delta}{\sigma, q, \tau}$.
    \end{lemma}
    \begin{proof}
      By induction on $n$:
      \begin{itemize}
        \item[$0$] $\ccrt(0)$ is $\mathit{nil}$.
        $\mathit{cylp}(\mathit{nil})=\{\varepsilon\}$.
         %and the only tree which is Structurally identical to $\mathit{nil}$ is $\mathit{nil}$ itself.
        For this reason we need to prove that $\reachesw^0_\delta(
        \sigma, q, \tau, \{\zzero,\oone\}^\Nat)$ is a singleton,
        but that's trivial, because $\forall \eta. \reachesw^0_\delta(
        \sigma, q, \tau, \{\zzero,\oone\}^\Nat)=\langle
        \sigma, q, \tau\rangle$.
        \item[$n+1$]
        We want to show that
        \[
        \reachesw^{n+1}_\delta(\sigma,q, \tau,\bigcap_{i=0}^n C(i)) \text{ is a singleton}
        \]
        knowing that
        \[
        \reachesw^{n}_\delta(\sigma,q, \tau,\bigcap_{i=0}^{n-1} C(i)) \text{ is a singleton}
        \]
        %
        Lemma \ref{lemma:auxbsq1}, states that
        \[
        \reachesw^{n}_\delta(\sigma,q, \tau,\bigcap_{i=0}^{n} C(i))
        \]
        is a singleton, too. Knowing that in $n+1$ steps the machine reads at most
        $n+1$ characters from the oracle $\eta$, we can say that, fixed a path
        we identify a sequence of $n+1$ cylinders throughout $\mathit{cylp}$,
        namely
        $C(0), \ldots, C(n)$. The n-long prefix of $\bigcap_i C(i)$,
        is a singleton, too. Call such prefix $\psi_n$.
        We can also rewrite the claim as:
        \[
        \langle
        \pi_1(\vdash_\delta'(\reachesf n \delta(\langle \sigma, q, \tau, \psi_n\rangle))),
        \pi_2(\vdash_\delta'(\reachesf n \delta(\langle \sigma, q, \tau, \psi_n\rangle))),
        \pi_3(\vdash_\delta'(\reachesf n \delta(\langle \sigma, q, \tau, \psi_n\rangle)))
        \rangle
        \]
        Lemma \ref{lemma:SFPidonprefix2} states, in other words, that since
        $\psi_n$ is a singleton,
        $\vdash_\delta'(\reachesf n \delta(\langle \sigma, q, \tau, \psi\rangle))$
        is a singleton too, so the claim is proved.
      \end{itemize}
    \end{proof}

    Now that we have show that $\ccrt$ is a Reduction Tree for $\reachesw^n_\delta$
    we are allowed to strengthen Proposition \ref{prop:PORimplreach} as follows:

    \begin{prop}
      \label{prop:PORimplreach2}
      For each $\delta: \Qs \times \Sigmab \times \{\zzero, \oone\} \longrightarrow \Qs \times \Sigmab \times \{L,R\}$
      If $x_\delta$ is the encoding of $\delta$ in $\Ss$ obtained through
      the function described in Corollary \ref{cor:deltarepr},
      \[
      f_\delta(x_m, x_\sigma, x_{q_i}, x_\tau,\omega) =
      \step(\listenc {x_\sigma, x_{q_i}, x_\tau, \ovverline 0 \Nat} 4, x_m,
      x_\delta, \omega)
      \]
      %
      is such that for every $n \in \Nat$,  $\sigma \in \Ss$, $q \in \Qs$
      there are two reduction trees\linebreak
      $t =\ccrt(n)$ and
      $\overline t \in \RT{\POR} {f_\delta} {\ovverline n \Nat,\sigma, i_2(q), \tau}$
      such that $\overline t$ is structurally identical to $t$ and
      for every path $C$ in $\mathit{cylp}(t)$,
      the corresponding path $D$ in $\mathit{cylp}(\overline t)$ is such that
      $\pi_i(\reachesw^n_\delta(\langle \sigma, q, \tau, C\rangle)) = \pi_i(\alpha
      (f_\delta(\ovverline n\Nat,\sigma, i_2(q), \tau, D)))$ for $i \in\{1,2,3\}$,
      where $\alpha$ is the inverse of the function $\listenc \cdot 4$ and
      $i_2: q_i \mapsto \ovverline i \Nat$
      is taken from Definition \ref{def:canencs}.
    \end{prop}


    \begin{proof}[Proof of Proposition \ref{prop:PORimplreach2}]
      Lemma \ref{lemma:stepinPOR} states that $\step$ is the counterpart of $\reachesf n \delta$.
      Definition \ref{def:reachcounter} states that there are a bijection
      $b$ and a set $N\subseteq \Nat$ such that
      $\forall n \in N.\forall \eta, \omega.\eta(n)= \omega(g(n))$
      entails that $\step$ and
      $\reachesf n \delta$ produce the same output on appropriate inputs.
      Lemma \ref{lemma:SFPidonprefix2} entails that $\{0, \ldots, n-1\}$
      is an appropriate candidate for $N$, then we can observe that any smaller
      set would draw us in contradiction: for instance think of the
      Stream Machine which
      copies the first $n$ characters of the oracle tape
      on the work tape: a similar result would not hold for prefixes smaller than $n$.
      Moreover, observe that if we re-label the nodes
      of $t$ with their image throughout $b$ we get
      $\overline t$. It's trivial to conclude that $\SI(t, \overline t)$ holds.
      Moreover, to show that $\overline t$ is a Reduction Tree for
      $f_\delta$, it suffices to observe that to each cylinder
      $D$ in $\mathit{cylp}(\overline t)$
      there corresponds a cylinder $C$ in $\mathit{cylp}(t)$
      whose labels are the counter-image of the labels of $C$
      through $b$; we know that $\ccrt(n)$ is a Reduction Tree for
      $\reachesw^n_\delta$, so $\reachesw^n_\delta(\sigma, q, \tau, C)$
      is a singleton and, for Definition \ref{def:reachcounter}
      (Counterpart of $\reachesf n \delta$)
      and Lemma \ref{lemma:stepinPOR},
       the claim holds.
    \end{proof}
    \begin{proof}[Proof of Proposition \ref{prop:PORimplreach}]
      Consequence of Proposition \ref{prop:PORimplreach2},
      introducing some existentials.
    \end{proof}

    \subsubsection{Proof of Proposition \ref{prop:PORimplSFP}}

    At this point, we want to show that Proposition \ref{prop:PORimplSFP} holds, too. Namely that the following claim holds.

    \PORimplSFP*

    We would like to prove \ref{prop:PORimplSFP}
    defining $f_M$ upon $f_\delta$, in order to leverage
    Proposition \ref{prop:PORimplreach2}.

    To do so, need to encode the
    initial Configuration of the machine, part of the work is already
    done (Section \ref{subsub:encodings}), it remains to show
    that the function $\ovverline \cdot \Tapes$ is in $\POR$
    to show, by compositionality that the initial encoding of a
    Machine can be represented by a function in $\POR$,
    given the machine's input $\sigma$.

    \begin{lemma}
      \label{lemma:tencinpor}
      There's a function $f :
      \{\zzero, \oone\}^*\longrightarrow \Ss$ in $\POR$
      such that if $\ovverline \cdot \Tapes$ is the encoding for tapes
      proposed in Corollary \ref{cor:confrepr}, then it holds that
      $\forall \sigma \in \{\zzero, \oone\}^*, \omega. f(\sigma, \omega)=
      \ovverline \sigma\Tapes$.
    \end{lemma}
    \begin{proof}
      Take the function $f$ defined below:
      \begin{align*}
        f(\eepsilon, \omega) &:= \ovverline \circledast\Tapes\\
        f(x\bbool, \omega) &:= \ral(f(x, \omega),\mathtt{if}(\ovverline 1 \Nat,\ovverline 0 \Nat, \bbool, \omega), \omega)|_{x\Df(\oone)\zzero\zzero}
      \end{align*}
      The proof is by induction on $\sigma$:
      \begin{itemize}
        \item[$\eepsilon$] In this case the $f$ coincides
        by definition with $\ovverline \cdot\Tapes$.
        \item[$\tau \bbool$] In this case the claim follows by induction:
        we are basically appending the encoding of $\bbool$ at the end of a List,
        so the claim is obtained from the IH and correctness
        of $\ral$ (Remark \ref{rem:corrlistops}).
      \end{itemize}
    \end{proof}

    Complementarily, while decoding the final configuration of a Canonical Stream
    Machine, we need to extract the longest sequence of $\zzero$ and $\oone$
    on the immediate left of the head by means of a $\POR$ function.
    %
    The existence of such function is stated by the following Lemma.

    \begin{lemma}
      \label{lemma:dectape}
      There's a function $f :
      \Ss \longrightarrow \Ss$ in $\POR$
      such that if $\ovverline \cdot \Tapes$ is the encoding for tapes
      proposed in Corollary \ref{def:canencs}, then it holds that
      $\forall \sigma \in \{\zzero, \oone, \circledast\}^*, \omega.
       f(\ovverline \sigma \Tapes, \omega)=
      \tau$ and $\tau$ is the longest suffix of $\sigma$ without $\circledast$.
    \end{lemma}
    \begin{proof}
      Take the function $\mathit{dectape}$ defined below:
      \begin{align*}
        \rho(t, x, \omega)&:= \pi(t, \mathit{diff}(\pi_0(t, \omega),
        x, \omega), \omega)\\
        \mathit{dectape}'(t, \eepsilon, \omega) &:= \eepsilon\\
        \mathit{dectape}'(t, x\bbool, \omega) &:= \mathtt{if}(
        \mathit{dectape}'(t, x, \omega)\rho(t, x\bbool, \omega),
        \eepsilon, \lnot \eq(\rho(t, x\bbool, \omega),
        \oone\oone\oone, \omega), \omega)\\
        \mathit{dectape}(t, \omega) &:= \mathit{dectape}'(t,
        \rrs(\pi_0(t, \omega), \omega), \omega)
      \end{align*}
      Before proceeding with the correctness of $\mathit{dectape}$, we must prove
      that, if $t$ is the encoding of a tape through $\ovverline \cdot \Tapes$, $x=\ovverline n\Nat$ and $n \le |t|$, $\rho(t, x, \omega)$ returns the $n$-th
      projection of $t$ from the right. This is a consequence of the correctness
      of the functions used in the definition of $\rho$, which has already been shown.
      %
      Before, we ought proof that $\mathit{dectape}'$ is a generalization of dectape,
      for which $x=\ovverline n\Nat \to \ovverline \sigma \Tapes = t \to
      \mathit{dectape}'(t, x, \omega)$ is the longest substring whithout
      $\circledast$ of $\sigma$ which ends in
      the $n$-th character of $\sigma$ from the left.
      The proof of the main claim is by induction on $n$:
      \begin{itemize}
        \item[$0$] According to what we proved above about $\rho$, and the fact the
        function checks the rightmost character of the $\sigma$'s encoding. Moreover,
        the encoding of any encoded $\sigma \in \Sigmab^*$ contains at least one
        charater. if this characteris $\circledast$ its encoding
        is $\oone\oone\oone$, so the condition on the $\mathit{if}$'s guard
        is verified and the whole expression reduces to $\eepsilon$, otherwise
        the function returns the decoding of the remaining part (which reduces
        to $\eepsilon$) and the decoded value of the character in exam.
        \item[$n+1$] The claim follows from the IH on the
        recursive call, ad the condideration above regarding the value of the
        projected character.
      \end{itemize}
    The main claim can be proved by joining the consideration above and the fact
    that the definition of $\mathit{decode}$ is defined as an instance of
    $\mathit{decode}$ with $x$ equal to the size of $\sigma$, so the substring
    returned by $\mathit{decode}'$ is actually a suffix.
    \end{proof}

    \begin{proof}[Proof of Proposition \ref{prop:PORimplSFP}]
      The first thing we show is that for each Polynomial Canonical Stream
      Machine $M:=\langle \Qs,\Sigma, \delta, q_i\rangle$,
      $\RT{\Ss} {\reachesw^{p(|x|)}_\delta}
      {x, q_i, \eepsilon}\subseteq \RT \SFP M x$
       for
      an appropriate $p \in \POLY$.
      Suppose that $t \in \RT{\Ss} {\reachesw^{p(|x|)}_\delta} {x, q_i, \eepsilon}$
      It means that for all $C(x_1), \ldots, C(x_{p(|x|)})\in \mathit{cylp}(t)$
      \[
      \reachesw^{p(|\sigma|)}_\delta(\sigma,q_i, \epsilon,\bigcap_{i=0}^{p(|\sigma|)-1} C(x_i)) \text{ is a singleton}
      \]
      which means that
      \[
      \lambda \eta. \pi_1(\reachesf {p(|\sigma|)} \delta(\langle \sigma,q_i, \epsilon,\eta\rangle))\left(\bigcap_{i=0}^{p(|\sigma|)-1} C(x_i)\right)\text{ is a singleton}
      \]
      The characterization of $\SFP$ (Characterization \ref{char:sfp})
      has as consequence that the value above is equal to $M(\sigma, \left(\bigcap_{i=0}^{p(|\sigma|)-1} C(x_i)\right))$ which proves
      $\RT{\Ss} {\reachesw^{p(|x|)}_\delta} {x, q_i, \eepsilon}\subseteq \RT \SFP M x$
      As consequence we can conclude that $\ccrt(p(|x|))$ is a Reduction Tree for any
      Polynomial Canonical Stream Machine.
      %
      Now take $f_M$ defined as
      %
      \[
        f_M(x, \omega) := \mathit{dectape}(\pi_1(f_\delta(f_p(\mathit{size}(x, \omega),\omega),
        \ovverline x\Tapes, \ovverline i \Nat,
        \ovverline \eepsilon\Tapes, \omega), \omega), \omega)
      \]
      %
      $f_M \in \POR$, because
      %
      \begin{enumerate}
        \item $\POR$ contains the computation of all the polynomials,
        so $\forall M$, there exists a function $f_p\in \POR$ which computes
        the time bound $p\in \POLY$ of $M$.
        \item $\ovverline \cdot \Tapes\in \POR$, because of Lemma
        \ref{lemma:tencinpor}
        \item $\forall n \ovverline n \Nat\in \Ss$.
        \item $\mathit{size}$ can be defined as follows:
        \begin{align*}
        \mathit{size}(\eepsilon, \omega) &:= \oone\\
        \mathit{size}(x\bbool, \omega) &:= \mathit{size}(x, \omega)\oone
      \end{align*}
        \item List projectors are in $\POR$.
      \end{enumerate}
      Proposition \ref{prop:PORimplreach} states that Reduction Tree
      obtained relabeling of the leafs of
      $\ccrt(p(|x|))$ with the function $i \mapsto \ovverline i \Nat$
      (which is the bijection $b$ introduced in Definition 30) is a
      Reduction Tree for $f_\delta$, too.
      Call this object $\overline t$, by definition of $f_M$,
      it is a Reduction Tree for $f_M$, too.
      The fact that $\forall C(x_1), \ldots C(x_{p(|\sigma|)}) \in \mathit{cylp}(t).
      M(\sigma, \bigcap_i C(n_i))=f_M(\sigma, \bigcap_i C(\ovverline {n_i} \Nat))$
      is a consequence of Proposition \ref{prop:PORimplreach}: it states that
      for the cylinders mentioned above it holds that:
      \[
      \reachesw^{p(|x|)}_\delta(\sigma, q_0,\eepsilon, \bigcap_{i=0}^{p(|\sigma|)-1} C(x_i))=
      f_\delta(\ovverline {p(|x|)}\Nat, \sigma, \ovverline 0\Nat, \eepsilon,
       \bigcap_{i=0}^{p(|\sigma|)-1} C(\ovverline {x_i} \Nat) )
      \]
      This fact entails that the longest suffix without $\circledast$ on the first projection of the expression on the left
      (which is $M(\sigma, \omega)$ according to Characterization \ref{char:sfp})
      is equal to the $f_M(\sigma, \omega)$ as a consequence of Lemma
       \ref{lemma:dectape}.
    \end{proof}

    It should not be too much of a problem to see that
    Lemma \ref{lemma:treetomeasure} and Proposition \ref{prop:PORimplSFP} entail
    the followign corollary:

    \begin{cor}
      \label{cor:SFPtoPOR}
      $\forall M \in \SFP \exists f_M \in \POR.$
      $$
      \forall x, y.
                    \mu\left(\{\eta \in \Bool^\Nat| M(x, \eta)= y\}\right)=
                    \mu\left(\{\omega \in \Bool^\Ss| f_M(x, \omega)= y\}\right)
      $$
    \end{cor}

    Such result confirms part of Conjecture \ref{conj:SFP}.









\end{conditional}














































%% SUBSECTION
%% From POR-functions to SFP-machines
\subsection{From $\POR$-functions
to $\SFP$}\label{sec:PORtoSFP}

In this section we will give the reduction from $\POR$ to $\SFP$.
The biggest issue of this reduction concernes the different ways adopted by
$\POR$ and $\SFP$ to access randomness.
In particular, the $\POR$ formalism includes the function
$Q(x, \omega) := \omega(x)$.
This means that the
coordinate $x$ used to access the oracle
can be the output of any $\POR$ function. From now on,
we will call this modality \emph{random access to the oracle}.
Conversely, the Stream Machine's foralism accesses randomness in a linear way:
at each transition a new cell of the oracle $\eta$ is consumed and the value
at that coordinate is used to determine the next configuration reached by the
machine.
This means that a $\SFP$ machine can explore at most a polynomial number
of coordinates of its oracle $\eta$; from now on we will call this modality
\emph{linear access to the oracle}.

This differencce makes the encoding from $\POR$ to $\SFP$
non-trivial. This is due to the fact that, fixed $\omega$, the output of the
$\POR$ function $Q(x, \omega)$ depends on
exactly $2^{|x|}$ values of $\omega$, and that
there is not a natural counterpart of $Q$ in $\SFP$ with this property.
This is trivial
because of the polynomial bound of $\SFP$. This entails that any
encoding from $\POR$ to the Stream Machine
formalism cannot preserve the random access to
the oracle within a polynomial number of steps.

For this reason we will need to encode in our reduction a mechanism which allows
to simulate \emph{random access to the oracle} in a formalism which does nt.
We achieved this result implementing a sort of \emph{associative table}, which
records each queried coordinate and the random answer given
the first time this particular coordinate was queried. To do so, and to show it
formally, we will introduce an intermediate formalism, the $\SIFP$, and we will
decline it into two variants: $\SIFPRA$ and $\SIFPLA$. The first is equivalent to
$\POR$ and is characterized by a fully random access to the oracle $\omega$,
whilst the second supports a linear and \emph{on-demand} access to randomness,
which means that the programmer has a partial control on the queried coordinate.
In particular, $\SIFPLA$ programs use oracle
functions $\eta: \Nat \longrightarrow \Bool$ which are explored consecutively,
starting from the coordinte $0$.
%
Once reduced $\POR$ to $\SIFPLA$, we will introduce an \emph{on-demand} variant
of $\SFP$, namely $\SFPOD$ which will be used as a sort of bridge between $\SIFPLA$
and $\SFP$.

The introduction of these many intermediate formalisms is aimed
to solve all the different issues of the complete reduction in a different
sub-reduction. For example, it wolud be possible to encode directly
$\POR$ in the Stream Machine formalism,
but this would cause the proof to become unnecessairly complex.
It would deal with the time-complexity of $\POR$ functions, the simulation
of the random access to the oracle function and the probability of each input-output
pair.

Conversely, our approach allows us to address one specific problem per formalism, namely:

\begin{itemize}
  \item We address the problem of introducing a
  cost model for $\POR$ when we reduce it to $\SIFPRA$.
  \item We show the equivalence between random access to
  the oracle and linear access when we encode $\SIFPRA$ in $\SIFPLA$.
\end{itemize}

Moreover the othe other steps of our reduction will not be too complex because:

\begin{itemize}
  \item We can employ a canonical reduction from an imperative formalism to
  a Turing machine when we reduce $\SIFPLA$ to multitape Stream Machines
  \item We can adapt some well knonwn equivalence to reduce the number of tapes
  of a Stream Machine with a polynomial overhead.
\end{itemize}




















\subsubsection{The $\SIFPRA$ formalism}
\label{subsub:portosifpra}
In this section we will define the $\SIFPRA$ formalism as a syntactic subset of $\SIFP$,
together with its syntax and its operational semantics. Later we will show that
the $\POR$ functions can be encoded by means of \emph{poly-time} $\SIFPRA$ programs.
In particular, we will show that $\POR \subseteq \text{poly-time }\SIFPRA$.
%
Formally, The $\SIFPRA$ paradigm is defined by an enumerable set
of correct programs and an operational semantics.

\begin{defn}[Correct programs of $\SIFP$]
  \label{def:sifp}
The language of $\SIFP$ programs is $\lang{\stm}$, i.e.
the set of strings produced by the non-terminal symbol $\stm$ defined by:
%
\begin{align*}
\id &\Coloneqq X_i\ |\ Y_i\ |\ S_i\ |\ R\ |\ Q\ |\ Z\ |\ T\qquad i \in \Nat\\
\xp &\Coloneqq \epsilon\ |\ \xp.\zero\ |\ \xp.\one\ |\ \id\ |\ \xp \sqsubseteq \id\ |\ \xp \land \id\ |\ \lnot \xp\\
\stm_\RA & \Coloneqq \id \takes \xp\ |\ \stm_\RA;\stm_\RA\ |\ \while \xp \stm_\RA\ |\ \fl \xp\\\
\stm_\LA & \Coloneqq \id \takes \xp\ |\ \stm_\LA;\stm_\LA\ |\ \while \xp \stm_\LA\ |\ \rb\\
\stm & \Coloneqq \id \takes \xp\ |\ \stm;\stm\ |\ \while \xp \stm_\RA\ |\ \fl \xp\ |\ \rb\ |\ \fl\xp
\end{align*}
\end{defn}

\begin{notation}
  We suppose $\cdot;\cdot$ to be \emph{right associative}.
\end{notation}

On top of this grammar, we define the notion of $\SIFPRA$ program, too.

\begin{defn}[$\SIFPRA$]
  The language of the $\SIFPRA$ programs is $\lang{\stm_\RA}$, i.e. the set of strings produced by the non-terminal symbol $\stm_\RA$ described in Definition \ref{def:sifp}.
\end{defn}

\begin{notation}[$Id$]
  We will denote with $Id$ either a generical $Id$
  --- especially when writing programs --- and the set of all the possibles register
  identificators.
\end{notation}

From now on, if we show that a certain result holds for $\SIFP$, we mean that it
holds for both $\SIFPRA$ and $\SIFPLA$. It is not true that \emph{any}
results which holds for $\SIFPRA$ holds for $\SIFPLA$, too. But, for instance,
when dealing with some combinatorial results concerning $\lang\xp$,
proving results for both the languages turns out to be useful.
%
The $\SIFP$ formalism is defined following the approach
adopted by Winskel in \cite{winskel1993formal} for the definition of IMP.
%
Even the operational semantics of $\SIFPRA$ is defined following such work.
We start by defining the notion of \emph{Store}: a partial function which
associates to each register its value.

\begin{defn}[Store]
A store is a function $\store: \id \rightharpoonup \{\zero, \one\}^*$.
\end{defn}

\begin{defn}[Empty store]
An \emph{empty} store is a store which is total and constant on $\epsilon$. We represent such object with $[]$.
\end{defn}

The reason why we want a store to be total rather than undefined on all registers
is because it allows us to back-up the content of some registers even if
those haven't been assigned to any expression.

\begin{defn}[Store updating]
We define the updating of a store $\store$ with a mapping from $y \in \id$ to $\tau \in \{\zero, \one\}^*$ as:
\[
\store[y\leftarrow \tau](x) \coloneqq \begin{cases} \tau & \text{if } x = y\\ \store(x) & \text{otherwise}\end{cases}
\]

\end{defn}

The notion of \emph{Store} allows us to define the semantics of
a $\SIFPRA$ program as function which maps a pair $\langle \store,\omega\rangle$
to another store.
%
The semantics of the expression is the same for $\SIFPRA$ and $\SIFPLA$;
differently, the semantics of the programs changes from $\SIFPRA$ to $\SIFPLA$.
This is why we are defining a \emph{Semantics of $\SIFP$ expressions} and an
\emph{Operational semantics of $\SIFPRA$} instead of an
\emph{Operational semantics of $\SIFP$}.

\begin{defn}[Semantics of $\SIFP$ expressions]
The semantics of an expression $E \in \lang{\xp}$ is the smallest function $\sred: \lang{\xp} \times (\id \longrightarrow \{\zero, \one\}^*)\times \Os \longrightarrow \{\zero, \one\}^*$ closed under the following rules:
\begin{center}
\vspace{12pt}
\AxiomC{\phantom{$\langle \epsilon, \store\rangle \sred \epsilon$}}
\UnaryInfC{$\langle \epsilon, \store\rangle \sred \epsilon$}
\DisplayProof
\hspace{18pt}
\AxiomC{$\langle e, \store \rangle \sred \sigma$}
\UnaryInfC{$\langle e.\zero, \store\rangle \sred \sigma \conc \zero$}
\DisplayProof
\hspace{18pt}
\AxiomC{$\langle e, \store \rangle \sred \sigma$}
\UnaryInfC{$\langle e.\one, \store\rangle \sred \sigma \conc \one$}
\DisplayProof

\vspace{12pt}
\AxiomC{$\langle e, \store \rangle \sred \sigma$}
\AxiomC{$\store(Id) = \tau$}
\AxiomC{$\sigma \subseteq \tau$}
\TrinaryInfC{$\langle e \sqsubseteq Id, \store\rangle \sred \one$}
\DisplayProof
\hspace{18pt}
\AxiomC{$\langle e, \store \rangle \sred \sigma$}
\AxiomC{$\store(Id) = \tau$}
\AxiomC{$\sigma \not\subseteq \tau$}
\TrinaryInfC{$\langle e \sqsubseteq Id, \store\rangle \sred \zero$}
\DisplayProof

\vspace{12pt}
\AxiomC{$\store(Id)=\sigma$}
\UnaryInfC{$\langle Id, \store\rangle \sred \sigma$}
\DisplayProof

\vspace{12pt}
\AxiomC{$\langle e, \store \rangle \sred \zero$}
\UnaryInfC{$\langle \lnot e, \store\rangle \sred \one$}
\DisplayProof
\hspace{18pt}
\AxiomC{$\langle e, \store \rangle \sred \sigma$}
\AxiomC{$\sigma \neq \zero$}
\BinaryInfC{$\langle \lnot e, \store\rangle \sred \zero$}
\DisplayProof

\vspace{12pt}
\AxiomC{$\langle e, \store \rangle \sred \one$}
\AxiomC{$\store(Id) = \one$}
\BinaryInfC{$\langle e \land Id, \store\rangle \sred \one$}
\DisplayProof
\hspace{18pt}
\AxiomC{$\langle e, \store \rangle \sred \sigma$}
\AxiomC{$\store(Id) = \tau$}
\AxiomC{$\sigma \neq \one \land \tau \neq \one$}
\TrinaryInfC{$\langle e \land Id, \store \rangle \sred \zero$}
\DisplayProof
\hspace{18pt}

\end{center}
\end{defn}

% The first reduction we will be involved with will be the one from $\POR$ to $\SIFPRA$. For this reason, we focus on that specific formalism defining its operational semantics and the notion of function computed by a $\SIFPRA$ program. Only later, we will introduce the operational semantics of the $\SIFPRA$ variant of $\SIFP$ together with the notion of function fomputed by a program of such foralism.

\begin{defn}[Operational semantics of $\SIFPRA$]
  \label{def:sifpraos}
The semantics of a program $P \in \lang{\stm_\RA}$ is the smallest function $\ssos: \lang{\stm_\RA} \times (\id \longrightarrow \{\zero, \one\}^*)\times \Os\longrightarrow (\id \longrightarrow \{\zero, \one\}^*)$ closed under the following rules:
\begin{center}
% \vspace{12pt}
% \AxiomC{$\phantom{\langle \sk, \store\rangle \ssos \store}$}
% \UnaryInfC{${\langle \sk, \store, \omega\rangle \ssos \store}$}
% \DisplayProof
% \hspace{18pt}
\AxiomC{$\langle e, \store\rangle\sred \sigma$}
\UnaryInfC{$\langle Id\takes e, \store, \omega\rangle \ssos \store\as {Id}{\sigma}$}
\DisplayProof
\hspace{18pt}
\AxiomC{$\langle s, \store, \omega\rangle\ssos \store'$}
\AxiomC{$\langle t, \store', \omega\rangle\ssos \store''$}
\BinaryInfC{$\langle s;t, \store, \omega\rangle \ssos \store''$}
\DisplayProof

\vspace{12pt}
\AxiomC{$\langle e, \store\rangle\sred \one$}
\AxiomC{$\langle s, \store, \omega\rangle\ssos \store'$}
\AxiomC{$\langle \while e s, \store', \omega\rangle\ssos \store''$}
\TrinaryInfC{$\langle \while e s, \store, \omega\rangle \ssos \store''$}
\DisplayProof
\hspace{18pt}
\AxiomC{$\langle e, \store\rangle\sred \sigma$}
\AxiomC{$\sigma \neq \one$}
\BinaryInfC{$\langle \while e s, \store, \omega\rangle \ssos \store$}
\DisplayProof

\vspace{12pt}
\AxiomC{$\langle e, \store\rangle \sred \sigma$}
\AxiomC{$\omega(\sigma)=b$}
\BinaryInfC{$\langle \fl e, \store, \omega\rangle \ssos \store[R \leftarrow b]$}
\DisplayProof

\end{center}
\end{defn}

We can associate a value to each $\SIFPRA$ program simply by looking at
the value which is stored in a specific register at the end of the computation.
That specific register is $R$.

\begin{defn}[Function evaluated by a $\SIFPRA$ program]
  \label{def:simprafuneval}
We say that the function evaluated by a correct $\SIFPRA$ program $P$ is $\mathcal \llbracket P\rrbracket: \lang{Stm} \longrightarrow (\Ss^n \times \Os \longrightarrow \Ss)$, defined as below\footnote{Instead of the infixed notation for $\ssos$, we will use its prefixed notation. So, the notation express the store associated to the $P$, $\Sigma$ and $\omega$ by $\ssos$.}:
\[
\llbracket P\rrbracket\coloneqq \lambda x_1, \ldots, x_n, \omega.\ssos(\langle P, []\as {X_1} {x_1}, \ldots, \as {X_n} {x_n}, \omega\rangle)(R)
\]
\end{defn}


Before showing that all the $\POR$ functions can be computed by a poly-time
$P \in \SIFPRA$, we introduce some notation in order to increase
the proof's readability. These abbreviations will be adopted for $\SIFPLA$, too.

% \begin{notation}
%   Writing a $\SIFP$ program, we will sometimes use expressions which use binary operators without paying attention to the fact
% \end{notation}
%
% \begin{notation}
% Writing a $\SIFP$ program, we use the notation $E = F$ as a shorthand (syntactic sugar) for $E \sqsubseteq F \land F \sqsubseteq E$.
% \end{notation}
%
% \begin{notation}
% Writing a $\SIFP$ program, we use the notation $E \neq F$ as a shorthand (syntactic sugar) for $\lnot (E \sqsubseteq F \land F \sqsubseteq E)$.
% \end{notation}
%
\begin{notation}
Writing a $\SIFP$ program, we use the notation $E \sqsubset F$ as a shorthand (syntactic sugar) for $\lnot (F \sqsubseteq E)$.
\end{notation}

The notation above may be handeled with care: it is a simplification. Indeed it
does not hold that if a string $\sigma$ is not a weak prefx of another string $\tau$
it is a strong subprefix $\tau$, but when we employ the shorthand $E \sqsubset F$
writing our reduction, we always work under the invariant that $E$ is a prefix of $F$.
%
We can show that, in those cases, the semantics of the expression behaves as expected.

\begin{remark}
  $E \subseteq F \to (E \subset F) \leftrightarrow \lnot (F \subseteq E)$
\end{remark}
\begin{proof}
  Suppose $E\subseteq F$. Suppose that $\lnot (F \subseteq E)$, this entails $\lnot (F=E)$ which is equivalent to $\lnot (E=F)$, together with $E\subseteq F$, we get $E \subset F$.
  Suppose $E \subset F$ and $F \subseteq E$, we get that $E \subset F$ and $F \subset E$ from transitivity we get $E \subset E$, which is absurd.
\end{proof}

\begin{notation}
\label{remark:if}
Writing a $\SIFP$ program, we the notation
\begin{align*}
&\quad\If {c} {\\
&\quad\stm;\\
&\quad}\\
\end{align*}
for representing:
\begin{align*}
&B \takes \epsilon.\one; \\
&\quad\while {c \land B} {\\
&\quad\stm;\\
&\quad B \takes \epsilon.\zero\\
&\quad}\\
\end{align*}
It's indeed true that
\begin{itemize}
\item The statement $\stm$ is executed if and only if $c$ holds.
\item The statement $\stm$ is executed only once.
\end{itemize}
\end{notation}

\begin{notation}[pseudo-procedeure]
A pseudo-procedure is a syntactic sugar for the $\SIFP$'s language, which consists in a \emph{pseudo-procedure's name}, a \emph{body} a list of \emph{formal parameters}. A call to such expression must be interpreted as the inlining of the pseudo-procedure's body in the place of the call in which the names of the formal parameters by the actual parameters and all the \emph{free} names of the body are substituted by fresh names.
\end{notation}

Pseudoprocedures allow us to factorize pieces of code and represent
programs in a conscise way, but they have nothing to do with actual
procedures and calls.
Indeed, as we have shown, the $\SIFP$ formalism doesn't contain
any notion of function and callable object.

Before getting into the actual reduction, we need to face some preliminar
work.
%
In particular, we found some issues encodning $\POR$'s
bounded recursive funcitons in $\SIFP$:
these are defined upon three functions ($h_0, h_1, g \in \POR$) and
a term $t \in \Lpw$, which is used as a size bound to the terms obtained
from $h_0$ and $h_1$.
Basically, this bound guarantees that all the $\POR$
functions are polynomially bounded (in time and size,
according to Lemma \ref{lemma:size}).
For this reason,
we show that we can express the size bound $t \in \Lpw$
by means of an expression
of $\SIFP$, i.e. a production of $\lang{\xp}$.
%
The polynomial complexity of the $\POR$'s encoding in
$\SIFPRA$ relies two other results:

\begin{itemize}
  \item $\POR$ terms have polynomial size in the size of their variables,
  which will be proved in Lemma \ref{lemma:size}, as we mentioned above.
  \item $\Lpw$ terms have polynomial size in the size of their variables,
  which will be proved in Lemma \ref{lemma:sizeofterms}.
\end{itemize}

For this reason, if we want to show that all the $\POR$
functions can be represented by means of \emph{poly-time} $\SIFPRA$ programs,
we must preliminarly show the following results.

%%% Lemma
%%% lemma:size
\begin{lemma}\label{lemma:size}
The size of a term in $\Lpw$ is poynomial in the size
of its variables.
\end{lemma}
% Proof
\begin{proof}
The proof is by induction on the production of the term.
\begin{itemize}
%
\item If the term is a digit or the empty string, it has no variable and its size is
$1$, which is a constant.
All constants are polynomials with no variables, so the claim is proved.
%
\item If the term is a variable, its size consists in the size of
its variable, which is a polynomial in the size of the variables of the term.
%
\item If the term is the concatenation
of two terms $t\conc s$, its size is the sum of the sizes of
its sub-terms, which are polynomials by IH.
Since the sum of polynomials is still polynomial, the union
of the variables of $t$ and $s$ is polynomial in its turn.
%
\item If the term is the product of two terms
$t\times s$, the size of $s$ is a polynomial $p_s$ in
the size of the variables in $s$, and the size of
$t$ is still polynomial $p_t$ in the size of
the variables in $t$.
Hence, the size of the term $t\times s$
is given by $p_tp_s$, which is polynomial
in the size of the variables in $t\times s$.
\end{itemize}
\end{proof}

This result can be leveraged to prove the inductive case of the analogous
result for $\POR$ terms.

%%% Lemma
\begin{lemma}\label{lemma:sizeofterms}
For each $f\in \POR$, the following holds:
$$
\forall x_1,\dots,x_n.\forall \omega.\exists p\in \POLY
\big(f(x_1,\dots, x_n,\omega)| \leq p(|x_1|,\dots, |x_n|\big).
$$
\end{lemma}
\begin{proof}
The proof is by induction on the structure of $f\in \POR$. Base cases:
\begin{itemize}
\item if $f$ is $E$, we introduce the the constant $1$.
%
\item If $f$ is $P_i$ we introduce the polynomial
$\sum^n_{i=0}|x_i|+1$.
It is easy to see that such value is greater or
equal than the size of each input.\footnote{Actually,
we are overkilling the bound: introducing the polynomial
$|x_i|$ for each
$P^n_i$ would have been sufficient.}
%
\item If $f$ is $\Cf$, we introduce the
constant $1$.
%
\item If $f$ is $\Sf_0$ or $\Sf_1$, we introduce the
polynomial $|x|+1$.
%
\item If $f$ is $\query$, we introduce the constant
$1$.
\end{itemize}
Inductive cases:
\begin{itemize}
\item Composition. By IH
$$
\forall 1\leq i\leq k.\exists p_i\in \POLY(h_i(x_1,\dots, x_n,\omega)|
\leq p_i(|x_1|,\dots, |x_n|)\big).
$$
So, a similar bound $q$ exists for the external
function $f$. the composition of $q$
with the sequence of polynomials $p_i$ is
still a polynomial and bounds the size of the composition
of the function by IH.
%
\item Bounded Recursion.
By IH the size of $g$ is bounded by a polynomial
$p_g$ in its inputs. Moreover, the size of the value computed
by $f$ in the inductive cases is polynomial in its input, as
it is truncated to the size of a term in $\Lpw$,
whose size is polynomial in its variables
(that are the inputs of $f$), by Lemma~\ref{lemma:size}.
Call this polynomial $p_t$. We introduce the polynomial $p_g+p_t$
Then, we proceed on induction
on the length of the string $\tau$ that is passed as recursion bound.
If such string has length $0$, it is
$\eepsilon$.
So, the function $f$ coincides with $g$,
and the size of its ouput is smaller than $p_g$ for induction hypothesis.
Otherwise, the size of the value computed
by $f$ is polynomial in its input, as
it is truncated to the size of a $t \in \Lpw$,
whose size is smaller than $p_t$ by induction hypothesis
\end{itemize}
\end{proof}

Thanks to these results, we can step to the Term Representation Lemma in $\SIFPRA$.
As we mentione before, such result is necessary to show that
the bounded recursion schema can be encoded in $\SIFPRA$


\begin{lemma}[Term representation in $\SIFPRA$]
  \label{lemma:lpwtermsifp}
All the terms of $\Lpw$ can be represented in $\SIFPRA$. Formally: $\forall t \in \Lpw. \exists \MM\in \lang{\stm}. Vars(t)=\{x_1, \ldots, x_n\} \to \MM(x_1, \ldots, x_n)= t(x_1, \ldots, x_n)$
\end{lemma}

Before showing the proof of Lemma \ref{lemma:lpwtermsifp}, we need to prove some
intermediate results, which will simplify the proof. In particular,
for sake of readability, we define the pseudo-procedures $\copyb$ which copies
the $|Z|$-th bit of $S$ at the end of $R$,
given that $Z$ contains the $|Z|$-th prefix of $S$, and prove its correctness
and its complexity.
%
Moreover, the definiton of this siple program will help us in showing
to the readet the schema which we use to prove that a certain program is
--- or is part of --- the encoding of some $\POR$ functions in
$\SIFPRA$ or $\SIFPLA$:

\begin{itemize}
  \item We define the encoding.
  \item We prove the correctness of such encoding with respect to some invariant
  properties.
  \item We show that the complexity of such program is polynomial in time.
  This kind of results are proved referring to the cost model described
  in Definition \ref{def:sifpcost}.
  We delayed the formal definition of $\SIFPRA$'s cost model,
  because it depends on a step-semantics which
  would require too much effort for being introduced in this section.
  Conversely,
  \ref{subsub:sifpratosifpla} we introduce a step semantics for
  $\SIFPLA$ and $\SIFPLA$ in Section, so we get a formal
  cost model for both the languages for free.
  Anyway, the complexity result we will prove in this section are
  simple and the reader can apply to $\SIFPRA$ the canonical cost model for
  imperative formalisms, assuming that $\fl{e}$ has complexity $O(1)$.
\end{itemize}

\begin{defn}[$\copyb$ preusdo-procedure]
  \label{def:copyb}
  \begin{align*}
  \copyb (Z, S, R)&\coloneqq  \If{Z.0 \sqsubseteq S}{\\
  & \quad Z \takes Z.\zero;\\
  & \quad R \takes R.\zero;\\
  & }\\
  & \If{Z.1 \sqsubseteq S}{\\
  & \quad Z \takes Z.\one;\\
  & \quad R \takes R.\one;\\
  & }\\
  \end{align*}
\end{defn}

\begin{lemma}[Complexity of $\copyb$]
\label{lemma:compcopyb}
The pseudo-procedure $\copyb$ requires a number of steps which is a
polynomial in the sizes of its arguments with respect to Definition \ref{def:sifpcost}.
\end{lemma}

\begin{proof}
The two $\If \ \ $s are described in Remark \ref{remark:if},
 and they cause no iteration. Moreover,
 the two statements are mutually exclusive,
 so this pseudo-procedure requires at most 5 steps.
\end{proof}

\begin{lemma}[Correctness of $\copyb$]
\label{lemma:corrcopyb}
After an execution of $\copyb$:
\begin{itemize}
\item If the first argument is a strong prefix of the second,
the size of the first argument ($Z$) increases by one,
and is still a prefix of the second argument ($S$).
\item Otherwise, the values stored in the first two registers don't change.
\item Each bit which is stored at the end of $Z$ is stored at the end of $R$.
\end{itemize}
\end{lemma}

\begin{proof}
Suppose that the value stored in $Z$ is a strong prefix of the value which is stored in $S$. Clearly it's true that $Z.\zero \sqsubseteq S \lor Z.\one\sqsubseteq S$. In both case $\copyb$ increases the length of the portion of $Z$ which is a prefix of $S$. If $Z$ is not a prefix of $S$ none of the two $\mathtt{if}$s is executed. The last conclusion comes from the observation that each assignment to $Z$ is followed by a similar assignment to $R$.
\end{proof}

\begin{proof}[Proof of Lemma \ref{lemma:lpwtermsifp} ]
We proceed by induction on the syntax of $t$. The correctness of such implementation is given by the following invariant properties:
\begin{itemize}
\item The result of the computation is stored in $R$.
\item The inputs are stored in the registers of the group $X$.
\item The function $\MM$ doesn't write the values it accesses as input.
\end{itemize}

$\MM$ is defined as follows:
\begin{itemize}
\item $\MM(\epsilon)\coloneqq R \takes \epsilon ;$
\item $\MM(\zero)\coloneqq R \takes \epsilon.\zero ;$
\item $\MM(\one)\coloneqq R \takes \epsilon.\one ;$
\item $\MM(Id)\coloneqq R \takes Id ;$
\end{itemize}

This pseudo-procedure $\copyb$ turns out to be useful in both the encodings of $\conc$ and $\times$. For the $\conc$ operator, we proceed with the following encoding:

\begin{align*}
\MM(t \conc s)\coloneqq &\MM(s)\\
& S \takes R;\\
& \MM(t)\\
& Z \takes \epsilon; \\
& \while {Z \sqsubset S}{\\
& \quad \copyb(Z, S, R)\\
& \quad }\\
\end{align*}

The correctness of $\MM(t \conc s)$ is a consequence of the correctness of $\copyb$.

The encoding of the $\times$ operator is the following:

\begin{align*}
\MM(t \times s)\coloneqq &
\MM(t)\\
& T \takes R;\\
& \MM(s)\\
& S \takes R;\\
& Z \takes \epsilon;\\
& R \takes \epsilon;\\
& Q \takes \epsilon;\\
& \while {Z \sqsubset S} { \\
& \quad \If{Z.\zero \sqsubseteq S} {\\
& \quad \quad Z \takes Z.\zero;\\
& \quad \quad \while {Q \sqsubset T} {\\
& \quad \quad \quad \copyb(Q, T, R)\\
%& \quad \quad \quad B \takes \epsilon.\zero;\\
& \quad \quad \quad }\\
& \quad \quad Q \takes \epsilon;\\
& \quad \quad }\\
& \quad \If{Z.\one \sqsubseteq S} {\\
& \quad \quad Z \takes Z.\one;\\
& \quad \quad \while {Q \sqsubset T} {\\
& \quad \quad \quad \copyb(Q, T, R)\\
%& \quad \quad \quad B \takes \epsilon.\zero;\\
& \quad \quad \quad }\\
& \quad \quad Q \takes \epsilon;\\
& \quad \quad }\\
%& \quad B \coloneqq 0\\
& \quad }
\end{align*}

This program is correct because because of the IH
and the correctness of $\copyb$, which has been
proved in Lemma \ref{lemma:corrcopyb}: the procedure, basically, matches $s$,
by writing in the $Z$ register its prefixes. At each cycle
a new character is added to the $Z$ register and
the content of $T$ ($t$ according to the IH) is added in $R$;
this process is repeated until it is equal to $S$.
\end{proof}

\begin{lemma}[Complexity of $\MM$]
\label{lemma:compmm}
$\forall t \in \Lpw. \MM(t)$ can be computed in number of steps which is polynomial in the size of the variables in $t$ with respect to Definition \ref{def:sifpcost}.
\end{lemma}

\begin{proof}
We proceed by induction on the syntax of $t$.
\begin{itemize}
\item[$\epsilon$] If the term is $\epsilon$, $\MM(t)$ consists in two steps.
\item[$\zero,\one$] If the term is a digit,  $\MM(t)$ consists in two steps.
\item[$x$] If the term is a variable, $\MM(t)$ consists in two steps.
\item[$t \conc s$] From the Lemmas \ref{lemma:corrcopyb} and \ref{lemma:compcopyb} we know that $\copyb$ requires a constant number of steps, and that each time $\copyb$ is executed, $Z$ grows by one. Moreover, we know that the function respects the fact that $Z$ is a prefix of $S$. For this reason, the complexity of the $\while\ \ $ statement is linear in the size of $Z$. Finally, the complexity takes in account two polynomial due the recursive hypothesis on $\MM$ and two steps for the two assignments before the $\while\ \ $. The overall sum of these complexities is still a polynomial.
\item[$t \times s$] We will distinguish the three levels of $\while\ \ $s by calling them \emph{outer}, \emph{middle} and \emph{inner}. For Lemmas \ref{lemma:compcopyb} and \ref{lemma:corrcopyb}, the inner $\while\ \ $s take at most $|T|$ steps, such value is a polynomial over the free variables of $t$ according to Lemma \ref{lemma:sizeofterms} and the induction hypothesis. The value of $T$ remains constant after its first assignment, for this reason all the inner cycles require a polynomial number of steps. The middle cycles, are an implementation of the $\mathtt{if}$ construct according to Remark \ref{remark:if}, so they are executed only once per each outer cycle. Moreover, they add a constant number of steps to the complexity of the inner cycles. This means that, modulo an outer cycle, the complexity is still polynomial. For the same argument of Lemma \ref{lemma:compcopyb}, the outer cycle takes at most $|S|$ steps which is a polynomial according to \ref{lemma:sizeofterms} and the induction hypothesis.
\end{itemize}
\end{proof}

Up to now we have shown that the terms of $\Lpw$ can be represented
by means of polynomial $\SIFP$ expressions: as we mentioned above, this is
fundamental fof showing that the bounded recursion schema can be implemented in
$\SIFPRA$. At this point, All the preliminar work for the main result of this section
has been accomplished, so we can state it formally.


\begin{lemma}[Implementation of $\POR$ in $\SIFPRA$]
\label{lemma:portosifp}
$\forall f \in \POR.\exists P\in \lang {Stm_\RA}.\\\forall x_1, \ldots x_n.
\llbracket P\rrbracket(x_1, \ldots, x_n, \omega)=f(x_1, \ldots, x_n, \omega)$.
Moreover, if $f$ is defined whitout using $Q$,
then $\LL{f}$ does not contain any $\fl e$ statement.
\end{lemma}

The reader may observe that the statement contains two calims: one concerning the
correctness of the translation and another concerning \emph{the shape}
of the tranlation. The second result may appear superflous. Indeed,
it is unnecessairy with respect to the reduction from $\POR$ to $\SIFPRA$, but
it will be used later -- precisely in Corollary \ref{cor:trivportosifpla}
to show that certain $\POR$ funcions are in $\SIFPLA$, too.
%
Before showing the coplete proof of Lemma \ref{lemma:portosifp}, we define
a pseudo-procedure which will be useful for the inductive case of the bounded
recursion.
%
Such piece of code basically truncates the content of a register to the length
of the value which is stored in another register. This operation takes place
after each recursive call in the induction schema and is the counterpart of the
$\cdot |_{t}$ opreation on $\Lpw$ terms.

\begin{defn}[Truncating pseudo-procedure]
  \label{def:trunc}
The $\trunc(T, R)$ pseudo-procedure is a $\SIFP$ program with free names $T$ and $R$, defined as follows:

\begin{comment}
\begin{align*}
trunc(T, R) \coloneqq &Q \takes R;\\
                      &R \takes \epsilon;\\
                      &Z \takes \epsilon;\\
                      &\while {Z \sqsubset T} {\\
                      &\quad B \takes \one;\\
                      &\quad \while {Z.\zero \sqsubseteq T \land B} {\\
                      &\quad \quad B \takes \one;\\
                      &\quad \quad \while {R.\zero \sqsubseteq Q \land B} {\\
                      &\quad \quad \quad R \takes R.\zero;\\
                      &\quad \quad \quad B \takes \zero;\\
                      &\quad \quad \quad }\\
                      &\quad \quad \while {R.\one \sqsubseteq Q \land B} {\\
                      &\quad \quad \quad R \takes R.\one;\\
                      &\quad \quad \quad B \takes \zero;\\
                      &\quad \quad \quad }\\
                      &\quad \quad Z \takes Z.0;\\
                      &\quad \quad B \takes 0;\\
                      &\quad \quad }\\
                      &\quad \while {Z.\one \sqsubseteq T \land B} {\\
                      &\quad \quad B \takes \one;\\
                      &\quad \quad \while {R.\zero \sqsubseteq Q \land B} {\\
                      &\quad \quad \quad R \takes R.\zero;\\
                      &\quad \quad \quad B \takes \zero;\\
                      &\quad \quad \quad }\\
                      &\quad \quad \while {R.\one \sqsubseteq Q \land B} {\\
                      &\quad \quad \quad R \takes R.\one;\\
                      &\quad \quad \quad B \takes \zero;\\
                      &\quad \quad \quad }\\
                      &\quad \quad Z \takes Z.0;\\
                      &\quad \quad B \takes 0;\\
                      &\quad \quad }\\
                      &}
\end{align*}
\end{comment}
\begin{align*}
\trunc(T, R) \coloneqq &Q \takes R;\\
                      &R \takes \epsilon;\\
                      &Z \takes \epsilon;\\
                      &Y_0 \takes \epsilon;\\
                      &\while {Z \sqsubset T} {\\
                      &\quad \If {Z.\zero \sqsubseteq T} {\\
                      &\quad \quad \copyb(R, Q, Y_0)\\
                      &\quad \quad Z \takes Z.\zero;\\
                      &\quad \quad }\\
                      &\quad \If {Z.\one \sqsubseteq T} {\\
%                      &\quad \quad B \takes \one;\\
                      &\quad \quad \copyb(R, Q, Y_0)\\
                      &\quad \quad Z \takes Z.\one;\\
                      &\quad \quad }\\
                      &}
\end{align*}
\end{defn}

\begin{lemma}[Complexity of truncation]
\label{lemma:comptrunc}
The pseudo-procedure $\trunc$ requires a number of steps which is at most polynomial in the sizes of its free names with respect to Definition \ref{def:sifpcost}.
\end{lemma}

\begin{proof}
By Lemma \ref{lemma:compcopyb} we know that the pseudo-procedure $\copyb$ requires a constant number of steps, furthermore, the inner cycles are the implementation of an $\mathtt{if}$ according to Remark \ref{remark:if}, so they are executed only once per outer cycle. Finally the number of outer cycles is bounded by the $|T|$, so the whole complexity of the pseudo-procedure is polynomial (linear) in $|T|$.
\end{proof}

\begin{lemma}[Correctness of truncation]
\label{lemma:corrtrunc}
The pseudo-procedure $\trunc$ truncates the register $R$ to its $|T|$-th prefix.
\end{lemma}

\begin{proof}
We proceed by induction on $T$.
\begin{itemize}
\item[$\epsilon$] Trivially we have $R=\epsilon$ since the cycle isn't executed.
\item[$\sigma b$] In this case, only one of the sub-cycles is executed (they are mutually-exclusive), a single more of $Q$ is stored in $R$ according to Lemma \ref{lemma:corrcopyb}, and $Q$ is unchanged after the execution of $\copyb$. Theses arguments prove the claim. The register $Y$ has no practical implications since it's only used in order to leverage the lemmas on $\copyb$.
\end{itemize}
\end{proof}

We have shown that all the surrounding elements of the bounded recursion schema\footnote{Namely: $\Lpw$ terms and their truncation.}
can be encoded in $\SIFPRA$ by means of poly-time programs.
To prove Lemma \ref{lemma:portosifp}, it remains us to show
that all the functions which are if $\POR$ are calculated by poly-time $\SIFPRA$
programs, too.

\begin{proof}[Proof of Lemma \ref{lemma:portosifp}]
For each function $f \in \POR$ we define a program $\LL{f}$ such that
$\llbracket \LL{f}\rrbracket(x_1, \ldots, x_n)=f(x_1, \ldots, x_n)$
by induction on the structure of $f$.
The correctness of $\LL{f}$
is given by the following invariant properties:
\begin{itemize}
\item The result of the computation is stored in $R$.
\item The inputs are stored in the registers of the group $X$.
\item The function $\LL\cdot$ doesn't change the values it accesses as input.
\end{itemize}

We define the function $\LL\cdot$ as follows.
\begin{itemize}
\item $\LL{E}\coloneqq R \takes \epsilon$.
\item $\LL{S_0}\coloneqq R \takes X_0.0$.
\item $\LL{S_1}\coloneqq R \takes X_0.1$.
\item $\LL{{P}^n_i}\coloneqq R \takes X_i$.
\item $\LL{C}\coloneqq R \takes X_1 \sqsubseteq X_2$.
\item $\LL{Q}\coloneqq \fl {X_1}$.
\end{itemize}

The basic functions' correctness is trivial. Moreover, it's simple to see that
the only translation containing $\fl e$ for some $e \in \lang\xp$ is
the translation of $Q$.

The encoding of the composition and of the bounded iteration are defined as follows:
\begin{align*}
\LL{g(h_1(x_1,\ldots, x_n, \omega), \ldots h_k(x_1,\ldots, x_n, \omega), \omega)}\coloneqq&
\LL{h_1}(X_1, \ldots, X_n)\\
&S_1 \takes R;\\
&\ldots\\
&\LL{h_k}(X_1, \ldots, X_n)\\
&S_k \takes R;\\
&Y_1 \takes X_1;\\
& \ldots\\
& Y_{\max(n, k)} \takes X_{\max(n, k)};\\
& X_1 \takes S_1;\\
& \ldots\\
& X_k \takes S_k;\\
%& X_{k} \takes Y_{n};\\
&\LL{g}(X_1, \ldots, X_k)\\
& X_1 \takes Y_1\\
&\ldots\\
&X_{\max(n+1, k+1)} \takes Y_{\max(n+1, k+1)};\\
%&\sk
\end{align*}

The correctness of this encoding with respect to the
invariants is a consequence of the IHs. Furthermore, suppose that
$f$ does not contain $Q$ in its definition, it mines that none of $g$ and $h_i$
for $1 \le i \le k$ does, so by IH, and for the construction we did,
we know that $\LL{f}$ does not contain any $\fl e$ statement.

Supposing that $g$ takes $n$ parameters,
the bounded iteration is encoded as follows:

\begin{align*}
\LL{\mathit{ite}(g, h_1, h_2, t)}\coloneqq
&Y_0 \takes X_{n+1};\\
&X_{n+1} \takes \epsilon;\\
& \LL{g}(X_1, \ldots, X_n)\\
%& Y \takes X_{n+2};\\
& X_{n+2} \takes R;\\
& \while {X_{n+1} \sqsubset Y_0} {\\
&\quad \If{X_{n+1}.\zero\sqsubseteq Y_0 }{\\
&\quad\quad \MM(t)(X_1, \ldots, X_n, X_{n+1})\\
&\quad\quad T \takes R;\\
&\quad \quad \LL{h_0}(X_1, \ldots, X_n, X_{n+1}, X_{n+2})\\
%&\quad\quad X_{n+1}\takes R;\\
&\quad\quad \trunc(T, R);\\
&\quad\quad X_{n+2} \takes R;\\
&\quad\quad X_{n+1}\takes X_{n+1}.\zero;\\
 }
& \quad \If{X_{n+1}.\one\sqsubseteq Y_0}{\\
&\quad\quad \MM(t)(X_1, \ldots, X_n, X_{n+1})\\
&\quad\quad T \takes R;\\
&\quad \quad \LL{h_1}(X_1, \ldots, X_n, X_{n+1}, X_{n+2})\\
&\quad\quad \trunc(T, R);\\
&\quad\quad X_{n+2} \takes R;\\
&\quad\quad X_{n+1}\takes X_{n+1}.\one;\\
 }
}\\
%&X_{n+2}\takes Y;\\
&R \takes X_{n+2};\\
%&\sk
\end{align*}
This encoding is quite cumbersome: we suppose that the bounded
recursive function takes $n+1$ parameters as input and that one of those,
the $n+1$-th is the recursion bound.
%
The correctness of this piece of code with respect to the
invariant properties mentione above can be shown by induction on the value of
the induction parameter $\sigma$ together with another invariant property:
at the end of the evaluation $X_{n+1}$ contains $\sigma$.

\begin{itemize}
  \item [$\eepsilon$] In this case, the evaluation skips the outer while, so the
  correctness of the overall code is a consequece of the induction hypothesis on
  $g$. At the end of the evaluation, $\store(X_{n+1})=\eepsilon$.
  \item [$\tau\bbool$] In this case we know that the code behaves correctly for input
  $\tau$. Suppose that the input is noe $\tau\bbool$; according to the semantics of
  the $\while{}{}$ statement, the execution of the code on $\tau\bbool$ unfolds
  as the execution of the code on $\tau$ (which respects the invariant properties
  by induction hypothesis), followed by a new cycle. This last cycle matches the
  value of $\bbool$. Suppose it to be $\zzero$. Thec code computes the size bound,
  without alterating the values in the other registers, then it computes $h_0$ and
  truncates it, then prepares the inputs for the next cycle (simulated call).
  The correctness of rhe overall procedure is a consequence
  of the IHs and the correctness of the $\trunc$ pseudo-procedure
  (Lemma \ref{lemma:corrtrunc}).
\end{itemize}
The proof that $f$ does not contain $\fl e$ statements for any $e$ is identical
to the case of composition.
\end{proof}

\begin{lemma}[Complexity of $\SIFPRA$]
  \label{lemma:compsifpra}
$\forall f \in \POR. \LL{f}$ takes a number of steps which is polynomial in the size of the arguments of $f$ with respect to Definition \ref{def:sifpcost}.
\end{lemma}
\begin{proof}
We proceed by induction on the proof of the fact that $f$ is indeed in $\POR$. All the base cases ($E$, $S_0$,$S_1$, ${P}^n_i$, $C$,$Q$) are trivial. The inductive steps follow easily:
\begin{itemize}
\item In the case of composition, we know that the thesis holds for all the pseudo-procedures $\LL\cdot$. The program requires a finite number of assignments more, so its complexity is still polynomial.
\item In the case of iteration we can move the same argument of Lemma \ref{lemma:compcopyb} to prove that the outer cycle is executed only $|Z|$ times, which is a polynomial in an argument of the encoded function. Moreover, the inner cycles are an implementation of the $\mathtt{if}$ construct according to Remark \ref{remark:if}, so they are executed only once per outer cycle. So the thesis comes from Lemma \ref{lemma:comptrunc}, from Lemma \ref{lemma:compmm}, from the fact that the composition of polynomials is still polynomial and from the IH.
\end{itemize}
\end{proof}

\begin{cor}
  \label{cor:PORtoSIFPRA}
  $\POR\subseteq$ poly-time $\SIFPRA$
\end{cor}
\begin{proof}
  The proof is a conjunciton of Lemmas \ref{lemma:portosifp} and \ref{lemma:compsifpra}.
\end{proof}

This corollary allows us to prove another result which will be used in the proof
of the second part of Conjecture \ref{conj:SFP}, namely:

\begin{cor}
  \label{cor:PORtoSIFPRAweak}
  $\forall f \in \POR.\exists P \in$ poly-time $\SIFPRA.$
  $$
  \forall x, y.
  \mu\left(\{\omega \in \Bool^\Ss| f(x, \omega)=y\}\right)=
  \mu\left(\{\omega \in \Bool^\Ss| \llbracket P\rrbracket (x, \omega)=y\}\right)
  $$
\end{cor}
\begin{proof}
  Consequence of Corollary \ref{cor:PORtoSIFPRA}.
\end{proof}

To prove the remaining part of
Conjecture \ref{conj:SFP},
we will show an encoding from $\SIFPRA$ to $\SIFPLA$ and then
an encoding from $\SIFPLA$ to $\SFPOD$, which is a variant
of $\SFP$ which reads from the $\eta$ tape (the random stream) \emph{on-demand}.
%
That reduction will use $r$ tapes wher $r$ is equal to the number of registers
used by the $\SIFPLA$. Since $\SFP$ is defined on two-taped Stream Machines, we
will show that a $r+1$-taped Steam machine can be reduced to a $2$-taped
machine with at most a polynomial overhead. For this reason, to get a poly-time
encoding of a $\POR$ function $f$ in $\SFP$ we need to show
that the number of registers used by encoding of $f$ in $\SIFPLA$ ($r$) is
constant and depends on $f$ only. To do so, we start showing that
for any $f \in \POR$, $\LL{f}$ requires a constant number of registers.
Moreover, contextually to the reduction from $\SIFPRA$ to $\SIFPLA$
we will show that a similar (by way simpler) result holds, too.
Composing those claims gives the result we are aiming to.

\begin{remark}
The number of registers used by $\LL{f}$ is finite.
\end{remark}

\begin{proof}
Programs are finite production, for this reason we can define a function
$\#_r^\stm:\lang{\stm_\RA}\longrightarrow \mathcal P(Id)$ which records
the idetificators of the registers used by a $\lang{\stm_\RA}$ program.
Since $\forall f \in \POR.\LL{f} \in \lang{\stm_\RA}$, the claim holds.
Such function can defined as follows:
\begin{align*}
\#_r^\stm(\fl e)&\coloneqq \#_r^\xp(e)\\
\#_r^\stm(Id\takes e)&\coloneqq \{Id\}\cup \#_r^\xp(e)\\
\#_r^\stm(\while{e}{s}&\coloneqq \#_r^\xp(e)\cup \#_r^\stm(s)\\
\#_r^\stm(p;s)&\coloneqq \#_r^\stm(p)\cup \#_r^\stm(s)\\[2ex]
\#_r^\xp(\epsilon)&\coloneqq \emptyset\\
\#_r^\xp(e.\zero)&\coloneqq \emptyset\\
\#_r^\xp(e.\one)&\coloneqq \emptyset\\
\#_r^\xp(Id)&\coloneqq \{Id\}\\
\#_r^\xp(e \sqsubseteq Id)&\coloneqq \{Id\}\cup \#_r^\xp(e)\\
\#_r^\xp(e \land Id)&\coloneqq \{Id\}\cup \#_r^\xp(e)\\
\#_r^\xp(\lnot e )&\coloneqq \#_r^\xp(e)\\
\end{align*}

We can sho by induction that
\begin{enumerate}
\item Each register which appairs in a program $P \in \lang{\stm_\RA}$ is in
$\#_r\stm(P)$.
\item $\forall P \in \lang{\stm_\RA}. \#_r^\stm(P)$ is finite.
\end{enumerate}

As a consequence $|\#_r^\stm(P)|$ is exactly an upper bound to
number of registers used by a $P \in \lang{\stm_\RA}$
\end{proof}

Finally we can state a corollary which will be useful in the next reduction.
Informally it states that for each program $P \in\lang{\stm_\RA}$
it's always possible to construcively
find a register which is not used by $P$.
The reduction from $\SIFPRA$ to $\SIFPLA$ is intimately a rewriting of
programs $P \in \lang{\stm_\RA}$ to programs $P \in \lang{\stm_\LA}$;
this result allows us to use a register $Y_k$ which is surely not used in $P$.

\begin{cor}
  \label{cor:freshreg}
  For each program $P \in \lang{\stm_\RA}$,
  $\exists t \in \Nat. \forall k\ge t. Y_{k}, X_k, S_k\not \in\#_r^\stm(P)$
\end{cor}
\begin{proof}
 Let $h$ be the maximum index (subscript)
 used by a register in $\#_r^\stm(P)$. Let $t:=h+1$.
 It holds that $\forall k\ge t.Y_k, X_k, S_k\not \in\#_r^\stm(P)$
\end{proof}


\begin{comment}
Now we should show that the oracles used by $\POR$ functions can be limited to a finite and polinomially sized domain. This result will be inherited by $\SIFP$ programs, too. This result will allow us to formalize the fact that when tanslating $\SIFP$ on multitape $\SFP$ machines we will end up with a machine which is not pointwise identical to the starting $P \in \SIFP$, but which will preserve the measure of any output given the input.

\begin{lemma}
\label{lemma:pormap}
$\forall f \in \POR. \forall \vec x \in \SS. \forall \omega \in \Os. \exists g\in \SS^\Nat. \exists k \in \Nat. \forall j \in \Nat. j < k \to \forall \omega' \omega'(g(j))\neq\omega(g(j))\to f(\vec x, \omega)\neq f(\vec x, \omega')$. Moreover the size of the function's graph is polynomial.
\end{lemma}
\begin{proof}
By induction on the syntax of $f$.
\begin{itemize}
\item If $f$ is $E, S_0, S_1, C$, or projection, the function which we need is $\emptyset$, the value of $k$ is $0$ both the conclusions hold.
\item If $f$ is $Q(x, \omega)$, the function which we need is the function $0\mapsto x$, $k$ is $1$. Both the conclusions hold.
\item In the case of composition, we have induction hypotheses on all the composed function. The $k$ which we need to introduce is the summation of all $k$ introduced by the inner hypotheses plus the one obtained instantiating the IH to its inputs. The function which we need to introduce is the one obteined shifting the $g_{i+1}$-th function's domain of $k_i$. The outer function is obtained by the corresponednt induction hypotesis instantiated on the inputs described by the inner functions. The domain of the function obtained by the induction hypothesis needs to be shifted by the sum of all the other $k$s. The union of all the shifted $g$ functions describes the function which we need. The size of the obtained function is polynomial because the sum of polynomials and their compositions are polynomials.
\item In the case of iteration, we proede by induction on the $y$ parameter.
\begin{itemize}
\item If the parameter is $\epsilon$ the function and $k$ are provided by the induction hypothesis on the base-case function.
\item If teh parameter is $\sigma b$, we have one more induction hypothesis which builds appropriate $g_\sigma$ and $k_\sigma$ for the $\sigma$ prefix. In this case we just need to instantiate that hypothesis on its proper inputs, then use the IH on $h_b$ instantiatinf it on its input, shift the function obtained by $k_\sigma$ and then $k_\sigma+k_{h_b}$ is the $k$ which we need to introduce and the function is the union of the $g_\sigma$ and the shifted function.
\end{itemize}
It is simple to verify that both the two conclusions hold.
\end{itemize}
\end{proof}

Since the implementation of $\POR$ is $\SIFP$ is $\omega$-conservative, we should state a similar result for the program $P$ obtained with the procedure described in Lemma \ref{lemma:portosifp}. Formally:

\begin{lemma}
\label{lemma:sifpmap}
$\forall f \in \POR. \forall \vec x \in \SS. \forall \omega \in \Os. \exists g\in \SS^\Nat. \exists k \in \Nat. \forall j \in \Nat. j < k \to \forall \omega' \omega'(g(j))\neq\omega(g(j))\to \LL(f)(\vec x, \omega)\neq \LL(f)(\vec x, \omega')$. Moreover the size of the function's graph is polynomial.
\end{lemma}
\begin{proof}
In Lemma \ref{lemma:portosifp}, we have proved that the translation $\LL(\cdot)$ preserves the behaviour of the program, fixed $\omega$, so the result is a consequence of Lemma \ref{lemma:pormap}.
\end{proof}
\end{comment}


























\subsubsection{From $\SIFPRA$ to $\SIFPLA$}
\label{subsub:sifpratosifpla}

We have shown that all the $\POR$ functions can be represented by means of
polynomial $\SIFPRA$ programs. Unfortunately this is not sufficient to prove the
result we are aiming to. As we explained above, $\SIFPRA$ is not suited
for a direct encoding in $\SFP$ for many reasons. One of those is the
fact that it supports a \emph{random access to the oracle}, while $\SFP$ does not.
For this reason, we define the $\SIFPLA$ formalism: the dialect of
$\SIFP$ which doesn't use the $\fl{\xp}$ primitive, but uses a simpler modality
of access to the oracle, which is indeed \emph{linear}.
%
In this section we will define $\SIFPLA$'s syntax and semantics, and we
will show that each $\SIFPRA$ program can be represented by means of a
$\SIFPLA$ program equivalent to the first with repsect to
the measure of the oracles mapping each input to the output. Namely:

\begin{lemma}
  \label{lemma:sifpratosifpla}
  Forall $P \in \SIFPRA$ there exists a $Q \in \SIFPLA$ such that
  $$
  \forall x, y. \mu\left(\{\omega \in \Bool^\Ss| \llbracket P\rrbracket (x, \omega)= y\}\right)=
                \mu\left(\{\eta \in \Bool^\Nat| \llbracket Q \rrbracket(x, \eta)= y\}\right)
  $$
  Moreover if $P$ is poly-time $Q$ is poly-time, too.
\end{lemma}

This result is analogous to what we proved in Corollary \ref{cor:SFPtoPOR}.
%
In particular, we show that each program in $\lang{\stm_\RA}$
can be simulated by mans of a progrma in $\lang{\stm_\LA}$ and that
the encoding we will define enatils Lemma \ref{lemma:sifpratosifpla}.
%
We derive Lemma \ref{lemma:sifpratosifpla} as a corollary of the proof that
$\SIFPRA$ can be simulated in $\SIFPLA$ with respect to two appropriate
step semantic relations.
%
The main issue we deal with during our reduction is proving that the
random access can be simulated building an associative table and storing it in
a specific register, which records all the queries which have been previously
simulated. This approach requires also that:
\begin{itemize}
  \item At each simulated query,
  the destination program looks up this table;
  \item If it finds the queried coordinate:
  \begin{itemize}
    \item It returns the result stored in the table
  \end{itemize}
  otherwise:
  \begin{itemize}
    \item It reduces $\fl{e}$ to a call of $\rb$ which outputs either $\bbool=\zzero$ or
    $\bbool=\oone$.
    \item it records the couple $\langle e,\bbool\rangle$ in
   the associative table and returns the $\bbool$.
  \end{itemize}
\end{itemize}


\begin{defn}[$\SIFPLA$]
  The language of the $\SIFPLA$ programs is $\lang{\stm_\LA}$,
  i.e. the set of strings produced by the non-terminal symbol $\stm_\LA$
  described in Definirion \ref{def:sifp}.
\end{defn}

The operational semantic of $\SIFPLA$ is almost identical to the
operational semantic of $\SIFPRA$, apart from the fact that it is
defined using oracle functions $\eta: \Nat \longrightarrow \Bool$ instead of
functions $\omega: \Ss \longrightarrow \Bool$.

\begin{defn}[Operational semantics of $\SIFPLA$]
  \label{def:sifplaos}
The semantics of a program $P \in \lang{\stm_\LA}$ is the smallest function $
\ssos: \left(\lang{\stm_\LA} \times (\id \longrightarrow \{\zero, \one\}^*)\times \Bool^\Nat\right)
\longrightarrow
\left((\id \longrightarrow \{\zero, \one\}^*)\times \Bool^\Nat\right)$
closed under the following rules:
\begin{center}
\vspace{12pt}
% \AxiomC{$\phantom{\langle \sk, \store\rangle \ssos \store}$}
% \UnaryInfC{${\langle \sk, \store, \eta\rangle \ssos \langle \store, \eta\rangle}$}
% \DisplayProof
% \hspace{18pt}
\AxiomC{$\langle e, \store\rangle\sred \sigma$}
\UnaryInfC{$\langle Id\takes e, \store, \eta\rangle \ssos \langle \store\as {Id}{\sigma}, \eta\rangle$}
\DisplayProof

\vspace{12pt}
\hspace{18pt}
\AxiomC{$\langle s, \store, \eta\rangle\ssos \langle \store', \eta'\rangle$}
\AxiomC{$\langle t, \store', \eta\rangle\ssos \langle\store'', \eta''\rangle$}
\BinaryInfC{$\langle s;t, \store, \eta\rangle \ssos \langle\store'', \eta''\rangle$}
\DisplayProof

\vspace{12pt}
\AxiomC{$\langle e, \store\rangle\sred \one$}
\AxiomC{$\langle s, \store, \eta\rangle\ssos \langle\store', \eta'\rangle$}
\AxiomC{$\langle \while e s, \store', \eta\rangle\ssos \langle\store'', \eta''\rangle$}
\TrinaryInfC{$\langle \while e s, \store, \eta\rangle \ssos \langle\store'', \eta''\rangle$}
\DisplayProof

\vspace{12pt}
\hspace{18pt}
\AxiomC{$\langle e, \store\rangle\sred \sigma$}
\AxiomC{$\sigma \neq \one$}
\BinaryInfC{$\langle \while e s, \store, \eta\rangle \ssos \langle\store, \eta\rangle$}
\DisplayProof
\hspace{18pt}
\AxiomC{\phantom{$\langle \rb \store, \bbool\eta\rangle \ssos \langle\store[R \leftarrow \bbool], \eta\rangle$}}
\UnaryInfC{$\langle \rb, \store, \bbool\eta\rangle \ssos \langle\store \as R \bbool, \eta\rangle$}
\DisplayProof

\end{center}
\end{defn}

Upon this semantics we can define the function computed by a $\SIFPLA$ program:

\begin{defn}[Function evaluated by a $\SIFPLA$ program]
  \label{def:simplafuneval}
We say that the function evaluated by a correct $\SIFPLA$ program $P$ is $\mathcal \llbracket P\rrbracket: \lang{\stm_\LA} \longrightarrow (\Ss^n \times \Bool^\Nat \longrightarrow \Ss)$, defined as below\footnote{Even in this case, we use the infix notation for $\ssos$.}:
\[
\rrbracket P\rrbracket\coloneqq \lambda x_1, \ldots, x_n, \eta.\ssos(\langle P, []\as {X_1} {x_1}, \ldots, \as {X_n} {x_n}, \eta\rangle)(R)
\]
\end{defn}


The proof of the reduction of a $\SIFPRA$ to $\SIFPLA$ can be given in many ways.
As we anticipated above, we found particularly useful to formulate the result as a
weak simulation result between a $\SIFPRA$ program and its $\SIFPLA$
implementation.
%
To do so, we need to define two single step semantics for $\SIFPRA$ and $\SIFPLA$
and to show that they are equivalent to the operational semantics we have given
in Definitions \ref{def:sifpraos} and \ref{def:sifplaos}.
%
In order to define the $\SIFPLA$ (and $\SIFPRA$) step semantics,
we extend the definition of those formalisms adding a new statement $\halt$
(which behaves exaclty as the \emph{nil} process of the CCS process algebra)
to simplify some definitions and proofs.

\begin{defn}[Language of the Halt-Extended $\SIFPLA$ and $\SIFPRA$]
  The language of the Halt-Extended $\SIFPLA$ and $\SIFPRA$ programs
  are $\lang{\stm_\LA'}$ (and $\lang{\stm_\RA'}$), where
  \begin{align*}
    \stm_\LA' & \Coloneqq \id \takes \xp\ |\ \stm_\LA;\stm_\LA'\ |\ \while \xp \stm_\LA\ |\ \rb\ |\ \halt\\
    \stm_\RA' & \Coloneqq \id \takes \xp\ |\ \stm_\RA;\stm_\RA'\ |\ \while \xp \stm_\RA\ |\ \fl \xp\ |\ \halt\\
  \end{align*}
\end{defn}

\begin{defn}[Step semantics of $\SIFPLA$]
  \label{def:sifplass}
The step semantics of a program $P \in \lang{\stm_\LA'}$ is the smallest relation
$$
\leadstola \in \mathcal P \left(\left(\lang{\stm_\LA'} \times (\id \longrightarrow \{\zero, \one\}^*)\times \Bool^\Nat\right)
\times
\left(\lang{\stm_\LA'} \times (\id \longrightarrow \{\zero, \one\}^*)\times \Bool^\Nat\right)\right)
$$
closed under the following rules:
\begin{center}
% \AxiomC{\phantom{$\langle e, \store\rangle\sred \sigma$}}
% \UnaryInfC{$\langle \sk P, \store, \Psi\rangle \leadstola \langle P, \store, \Psi\rangle$}
% \DisplayProof
% \hspace{18pt}
\vspace{12pt}
\AxiomC{$\langle e, \store\rangle\sred \sigma$}
\UnaryInfC{$\langle Id\takes e;P, \store, \Psi\rangle \leadstola \langle P, \store\as {Id}{\sigma}, \Psi\rangle$}
\DisplayProof
\hspace{18pt}
\AxiomC{$\langle e, \store\rangle\sred \sigma$}
\AxiomC{$\sigma \neq \one$}
\BinaryInfC{$\langle \while e s; P, \store, \Psi\rangle \leadstola \langle P,\store, \Psi\rangle$}
\DisplayProof

\vspace{12pt}
\AxiomC{$\langle e, \store\rangle\sred \one$}
\UnaryInfC{$\langle \while e s; P, \store, \Psi\rangle \leadstola \langle s; \while e s;P, \store, \Psi\rangle$}
\DisplayProof

\vspace{12pt}
\AxiomC{$\Psi = \bigcap_{i=0}^{n-1} C(i)$}
\UnaryInfC{$\langle \rb;Q, \store, \Psi\rangle \leadstola \langle Q,\store \as R \one, \Psi \cap P(n)\rangle$}
\DisplayProof

\vspace{12pt}
\AxiomC{$\Psi = \bigcap_{i=0}^{n-1} C(i)$}
\UnaryInfC{$\langle \rb;Q, \store, \Psi\rangle \leadstola \langle Q,\store \as R \zero, \Psi \cap N(n)\rangle$}
\DisplayProof
\end{center}
\end{defn}

Before defining the step semantics for $\SIFPRA$,
we would like to briefly discuss the
step semantics of $\SIFPLA$ have defined above.
The semantics of the deterministic statements
is canonical, indeed:
\begin{itemize}
  \item We treat the $\cdot;\cdot$ as the action prefixing operator for
  CCS process algebra.
  \item We manage assignments basically recording on the store the effects of the statement.
  \item We have two rules for the $\while{}{}$statement:
  \begin{itemize}
    \item If the guard is true, the $\while{e}{s}$ statement
    is interpreted executing its body $s$ and then the
    whole statement again.
    \item If the guard $e$ is not true,
    its semantics skips to the next statement.
  \end{itemize}
\end{itemize}
%
All these rules, are non-random so they do not change $\Psi$. Differently, the
two rules for the $\rb$ statement can generate two different configurations depending
on the value that all the oracles of the set on the right have on their $n$-th
coordinate: if such value is $\one$ we record it in $R$,
similarly if such value is $\zero$. These rules are defined only if $\Psi$ is a
finite intersection of cylineders -- we can show by induction that
in our if we start with $\Psi:= \Bool^\Nat$ it will always be the case -- and
this reflects the intuitive behavior of the program.
%
This way to proceed generalizes the semantics, making it directly suitable for
a measure analysis: indeed, we show that the transitive closure of
$\leadstola (\langle P, []\as X x, \Bool^\Nat\rangle)$
describes exactly all the possible paths on the Reduction Tree associated to
$\lambda \eta. \llbracket P\rrbracket(x, \eta)$. This allows us to prove the equivalence between
$\SIFPRA$ and $\SIFPLA$ in a quite natural way.

In a similar fashion, we define the step semantics for $\SIFPRA$:

\begin{defn}[Step semantics of $\SIFPRA$]
  \label{def:sifprass}
The step semantics of a program $P \in \lang{\stm_\RA'}$ is the smallest relation
$$
\leadstora \in \mathcal P \left(\left(\lang{\stm_\RA'} \times (\id \longrightarrow \{\zero, \one\}^*)\times \Bool^\Ss\right)
\times
\left(\lang{\stm_\RA'} \times (\id \longrightarrow \{\zero, \one\}^*)\times \Bool^\Ss\right)\right)
$$
closed under the following rules:
\begin{center}
% \AxiomC{\phantom{$\langle e, \store\rangle\sred \sigma$}}
% \UnaryInfC{$\langle \sk P, \store, \Psi\rangle \leadstora \langle P, \store, \Psi\rangle$}
% \DisplayProof
% \hspace{18pt}
\AxiomC{$\langle e, \store\rangle\sred \sigma$}
\UnaryInfC{$\langle Id\takes e;P, \store, \Psi\rangle \leadstora \langle P, \store\as {Id}{\sigma}, \Psi\rangle$}
\DisplayProof
\hspace{18pt}
\AxiomC{$\langle e, \store\rangle\sred \sigma$}
\AxiomC{$\sigma \neq \one$}
\BinaryInfC{$\langle \while e s; P, \store, \Psi\rangle \leadstora \langle P,\store, \Psi\rangle$}
\DisplayProof

\vspace{12pt}
\AxiomC{$\langle e, \store\rangle\sred \one$}
\UnaryInfC{$\langle \while e s;P, \store, \Psi\rangle \leadstora \langle s; \while e s;P, \store, \Psi\rangle$}
\DisplayProof

\vspace{12pt}
\AxiomC{$\langle e, \store\rangle \sred \sigma$}
\AxiomC{$\Psi \cap P(\sigma)\neq \emptyset$}
\BinaryInfC{$\langle \fl e ;Q, \store, \Psi\rangle \leadstora \langle Q,\store \as R \one, \Psi \cap P(\sigma)\rangle$}
\DisplayProof

\vspace{12pt}
\AxiomC{$\langle e, \store\rangle \sred \sigma$}
\AxiomC{$\Psi \cap N(\sigma)\neq \emptyset$}
\BinaryInfC{$\langle \fl e ;Q, \store, \Psi\rangle \leadstora \langle Q,\store \as R \zero, \Psi \cap N(\sigma)\rangle$}
\DisplayProof
\end{center}
\end{defn}

In the rules for $\fl e$, we ask $\Psi \cap N(\sigma)\neq \emptyset$, because we
don't want the relation $\leadstora$ to relate configurations which are not
related by $\ssos$: indeed, if $\Psi$ does not contain any oracle in $C(\sigma)$
dor a given $sigma$, it means that there is no oracle $\omega$ which would drive
that reduction.
%
The closure of the relation $\leadsto_\cdot$ for $\cdot \in \{\LA, \RA\}$
under the transitive property
produces respectively $\leadstolan n$ and $\leadstoran n$.

\begin{defn}[Indexed transitive closure of $\leadstola$ and $\leadstora$]
  For $\cdot \in \{\mathbf{LA}, \mathbf{RA}\}$,
  we define the family of relations  $\{\leadsto_\cdot^n\}_{n\in \Nat}$
  as the set of functions closed and minimal with respect to the following rules:
  $$
  \begin{aligned}
    \langle P, \store, \Psi\rangle &\leadsto_\cdot^0\langle P, \store, \Psi\rangle\\
    \big( \langle P, \store, \Psi\rangle \leadsto_\cdot^n\langle P', \store', \Psi'\rangle \land \langle P', \store', \Psi'\rangle &\leadsto_\cdot\langle P'', \store'', \Psi''\rangle\big) \to\big(
    \langle P, \store, \Psi\rangle \leadsto_\cdot^{n+1}\langle P'', \store'', \Psi''\rangle\big)
  \end{aligned}
  $$
\end{defn}

The idea behind this definitions is to enrich the operational semantic with some
pieces of information which can be used to build an induction
proof of the reduction from $\SIFPRA$ to $\SIFPLA$, in particular:

\begin{enumerate}
  \item We add a set of oracles
  (either $\Nat \longrightarrow \Bool$ or $\Ss \longrightarrow \Bool$) $\Psi$
  which  lead to a certain
  target configuration.
  In this way, we can directly prove Lemma \ref{lemma:sifpratosifpla}
  directly on the simulation result we are aiming to. In other words,
  the transitive closure of $\leadsto_\cdot$ shapes this parameter in order
  to build, together with the reduction, the measurable set of functions which
  bring the reduction to a certain configuration.
  \item We can use this set of oracles to keep track of the coordinates
  which have alerady been queried to the oracle. This because by definition of
  $\leadstora$ and $\leadstola$, $\forall k, P \in \lang{\stm_\cdot'}, \store.
  \langle P, \store, \Os\rangle \leadsto_\cdot^k \langle P', \store', \Phi\rangle$
  where $\Phi$ is exactly the intersection of the cylinders on the coordinates
  which have been queried by $P$ during its reduction to $P'$. Moreover, if
  this query reduced to $\oone$, that cylinder is positive, otherwise it is negative.
  \item The book-keeping information which is contaied in the set of oracles related
  with respect to $\leadstora$ and $\leadstola$ can be used to enrich each
  configuration of the evaluation of $P$ with the associative table
  which is built by its corresponding Program $P'$ during its evaluation.
\end{enumerate}

This single-step semantics can be used to define the cost model we used in Section
\ref{subsub:portosifpra} to prove the polynomial time complexity
of the translation of $\POR$ in $\SIFPRA$

\begin{defn}[Cost Model For $\SIFPRA$ and $\SIFPLA$]
  \label{def:sifpcost}
  We say that a program $P \in \lang{\stm_\RA}$
  has time complexity $f: \Nat \longrightarrow \Nat$ if and only if
  $$
  \forall x\in Ss, k \in \Nat. \exists k, \store', \Psi.
  \langle P, []\as X x, \Os\rangle \leadstoran k
  \langle\halt, \store', \Psi\rangle
  $$
  entails that $k \le f(|x|)$. Analogously for $\SIFPLA$.
\end{defn}

Finally, we define the transitive closure of $\leadsto_\cdot$ for $\cdot \in
\{\mathbf{LA}, \mathbf{RA}\}$:

\begin{defn}[Step semantics transitive closure]

  \begin{align*}
    \leadstolan * &:= \bigcup_{n \in \Nat} \leadstolan n\\
    \leadstoran * &:= \bigcup_{n \in \Nat} \leadstoran n\\
  \end{align*}

\end{defn}

Our goal now is to define a characerization of the function evaluated by a
program of $\lang {\stm_\LA}$ program which relies on the
step semantics rather than the
canonical operational semantics we used before.
%
The operational semantics and the single step semantics are intuitive, indeed
we can characterize the notion of value computed by a program of $\SIFPLA$ and
$\SIFPRA$ using this semantics.

\begin{lemma}
  \label{lemma:psimaximal}
  For each $P', P\in \lang {\stm_\RA}$, for each $\Psi \subseteq \Os$, and
  for each store $\sigma$,
  if $\Psi' \subseteq \Os$ is the maximal set
  such that
  $$
  \langle P,\store, \Psi \rangle \leadstoran k
  \langle P', \store', \Psi'\rangle
  $$
  for some $\store'$ and some $P'$
  and
  $$
  \langle P',\store', \Psi' \rangle \leadstora
  \langle P'', \store'', \Psi''\rangle
  $$
  then $\Psi''$ is the maximal set such that
  $\langle P,\store, \Psi \rangle \leadstoran {k+1}
  \langle P'', \store'', \Psi''\rangle$
\end{lemma}
\begin{proof}
  By induction on $P'$.
  \begin{itemize}
    \item[$Id\takes e$] In this case, the number of steps of reduction
    is one and $\Psi'=\Psi''$. Any larger set would break
    the maximality of $\Psi'$.
    \item[$\fl e$] In this case, the number of steps of reduction
    is one and any larger candidate would break the hypothesis on the maximality
    of $\Psi'$ or the hypothesis on the $k+1$-th step. The result holds.
    \item[$\while e s$] Depending on the evaluation of $e$ in $\store$,
    we can apply two rules, in both cases the number of steps of
    reduction is one and $\Psi'=\Psi''$. As above any larger candidate would
    break the hypothesis on the maximality
    of $\Psi'$.
  \end{itemize}
\end{proof}

This result can be instantiated on $\Psi=\Os$ and eliminating $k$
in order to obtain the following result:

\begin{cor}
  \label{cor:omaximality}
  For $\cdot \in \{\LA, \RA\}$, for each $P', P\in \lang {\stm_\cdot}$ and
  for each store $\sigma$,
  if $\Psi \subseteq \Os$ is such that
  $$
  \langle P,\store, \Os \rangle \leadsto_\cdot k
  \langle P', \store', \Psi\rangle
  $$
  then $\Psi$ is the maximal set such that
  $$
  \langle P,\store, \Os \rangle \leadsto_\cdot k
  \langle P', \store', \Psi\rangle
  $$
\end{cor}
\begin{proof}
  We will show the result for $\RA$ only, the proof for $\LA$ is analogous.
  First, we observe that $\Os$ is the maximal set such that
  $\langle P, \store, \Os\rangle \leadstoran 0 \langle P, \store, \Os\rangle$.
  Then we go by induction on $k$. For $0$, $\Psi=\Os$, and the result
  is trivially obtained, otherwise the result comes from the
  induction hypothesis and Lemma \ref{lemma:psimaximal}.
\end{proof}

First we characterize the notion of value computed by a $\SIFPLA$ or a $\SIFPRA$
program, then we use this result to characterize the sets $\{\omega \in \Bool^\Ss| \llbracket P\rrbracket (x, \omega)= y\}$ and $\{\eta \in \Bool^\Nat| \llbracket P \rrbracket(x, \eta)= y\}$

\begin{characterization}[Value Computed by a $\SIFPLA$ and $\SIFPRA$ Program]
  \label{char:sifp.avalue}
  For $\cdot\in \{\mathbf{LA}, \mathbf{RA}\}$ and
  $\mathbb V \in \{ \Bool^\Nat, \Bool^\Ss\}$
  it holds that for each $P \in \lang{\stm_\cdot'}$ and
  $\forall \sigma, \tau \in \Ss \forall \psi \in \mathbb V$:
  \begin{align*}
    \llbracket P\rrbracket (\sigma, \psi) = \tau \leftrightarrow
    \langle P; \halt, []\as X \sigma, \mathbb V \rangle \leadsto_\cdot^*
    \langle \halt, \store, \Psi \rangle \land \store(R)=\tau
  \end{align*}

 for some
  $\{\psi\}\subseteq \Psi \subseteq \mathbb V$, and a store $\store$
\end{characterization}


\begin{proof}
The proof is by induction on the proofs of $\ssos$ and $\leadsto_\cdot^k$.
\end{proof}


\begin{characterization}
  \label{char:setofos}
  For $\cdot \in \{LA, \RA\}$, for each $P \in \lang{\stm_\cdot}$
  and for each $\sigma, \tau \in \Ss$,
  if $\Psi\subseteq \Os$ is such that
  $$
  \langle P; \halt, []\as X \sigma, \Os \rangle \leadsto_\cdot *\langle \halt, \store', \Psi\rangle
  $$
  for some $\store'$, then
  $\{\omega \in \Bool^\Ss| \llbracket P\rrbracket (\sigma, \omega)= \tau\}=\Psi$
\end{characterization}
\begin{proof}
  The result is a particularization of the existensial quantificators in
  Corollary \ref{cor:omaximality} and the characterization of value computed by
  a $\SIFPRA$ and $\SIFPLA$ program, i.e. Characterization \ref{char:sifp.avalue}.
\end{proof}
%
We argumented that $\leadstoran n$ and $\leadstoran n$ are designed in order
to describe the set of oracles $\Psi$ which support a given reduction,
Characterization \ref{char:setofos} proofs this conclusion formally.
%
This allows us to use the relations $\leadstola$ and $\leadstora$ to prove
Lemma \ref{lemma:sifpratosifpla}.


% \begin{characterization}[Function Evaluated by a $\SIFPLA$ and $\SIFPRA$ Program]
%   For $\cdot\in \{\mathbf{LA}, \mathbf{RA}\}$
%   and respectively for $\mathbb V \in \{ \Bool^\Nat, \Bool^\Ss\}$,
%   it holds that for each $P \in \lang{\stm_\cdot'}$,
%   if forall $x \in \Ss$ and $\psi \in \mathbb V$
%   $$
%   \exists \store', \Psi.~ \psi \in \Psi \land \langle P;\halt, []\as X x,\mathbb V\rangle
%    \leadsto_\cdot^*(\langle \halt, \Sigma', \Psi\rangle)
%    $$
%   it holds that
%   $$
%   \llbracket P\rrbracket=\lambda x, \psi.\pi_2\left(\leadsto_\cdot^{f(P, x, \psi)}(\langle P, []\as X x,
%   g(P, \psi)\rangle)\right)
%   $$
%   where $f: \lang{\stm_\cdot}\times \Ss \times \Bool^{\Nat \cup \Ss}\longrightarrow \Nat$
%   is the function which associates the value $k$
%   described above to each triple $P, x, \psi$.
%   Similarly $g: \lang{\stm_\cdot}\times \Bool^{\Nat \cup \Ss}\longrightarrow \mathbb P(\Bool^{\Nat \cup \Ss})$
%   is the function which associates the set $\Psi$
%   described above to each triple $P, x, \psi$.
% \end{characterization}
% \begin{proof}
%   Consequence of the Characterization of the Value Computed by a
%   $\SIFPLA$ and $\SIFPRA$ Program (Characterization \ref{char:sifp.avalue}).
%   Indeed such results asserts the eixtstence of the functions $f$ and $g$ in
%   both the directions.
% \end{proof}


Thanks to these characterizations we can define the encoding from
$\SIFP_\RA$ to $\SIFP_\LA$
(practically we only need the encoding of $\fl{}$ in $\SIFP_\RA$)
and prove that an appropriate simulation result holds with respect to
the programs' step semantics.
%
In other words, we want to show that there is a function
%
$$
\Theta: \left(\lang{\stm_\RA'}\times \left(\id\to{\Ss}\right)\times \mathcal P (\Bool^\Ss) \right)
\longrightarrow
\left(\lang{\stm_\LA'}\times \left(\id\to{\Ss}\right)\times \mathcal P (\Bool^\Nat) \right)
$$
%
which associates to each triple $\langle P_\RA, \Sigma, \Psi\rangle$ another triple
$\langle P_\LA, \Gamma, \Phi\rangle$ which weakly simulates the relation $\leadstora$
with respect to $\leadstola$. This is depicted by Figure \ref{fig:commutationsifp}.
%
\begin{figure}[]
  \begin{tikzpicture}[node distance=6cm]
      \node (PRA) {$\langle P_\RA;Q_\RA, \store, \Psi\rangle$};
      \node[below of = PRA] (PLA) {$\langle P_\LA;Q_\LA, \Gamma, \Phi\rangle$};
      \node[right of = PRA] (P1RA) {$\langle Q_\RA, \store', \Psi'\rangle$};
      \node[right of = PLA] (P1LA) {$\langle Q_\LA, \Gamma', \Phi'\rangle$};


      \draw[->] (PRA) edge[draw, decorate, decoration={zigzag, post=lineto, post length=3mm}] (P1RA);
      \draw[->] (PLA) edge[draw, decorate, decoration={zigzag, post=lineto, post length=3mm}, shorten >=.25em] node[inner sep=0pt,at end,sloped] {${}^*$}(P1LA);
      \draw[->] (PRA) edge node[fill=white] {$\Theta$} (PLA);
      \draw[->] (P1RA) edge node[fill=white] {$\Theta$} (P1LA);
  \end{tikzpicture}
  \caption{Commutation schema between $\SIFPRA$ and $\SIFPLA$}
  \label{fig:commutationsifp}
\end{figure}
%
In particular, $\Theta$ will be defined upon three co-operating functions:
%
\begin{itemize}
  \item A function
  $$
  \alpha: \lang{\stm_\RA'}
  \longrightarrow
  \lang{\stm_\LA'}
  $$
  which maps the program $P_\RA \in \lang{\stm_\RA'}$ into its
  corresponding $P_\LA \in \lang{\stm_\LA'}$ with respect to
  the simulation relation.
  \item A function
  $$
  \beta:\left(\lang {\stm_\RA'}\times\left(\id\to{\Ss^*}\right)\times \mathcal P (\Bool^\Ss) \right)
  \longrightarrow
  \left(\id\to{\Ss^*}\right)
  $$
  which associates the running configuration of $P_\RA \in \lang{\stm_\RA'}$
  to the configuration of the corresponding $\alpha(P_\RA)=P_\LA \in \lang{\stm_\LA'}$
  with respect to the simulation relation.
  The resulting configuration depends on the set of matching oracles.
  This  because, the $\beta$ should
  basically add to the $\store$ of $P_\RA$ a register containing
  an associative table, which we already discussed.
  Finally, it should not be too much of a problem
  to see that fixed the sequence of queried by a program
  the associative table is uniquely defined modulo permutations.
  \item A function
  $$
  \gamma:\mathcal P (\Bool^\Ss)
  \longrightarrow
  P (\Bool^\Nat)
  $$
  which is the semantical counterpart of the $\beta$ function: whilst $\beta$
  builds a syntactic representation of the queries made by the program $P_\RA$,
  $\gamma$ builds a semantical representation of the queries made by the program
  $\alpha(P_\RA)$, which is the set of oracles
  shaped by the transition relation. This is computed using the sequence of
  coordinates queried by $P_\RA$.
\end{itemize}

We can state formally these observations by means of the following Proposition

\begin{prop}[Simulation of $\SIFPRA$ in $\SIFPLA$]
  \label{prop:ratola}
  There are a function
  $$
  \Theta: \left(\lang{\stm_\RA'}\times \left(\id\to{\Ss}\right)\times \mathcal P (\Bool^\Ss) \right)
  \longrightarrow
  \left(\lang{\stm_\LA'}\times \left(\id\to{\Ss}\right)\times \mathcal P (\Bool^\Nat) \right)
  $$
  and three functions
  $$
  \alpha: \lang{\stm_\RA'}
  \longrightarrow
  \lang{\stm_\LA'}
  $$
  $$
  \beta:\left(\lang {\stm_\RA'}\times\left(\id\to{\Ss^*}\right)\times \mathcal P (\Bool^\Ss) \right)
  \longrightarrow
  \left(\id\to{\Ss^*}\right)
  $$
  $$
  \gamma:\mathcal P (\Bool^\Ss)
  \longrightarrow
  P (\Bool^\Nat)
  $$
  such that
  $$
  \Theta(P, \store, \Psi) = \langle \alpha(P), \beta(P, \store, \Psi), \gamma(\Psi)\rangle
  $$
  and
  \begin{align*}
  &\forall P \in \lang{\stm_\RA'}.\forall \store.\forall \Psi \in \Os.\\
  &\quad\exists S \subseteq \Ss. \Psi = \bigcap_{s \in S}C(s) \to\\
  &\quad\quad\forall Q.\exists P', \store', \Psi'.\langle P;Q, \store, \Psi\rangle \leadstora \langle P', \store', \Psi'\rangle \to\\
  &\quad\quad\quad\exists \Gamma, \Phi \subseteq \Ss^\Nat.\exists k\ge 1.\Theta(P;Q, \store, \Psi) \leadstolan k \langle\alpha(P'), \Gamma, \gamma(\Psi')\rangle\land\\
  & \quad\quad\quad\quad \forall G \in \#_r^\stm(P).\beta(P', \store', \Psi')(G)=\Gamma(G) \land\\ & \quad\quad\quad\quad\quad\beta(P',\store', \Psi')(Y_{{|\#_r^\stm(P)|+1}})=\listenc{\listenc {\sigma_1, b_1} 2, \ldots, \listenc {\sigma_t, b_t} 2}t \land\\
  & \quad\quad\quad\quad\quad \Gamma(Y_{{|\#_r^\stm(P)|+1}})=\listenc{\listenc {\sigma_{f(1)}, b_{f(1)}} 2, \ldots, \listenc {\sigma_{f(t)}, b_{f(t)}} 2}t
  \end{align*}
  for some $t \in \Nat$ and some permutation $f:  \{1, \ldots, t\}\longrightarrow \{1, \ldots, t\}$
\end{prop}

The reader may find the statement of Proposition \ref{prop:ratola}
counter-intuitive: it breaks the redction schema described in
Figure \ref{fig:commutationsifp} introducing a slightly weaker claim.
Indeed, we are allowing the store reached by $\Theta(P;Q, \store, \Psi)$
to be not exactly $\beta(P',\store', \Psi')$, as described by te schema, but an
approximation. The reason is that during
the execution of the program, $\alpha(P)$ may use some registers
to support the reduction of $\fl{}$ to $\rb$ apart from the register
$Y_{{|\#_r^\stm(P)|+1}}$ which will contain the associative table, but these
additional register will not influence the overall reduction of the other steps.
The other approzimation is allowing the function $\beta$ to return a
permutation of the table computed during the reduction.
%
Nevertheless, in Lemma \ref{lemma:workreginvariance} we observe the value
in the work-registers used for the reduction does not affect the remaining part of
the computation, and in Corollary \ref{cor:simperminvariance} we observe that
our reduction does not suffer for working with a certain associative table
$\listenc{\listenc {\sigma_1, b_1} 2, \ldots, \listenc {\sigma_t, b_t} 2}t$
rather than its permutation
$\listenc{\listenc {\sigma_{f(1)}, b_{f(1)}} 2, \ldots, \listenc {\sigma_{f(t)}, b_{f(t)}} 2}t$.

We will prove Proposition \ref{prop:ratola} in two parts:

\begin{enumerate}
\item We will define $\Theta$.
\item We will show by induction on the definition of $\leadstora$ that
 Proposition \ref{prop:ratola} holds.
\end{enumerate}

\begin{defn}[$\Theta$ Function]
  \label{def:Theta}
  $$
  \Theta: \left(\lang{\stm_\RA'}\times \left(\id\to{\Ss}\right)\times \mathcal P (\Bool^\Ss) \right)
  \longrightarrow
  \left(\lang{\stm_\LA'}\times \left(\id\to{\Ss}\right)\times \mathcal P (\Bool^\Nat) \right)
  $$
  is defined as follows:
  $$
  \Theta(P, \store, \Psi):= \langle \alpha(P), \beta(P, \store, \Psi), \gamma(\Psi)\rangle
  $$
  where $\alpha, \beta, \gamma$ are defined respectively in Definitions \ref{def:alpha}, \ref{def:beta}, \ref{def:gamma}.
\end{defn}

\begin{defn}[$\alpha$ Function]
  \label{def:alpha}
  The funciton $\alpha: \lang{\stm_\RA'}
    \longrightarrow
    \lang{\stm_\LA'}$ is defined as an instance of $\alpha'$ which itself is a
    $\lang{\stm_\RA'}\times \Nat
      \longrightarrow
      \lang{\stm_\LA'}$ function defined by
     induction on the syntax of $\lang{\stm_\RA'}$.
  \begin{align*}
    \alpha(P)&:=\alpha'(P, |\#_r^\stm(P)|+1)\\
    \alpha(Id \takes e, n) &:= Id \takes e\\
    \alpha(\halt, n) &:= \halt\\
    \alpha(s;t) &:= \alpha(s, n);\alpha(t, n)\\
    \alpha(\while e s, n) &:= \while e {\alpha(s, n)}\\
    \alpha(\fl e, n) &:=  Y_{n+3}\takes e; \mathit{fl}_n
  \end{align*}
  Where $|\#_r^\stm(P)|+1$ is such that $Y_{|\#_r^\stm(P)|+1} \not \in \#_r^\stm(P)$
  according to $\mathit{freshreg}$ is a consequence of Corollary \ref{cor:freshreg}.
  The family of programs\footnote{Saying that $\mathit{fl}_n$ are programs instead of pseudoprocedures, we mean that the names of the registers they use must remain the same after their inlining.} $\mathit{fl}_n$ are defined in Definition
  \ref{def:flpseudo}.
\end{defn}

In order to define the pseudoprocedure which simulates the $\fl e $ primitive,
we will reuse some of the functions and the data-structures we defined for
the reduction from $\POR$ to $\SIFPRA$. As a consequence of
Lemma \ref{lemma:portosifp}, we can formally state that all
these functions do not use $\fl e$, as a consequence they are in $\SIFPLA$, too.

\begin{cor}
  \label{cor:trivportosifpla}
  All the functions $f \in \POR$ defined in Section \ref{sec:SFPtoPOR} apart from
  $\chi$ and $\mathit{apply}$ are such that $\LL{f}\in \SIFPLA\cap \SIFPRA$.
\end{cor}
\begin{proof}
  The result is a consequece of the definitions of those functions and of Lemma
  \ref{lemma:portosifp}: there, together with the correctness of $\LL{f}$, we showed
  that if a function $f \in \POR$ can be defined without recurring to $Q$ then
  $\LL{f}$ does not contain any $\fl e$ expression. For this reason it is in $\SIFPLA$, too.
\end{proof}

\begin{notation}[Program $\alpha$-conversion]
  \label{notation:alpha}
  In order avoid name clashes, we denote $P^\alpha_n$ the program $P\in \SIMP$
  in which all the name of the registers apart from the family $X_i$ and $R$
  have been reassigned to an appropriate register $S_j$ for $j\ge n$.
\end{notation}

As expected, this conversion preserves the semantics of the program, as
showed by the following Remark.

\begin{remark}
  $$
  \forall P \in \lang{\stm_\RA'}\cup \lang{\stm_\LA'}. \forall k \in \Nat.
  k\ge \#_r^\stm(P)+1\to \llbracket P^\alpha_k\rrbracket =\llbracket P\rrbracket
  $$
  where $\llbracket \cdot \rrbracket$ is the function in Definitions \ref{def:simprafuneval} or
  \ref{def:simplafuneval}.
\end{remark}
\begin{proof}
  By induction on the syntax of $P$ and showing an analogous result for exressions,
  namely that expression evaluate in the same way in the original store and in the
  alpha converted store.
\end{proof}

\begin{defn}
  \label{def:flpseudo}
  The family of programs $\mathit{fl}_k()$ is defined as follows:
  \begin{align*}
  \mathit{fl}_k\coloneqq& \while{Y_k\sqsubseteq\epsilon}{\\
  &\quad Y_k \takes \listenc{} 0;\\
  &}\\
  &Y_{k+1}\takes X_1;\\
  &Y_{k+2}\takes X_2;\\
  &X_1\takes Y_{k+3};\\
  &X_2\takes Y_{k};\\
  &\LL{\simulate}^\alpha_{\max (|\#_r^\stm(\LL{\simulate}|+1,k)}\\
  &\while {R \sqsubseteq \epsilon}{\\
  &\quad X_1 \takes \listenc{} 0;\\
  &\quad X_2 \takes Y_{k+3};\\
  &\quad\LL{\rel}^\alpha_{\max (|\#_r^\stm(\LL{\rel})|+1,k)}\\
  &\quad X_1\takes R;\\
  &\quad \rb;\\
  &\quad X_2 \takes R;\\
  &\quad\LL{\rel}^\alpha_{\max (|\#_r^\stm(\LL{\rel})|+1,k)}\\
  &\quad X_2 \takes R;\\
  &\quad X_1 \takes Y_k;\\
  &\quad\LL{\rel}^\alpha_{\max (|\#_r^\stm(\LL{\rel})|+1,k)}\\
  &\quad Y_k \takes R;\\
  &}\\
  & X_1 \takes Y_{k+3};\\
  & X_2 \takes Y_k;\\
  &\LL{\simulate}^\alpha_{\max (|\#_r^\stm(\LL{\simulate})|+1,k)}\\
  & X_1 \takes Y_{k+1};\\
  & X_2 \takes Y_{k+1};
  \end{align*}
\end{defn}

Basically, this piece of code implements an associative function, which is stored
in the register $Y_k$. It uses exactly the same encoding we defined in \ref{def:funenc}.
This allows us to reuse the function $\simulate$
we defined in $\POR$ to simulate finite functions -- i.e. to look up associative tables.
If a certain coordinate is present in the function's domain, we are certain that
the second $\while {}{}$ will not be executed by the correctness
of $\simulate$ (Lemma \ref{lemma:simcorr}) and by Lemma \ref{lemma:portosifp},
so it ends returning the value which is associated to that coordinate in the table
(the simulated value of $\omega (\store(Y_{k+3})))$). Otherwise, the body of the
orcale is executed once only and ends up adding an entry for the coordinate
$\omega (\store(Y_{k+3})))$ to the simulated oracle.
%
Before proceding with the definitions of $\beta$ and $\gamma$ we prove some results
we use in the proof of Proposition \ref{prop:ratola}. We already mentioned these
results: they allow the weakening of the canonical simulation relation between
$\leadstora$ and $\leadstola$. The first concernes the
registers added by the definition of $\mathit{fl}_k$: we show that if a transition is defined
for a store $\store$, then it's identical the registers used by a program $P_\RA$
on all the other stores which preserve the values in such registers plus
the register which stores the associative table. This way,
when we prove the transitive closure of Proposition \ref{prop:ratola},
we can limit ourselves to show that the two transitions (i.e. the original and the simulated)
are on the registers which are atually used by the program $P_\RA$ and the register
containing the associative table. Finally, we want to weaken again this property
showing that the associative table computed by the program can differ
from the one described by $\beta$: one can be the permutation of the other.


% \begin{lemma}
%   \label{lemma:largerstore1}
%   $\forall P \in \lang{\stm_\RA}$ (resp. $\lang{\stm_\RA}$) for each store $\store$
%   and foreach $\Psi\ \subseteq \Os$, if there exist $P', \store', \Psi'$ such that
%   $\langle P, \store, \Psi\rangle\leadsto_\cdot\langle P', \store', \Psi'\rangle$
%   for $\cdot \in \{\RA, \LA\}$, it holds that
%   $\forall \Gamma \supseteq \store.$, if $\store\subseteq \Gamma$ then there exist a
%   $\Gamma'\supseteq \store'$ such that
%   $\langle P, \Gamma, \Psi\rangle\leadsto_\cdot\langle P', \Gamma', \Psi'\rangle$.
% \end{lemma}
% \begin{proof}
%   The proof is by induction on the syntax of $\stm$, basically observing that
%   if $\Gamma \supseteq \store$ and $\store(Id)=\sigma$ then $\Gamma(Id)=\sigma$.
% \end{proof}
%
% This result can be generalized to the indexed transitive closure:
%
% \begin{lemma}
%   $\forall n \in \Nat, P \in \lang{\stm_\RA}$ (resp. $\lang{\stm_\RA}$)
%   for each store $\store$
%   and foreach $\Psi\ \subseteq \Os$, if there exist $P', \store', \Psi'$ such that
%   $\langle P, \store, \Psi\rangle\leadsto_\cdot^n\langle P', \store', \Psi'\rangle$
%   for $\cdot \in \{\RA, \LA\}$, it holds that
%   $\forall \Gamma \supseteq \store.$, if $\store\subseteq \Gamma$ then there exist a
%   $\Gamma'\supseteq \store'$ such that
%   $\langle P, \Gamma, \Psi\rangle\leadsto_\cdot^n\langle P', \Gamma', \Psi'\rangle$.
% \end{lemma}
% \begin{proof}
%   The proof is by induction on $n$. The base case is trivial. The inductive case
%   can be obtained applying Lemma \ref{lemma:largerstore1} to the inductive
%   hypothesis.
% \end{proof}
%
% Upon the definition of $\alpha$, we have to write the definitions of
% $\beta$ and $\gamma$. Let us start from $\beta$; this function has to describe the
% configuration of the output program. From Lemma \ref{lemma:largerstore1} we know
% that we can simply add to the store $\store$ the minimal set of registers needed
% by $\alpha(P_\RA)$ to compute its result.

% This can be proven showing that if two stores $\store$ and $\Gamma$ are identical
% on all the names used by a $P \in \lang {\stm_\RA}$, for a set of oracles
% $\Psi \subseteq \Ss^\Nat$ they reduce producing two stores $\store'$ and
% $\Gamma'$ which are identical on the values of the registers used by $P$. Formally:

\begin{lemma}
  \label{lemma:workreginvariance}
  For each progam $P \in \lang{\stm}$, for each store $\store$ and $\Gamma$,
  if $\forall G \in \#_r^\stm(P).\store(G)=\Gamma(G)$ and
  $\store(Y_{{|\#_r^\stm(P)|+1}})$ is a permutation of
  $\Gamma(Y_{{|\#_r^\stm(P)|+1}})$ then for each set of
  $\Psi \subseteq \Ss^\Nat$ it holds that
  \begin{align*}
    &\left(\alpha(P), \store, \Psi\rangle \leadstola \langle Q, \store', \Psi'\rangle\right)\to\\
    &\left(\alpha(P), \Gamma, \Psi\rangle \leadstola \langle Q, \Gamma', \Psi'\rangle\right)\land\\
    &\forall G \in \#_r^\stm(P)\land \store'(G)=\Gamma'(G) \land\\
    &\store'(Y_{{|\#_r^\stm(P)|+1}}) \text{ is a permutation of }\Gamma'(Y_{{|\#_r^\stm(P)|+1}})
  \end{align*}
\end{lemma}

\begin{proof}
  By cases on the syntax of $P$. All the cases are trivial apart fron $\mathit{fl}_k$.
  In this case, first observe that $k={|\#_r^\stm(P)|+1}$. One may observe that
  the only registers which are in  $\#_r^\stm(P)$ and are used by $\alpha(\fl e)$
  are the registers of the family $X_i$ adn $R$. Concerning $R$, we an derive that
  it's only affected by $\rb$, but since both the reductions use the same set of
  oracles $\Psi$ (and because we are supposing that they are ending up with the
  same register $\Psi'$), we can derive that the call to $\rb$ had the same result,
  so by definition fo $\mathit{fl}_k$, $\store'(R)=\Gamma'(R)$. The registers of
  the family $X_i$ are invariant because of the definitions of $\mathit{fl}_k$
  and of the invariant on $\LL\cdot$: it accesses those registers as read-only.
  Moreover, the $\alpha$-conversion of such program makes those pieces of code
  independent from all the registers used by $P$ as a conequence of the definition
  of Notation \ref{notation:alpha}. Moreover, working on a symbol table $t$ or
  a simbol table $\overline t$ which is a permutation of $t$ in the sense described
  by Proposition \ref{prop:ratola} makes no difference for $\mathit{fl}_k$.
  This as a consequence of Corollary \ref{cor:simperminvariance}, which asserts
  that $\simulate$ is invariant with respect to permutations and Lemma \ref{lemma:portosifp}.
  Finally, adding an entry to two lists preserves the fact that one is the permutation
  of the other.
\end{proof}

This result has two important consequences on the definition of $\beta$: we can
simply define it as a function which defines the value of
$Y_{{|\#_r^\stm(P)|+1}}$. Moreover, it won't be a problem the fact that
the procedure $\mathit{fl}_k$ uses some work registers which aren't used by
$P$, this because only the register used by $P$ determine the next configuration.
%
Before defining $\beta$ we can observe that it won't be a problem if such function
won't be total: Proposition \ref{prop:ratola} requires $\Psi$ to be an intersection
of cylinders, so we can define $\beta$ on that cases only.

\begin{defn}[Function $\beta$]
  \label{def:beta}
  We define
  $$
  \beta:\left(\left(\lang {\stm_\RA'}\times\id\to{\Ss^*}\right)\times \mathcal P (\Bool^\Ss) \right)
  \longrightarrow
  \left(\id\to{\Ss^*}\right)
  $$
  as follows:
  \begin{align*}
  \beta(P, \store, \bigcap_{i=1}^k C(\sigma_i))&:= \store \as {Y_{{|\#_r^\stm(P)|+1}})} {\listenc{\listenc {\sigma_1, b_{C(\sigma_1)}} 2, \ldots, \listenc {\sigma_k, b_{C(\sigma_k)}} 2}k}\\
  \end{align*}
  where
  $$
  b_{C(\sigma)}:= \begin{cases}
  \one & \text{ if } C(\sigma)= P(\sigma)\\
  \zero & \text{ if } C(\sigma)= N(\sigma)
  \end{cases}
  $$
\end{defn}

%
%
% Looking at the inductive definition of
% $\alpha$ we observe that it uses exactly the same registers of $P_\RA$ apart from
% the case of $\fl{e}$. It turns out that this definition depends only on the register
% $Y_k$ for $k={\max (\#_r^\stm(\LL(\rel))+1,\#_r^\stm(\LL(P_\RA))+1)}$
% and the $X_i$ registers, which will be proven neutral for the program. This is
% formally stated by the following Lemmas; the first describes an upper bound to
% the set of registers which affect the result of the reduction.
%
% \begin{lemma}
%   $\forall P \in \lang{\stm_\RA}$ define $\mathit{pa}(P)$
%   the set of registers which can are read by
%   the program prior to their assignment. It holds that
%   $\mathit{pa}(\alpha(P))\subseteq\{Y_{\max (\#_r^\stm(\LL(\rel))+1
%   ,\#_r^\stm(\LL(P_\RA))+1)}\}\cup \mathit{pa}(P)\cup
%    \bigcup_{i \in \Nat}\{X_i\}$.
% \end{lemma}
% \begin{proof}
%   The proof is given by three nexted inductions:
%   \begin{itemize}
%     \item The most external is on the syntax of $P$. It's almost everywhere trivial
%     apart from the $\fl e$ case, because $\alpha(P)=P$ in all these  cases.
%     \item On the $\fl e$ cases, we observe that the expression in the first
%     $\while e s$ statement contains the name $Y_k$ For $k={\max
%     (\#_r^\stm(\LL(\rel))+1,\#_r^\stm(\LL(P_\RA))+1)}$, then the program reads
%     $X_1, X_2$. After that, it holds that, if $\mathit{pa}(\simulate)\cup
%     \mathit{pa}(\rel)\subseteq \bigcap_{i \in \Nat}\{X_i\}$, $\mathit{pa}(P)$
%     does not directly read any other register. To show that we show
%     a stronger result: $\forall f \in \POR. \mathit{pa}(\LL(P))\subseteq
%     \bigcap_{i \in \Nat}\{X_i\}\land \LL(f)$ assigns $R$.
%     To do so, we go by induction on $f \in \POR$.
%     Base cases are trivial. The composition case comes from the IH.
%     The bounded recursion case depends on the IH and some
%     other proofs:
%     \begin{itemize}
%       \item $\forall t \in \Lpw \mathit{pa}(\MM(t))\subseteq
%       \bigcap_{i \in \Nat}\{X_i\}\land \MM(t)$ assigns $R$. This result can be
%       obtained by induction on the syntax of $t$, thanks to the following
%       observation:
%       \item If the $\copyb(Z, S, R)$ pseudo-procedure
%       is inlined in a program where $Z, S, R$
%       have been defined, it causes no reads to undefined registers.
%       \item If the $\trunc(T, R)$ pseudo-procedure
%       is inlined in a program where $T, R$ have been defined, it causes no
%       reads to undefined registers, this proof relies on the previous because
%       it contains inlinings of $\copyb$
%     \end{itemize}
%     The last two results come from definition of the notion of pseudoprocedure
%     and their definitions (Definitions \ref{def:copyb}, \ref{def:trunc})
%   \end{itemize}
%   These results entail that $\mathit{pa}(\simulate)\cup
%   \mathit{pa}(\rel)\subseteq \bigcap_{i \in \Nat}\{X_i\}$, $\mathit{pa}(P)$, so
%   our claim is proved.
% \end{proof}
%
% We can go further showing that $\mathit{fl}$ does not depend on the $X_i$ registers.
%
% \begin{lemma}
% $\forall e \in \lang{\xp}$ and for each
% $k \in \Nat$, for each store $\store$ and for each $\Psi \subseteq \Ss^\Nat$
% there exist a store $\gamma$ and a set of oracles $\Phi \subseteq \Ss^\Nat$ such that
% for each register variation of $\store$ called $\store'$ which does not affect
% $Y_k$, it holds that:
%
% $$
% \left(\langle Y_{k+3}\takes e; fl_k ;\halt, \store, \Psi\rangle \leadstolan * \langle \halt, \Gamma, \Phi\rangle\right)\to
% \left(\langle Y_{k+3}\takes e; fl_k ;\halt, \store', \Psi\rangle \leadstolan * \langle \halt, \Gamma, \Phi\rangle\right)
% $$
% \end{lemma}
% \begin{proof}
%   $\mathit{fl}_k$ reads only from $X_1$ and $X_2$ and reassigns them after
%   its execution, so it is invariant on these registers. Moreover, when we defined
%   $\LL$ we argumented that it depended only on $X_1, \ldots, X_h$ where $h$
%   is the number of arguments of the encoded functions and is invariant on all the
%   other $X_j$ registers. For this reason and
%   For this reason
% \end{proof}
% The previous result, together with Lemma \ref{lemma:largerstore1}, prove that
% the reduction works id and only if $\beta$ assigns only the
% $Y_{\max (\#_r^\stm(\LL(\rel))+1,\#_r^\stm(\LL(P_\RA))+1)}$ register properly.

Finally, we should define $\gamma$ which maps the set of oracles described by
$\leadstora$ to the set descirbed by the relation $\leadstola$. By the definition
of $\alpha$ we gave, it is clear that the accesses to sparse coordinates of the
oracles made by $P$, are replaced by accesses to the initial coordinates of
the oracles of $\alpha(P)$. So the function $\gamma$ wuold simply convert an
intersection of $k$ cylinders of $\Os$ to an intersection of the cylinders
$C(0), \ldots, C(n-1)$ for appropriate polarities.

\begin{defn}[Function $\gamma$]
  \label{def:gamma}
  \begin{align*}
    \gamma(\bigcap_{i=1}^0C(\sigma_i))&:= \Bool^\Nat\\
    \gamma(\bigcap_{i=1}^{k+1}C(\sigma_i))&:=\gamma(\bigcap_{i=1}^{k+1}C(\sigma_i)) \cap \begin{cases}
      P(k+1) &\text{if } C(\sigma_{k+1})=P(\sigma_{k+1})\\
      N(k+1) &\text{if } C(\sigma_{k+1})=N(\sigma_{k+1})\\
    \end{cases}\\
  \end{align*}
\end{defn}

Before giving the proof of Proposition \ref{prop:ratola},
which intuitively shold be valid, we show some technical lemmas.
%
The first states that if two stores are identical on the variables which appear
in an expression, that expression evaluates in the same way in both the stores.
%
The second will be useful in the proof of Lemma \ref{lemma:sifpratosifpla}, and
states that the function $\gamma$ preserves the measure of the input set and of
its image.

\begin{lemma}
  \label{lemma:measureofgamma}
  $\forall \Phi \subseteq \Bool^\Nat. \exists \Psi \subseteq \Bool^\Ss.
  \Psi = \gamma(\Phi)\to \mu(\Phi)=\mu(\Psi)$
\end{lemma}
\begin{proof}
  By induction on the cardinality of $S$: the set which is used for the definition
  of $\gamma$. The hypothesis on $\Psi$ guarantees its existence.
  If $S=\emptyset$, then the result is trivial, because $\mu(\Bool^\Nat)=\mu(\Bool^\Ss)$.
  Otherwise it comes from the induction hypothesis and from the fact that $s$ is
  a set so it contains no repetitions.
\end{proof}


\begin{lemma}[Reduction of expressions]
  \label{lemma:expred}
  $\forall e \in \lang{\xp}.\forall \store, \Gamma.
  (\forall G \in \#_r^\xp(e)) \store(e)=\Gamma(e)\to
  \langle e, \store\rangle \sred \sigma \to \langle e, \Gamma\rangle \sred \sigma$
\end{lemma}
\begin{proof}
  By induction on the syntax of $e$.
  \begin{itemize}
    \item $\epsilon$ is the only base case, and the conclusion is trivial.
    \item For all the other cases, the conclusion is a consequence of the IH(s).
  \end{itemize}
\end{proof}

We can finally prove Proposition \ref{prop:ratola}.

\begin{proof}[Proof of Proposition \ref{prop:ratola}]
  Before getting into the details of the proof, we observe that the fact that
  $\Psi$ is an intersection of cylinders on differnt coordinates, it holds that if
  $\langle P;Q, \store,\Psi\rangle \leadstora \langle P', \store',\Psi'\rangle$
  then $\Psi'$ can always be expressed as an intersection of cylinders.
  This becasue of the definition of $\leadstora$: all therules preserve $\Psi$
  apart from the rules for $\fl e$, which have the precondition that
  $\Psi\cap C(\sigma)\neq \emptyset$ and define the resulting cylinder as $\Psi\cap C(\sigma)$.
  This enatils
  that both the funcions $\beta$ and $\gamma$ are defined on their inputs.

  We proceed by cases on $P$:
  \begin{itemize}
    \item[$Id \takes e$] By construction of $\beta$ we know that the two triplets
    $\langle Id \takes e;Q, \Sigma, \Psi\rangle$ and
    $\Theta(Id \takes e;Q, \Sigma, \Psi)$ have stores which
    are identical on all the registers used by $P$ (namely: $\in \#_r^\stm(P)$).
    This entails that
    $Id \takes e$ and $\alpha(Id \takes e)$ both evaluate to the same assignment
    $\as {Id} \sigma$ because both the expression evaluate to the same value
    (consequnce of Lemma \ref{lemma:expred}).
    So, the ending stores are identical on $\#_r^\stm(P)$.
    Moreover the value contained in $Y_{|\#_r^\stm(P)|+1}$ is not changed by
    both the programs, so the condition on the permutation holds.
    \item[$\while e s$] By construction of $\beta$ we know that thre two triplets
    $\langle Id \takes e;Q, \Sigma, \Psi\rangle$ and
    $\Theta(Id \takes e;Q, \Sigma, \Psi)$ work with stores which
    are identical on all the registerrs used by $P$ (namely: $\#_r^\stm(P)$).
    This entails that
    $e$ evaluates to the same expression $\sigma_e$ in both $P$ and $\alpha(P)$.
    This implies that if the condition is $\one$ in $P$, it is $\one$ in
    $\alpha(P)$, too. We proceed by cases on this proposition.
    \begin{itemize}
      \item If it is true, then it holds that
          $$
          \langle \while e s; Q, \store, \Psi\rangle \leadstora \langle s;\while e s; Q, \store, \Psi\rangle
          $$
          and that
          $$
          \begin{gathered}
          \langle \alpha(\while e s; Q), \beta(\store, \Psi), \gamma(\Psi)\rangle \leadstola\\\quad\quad\quad\quad \langle\alpha(s); \while e {\alpha(s)}; Q, \beta(\store, \Psi), \gamma(\Psi)\rangle =
          \\\quad\quad\quad\quad\langle\alpha(s;\while e s; Q), \beta(\store, \Psi), \gamma(\Psi)\rangle
          \end{gathered}
          $$
          which proves the claim.
      \item Conversely, if the proposition does not hold, it holds that
          $$
          \langle Q, \store, \Psi\rangle \leadstora \langle Q, \store, \Psi\rangle
          $$
          and that
          $$
          \begin{gathered}
          \langle \alpha(\while e s; Q), \beta(\store, \Psi), \gamma(\Psi)\rangle \leadstola\\\quad\quad\quad\quad \langle Q, \beta(\store, \Psi), \gamma(\Psi)\rangle = \langle\alpha(Q), \beta(\store, \Psi), \gamma(\Psi)\rangle
          \end{gathered}
          $$
          which proves the claim.
    \end{itemize}
    \item[$\cdot;\cdot$] The result comes from vacuity of the premise
    \item[$\fl e$] In this case we know that $\Psi$ is an intersection cylinders
     by hypothesis. Let $\langle e, \store\rangle \sred \sigma$. It holds that $\langle e, \beta(\store, \Psi)\rangle \sred \sigma$ for definition of $\beta$ (Definition \ref{def:beta}) and
     Lemma \ref{lemma:expred}. We can procede by cases on $\Psi\subseteq P(\sigma)$.
    Suppose that $\Psi \subseteq P(\sigma)$. We can rewrite the premise applying
    the reduction rule descirbed for the positive cylinder, obtaining
     $$
     \langle \fl e;Q, \store, \Psi\rangle \leadsto_\RA \langle Q, \store\as R \one, \Psi\rangle.
     $$
     It also holds that
     $$
     \langle \alpha(\fl e;Q), \beta(\store, \Psi), \gamma(\Psi)\rangle \leadstolan * \langle \alpha(Q), \Gamma, \Phi\rangle.
     $$
     By definition of $\beta$, we know that $\beta(\store, \Psi)({Y_{|\#_r^\stm(P)|+1}})$
     contains the encoding of an associative table $T$ such that
     $\langle \sigma, \one\rangle \in T$, we have already observed, in the discussion
     after the definition of $\alpha$ (Definition \ref{def:alpha}) that, in this case
     $\alpha(\fl e)$ performs a lookup in such table and returns the value it founds
     in the table, i.e. $\one$. Doing so, $\alpha(\fl e)$ is completely transparent
     on the registers used by the program $P$, because it backups the values in
     $X_1$ and $X_2$ and because of the $\alpha$-conversions of the pieces of
     code embedded in the definition: according to the definition of the names'
     conversion (Notation \ref{notation:alpha}), all the names
     are reassigned apart from the $X_i$s and $R$. Anyway, Lemma
     \ref{lemma:portosifp} ensures that $X_i$s are accessed in read only mode
     and that $R$ contains the output of the function, which, at the end is $\one$,
     as  we argumented above. Moreover all the other registers used by $\mathit{fl} k$
     are above the range of registers used by $P$.
     For this reason we can say that $\Gamma$ is
     equal to $\store\as R \one$ in $R, X_1, X_2$ and in all the registers used
     by $P$ and that
     $\beta(\store, \Psi)({Y_{|\#_r^\stm(P)|+1}})=\Gamma({Y_{|\#_r^\stm(P)|+1}})$
     which is stronger than the condition required by the claim.
     Conversely, suppose that $\Psi \not\subseteq P(\sigma)$. In this case,
     we procede by cases on $\Psi \subseteq N(\sigma)$. If it is true,
     we can repropose the argument above for the premise
     $$
     \langle \fl e;Q, \store, \Psi\rangle \leadsto_\RA \langle Q, \store\as R \zero, \Psi\rangle.
     $$
     showing that the claim holds with an argument analogous with the one proposed above.
     Finally, suppose that $\Psi \not \subseteq P(\sigma)\land \Psi \not \subseteq N(\sigma)$.
     It means that both the cylindes $P(\sigma)$ and $N(\sigma)$ do not appear
     in the definition of $\Psi$. It holds that
     \begin{align*}
     &\langle \fl e;Q, \store, \Psi\rangle \leadsto_\RA \langle Q, \store\as R \one, \Psi\cap P(\sigma)\rangle \land\\
     &\langle \fl e;Q, \store, \Psi\rangle \leadsto_\RA \langle Q, \store\as R \zero, \Psi\cap N(\sigma)\rangle
     \end{align*}
     We will take in exam only the first case, the second is analogous.
     In this case, suppose that $\Psi$ is the intersection of $k$ cylinders, then
     $$
     \langle \alpha(\fl e;Q), \beta(\store, \Psi), \gamma(\Psi)\rangle \leadstolan * \langle \alpha(Q), \Gamma, \gamma(\Psi)\cap P(k+1)\rangle.
     $$
     It also holds that
     $$
     \langle \alpha(Q), \Gamma, \gamma(\Psi)\cap P(k+1)\rangle=\langle \alpha(Q), \Gamma, \bigcap_{i=1}^k C(i)\cap P(k+1)\rangle = \langle \alpha(Q), \Gamma, \gamma(\Psi \cap P(\sigma))\rangle
     $$
     For the definition of $\leadstola$ in the case of $\rb$ and
     the definition of $\mathit(fl) k$, this the program puts $\one$ in $R$ and
     adds a new entry in
     the associative table, in a coordinate which is not necessairly the
     position described by $\beta$, but the claim still holds because
     the two encoded tables are one the permutatio of the other.
  \end{itemize}
\end{proof}

This result concernes only a single single step of the transition, for this
reason we need to employ it to prove the inductive case of a analogous result
concerning $\leadstoran n$ and $\leadstolan n$ insetad of $\leadstora$ and
$\leadstola$. For these reason, the statement of the result which we are addressing
is almost identical to the statement of Proposition \ref{prop:ratola},
with the difference that we generalize the statement to each number of step $n \in \Nat$.
%
Basically, the inductive case will rely on the coscusions we draw in Lemma
\ref{lemma:workreginvariance} used to justify the definition of the function
$\beta$. In order to use the resuslt, we must
show that it holds for the $\leadstolan n$ relations, too.

\begin{lemma}
  \label{lemma:workreginvariance2}
  For each progam $P \in \lang{\stm}$, for each store $\store$ and $\Gamma$,
  if $\forall G \in \#_r^\stm(P).\store(G)=\Gamma(G)$ and
  $\store(Y_{{|\#_r^\stm(P)|+1}})$ is a permutation of
  $\Gamma(Y_{{|\#_r^\stm(P)|+1}})$ then for each set of
  $\Psi \subseteq \Ss^\Nat$ it holds that
  \begin{align*}
    &\left(\alpha(P), \store, \Psi\rangle \leadstolan n \langle Q, \store', \Psi'\rangle\right)\to\\
    &\left(\alpha(P), \Gamma, \Psi\rangle \leadstolan n \langle Q, \Gamma', \Psi'\rangle\right)\land\\
    &\forall G \in \#_r^\stm(P)\land \store'(G)=\Gamma'(G) \land\\
    &\store'(Y_{{|\#_r^\stm(P)|+1}}) \text{ is a permutation of }\Gamma'(Y_{{|\#_r^\stm(P)|+1}})
  \end{align*}
\end{lemma}
\begin{proof}
  We proceed by induction on $n$:
  \begin{itemize}
    \item [$0$] This case is trivial, beacuse $\leadstoran 0$ and $\leadstolan 0$
    are the identity relation.
    \item [$n+1$] The IH states that the simulation of the first
    $n$ steps produces a configuration which is almost everywhere identical to
    $\langle Q, \store', \Psi'\rangle$, with the differences that
    \begin{enumerate}
      \item The assocaitive table stored in $\store'(Y_{{|\#_r^\stm(P)|+1}})$
      is a permutation of $\Gamma'(Y_{{|\#_r^\stm(P)|+1}})$,
      \item Some values on the registers which are not used by $P$ can differ.
    \end{enumerate}
    The application of Lemma \ref{lemma:workreginvariance} to the inductive
    hypothesis produced the claim we are addressing.
  \end{itemize}
\end{proof}

\begin{lemma}
  \label{lemma:rantolan}
  For $\alpha, \beta, \gamma$ and $\Theta$ defined respectively in Definitions
  \ref{def:alpha}, \ref{def:beta}, \ref{def:gamma} and \ref{def:Theta}, it holds that:
  \begin{align*}
  &\forall n \in \Nat.\forall P \in \lang{\stm_\RA'}.\forall \store.\forall \Psi \in \Os.\\
  &\quad\exists S \subseteq \Ss. \Psi = \bigcap_{s \in S}C(s) \to\\
  &\quad\quad\forall Q.\exists P', \store', \Psi'.\langle P;Q, \store, \Psi\rangle \leadstoran n \langle P', \store', \Psi'\rangle \to\\
  &\quad\quad\quad\exists \Gamma, \Phi \subseteq \Ss^\Nat.\exists k\ge n.\Theta(P;Q, \store, \Psi) \leadstolan k \langle\alpha(P'), \Gamma, \gamma(\Psi')\rangle\land\\
  & \quad\quad\quad\quad \forall G \in \#_r^\stm(P).\beta(P', \store', \Psi')(G)=\Gamma(G) \land\\ & \quad\quad\quad\quad\quad\beta(P',\store', \Psi')(Y_{{|\#_r^\stm(P)|+1}})=\listenc{\listenc {\sigma_1, b_1} 2, \ldots, \listenc {\sigma_t, b_t} 2}t \land\\
  & \quad\quad\quad\quad\quad \Gamma(Y_{{|\#_r^\stm(P)|+1}})=\listenc{\listenc {\sigma_{f(1)}, b_{f(1)}} 2, \ldots, \listenc {\sigma_{f(t)}, b_{f(t)}} 2}t
  \end{align*}
  for some $t \in \Nat$ and some permutation $f:  \{1, \ldots, t\}\longrightarrow \{1, \ldots, t\}$
  and with $k$ linear in $n$
\end{lemma}
\begin{proof}
  We proceed by induction on $n$:
  \begin{itemize}
    \item [$0$] This case is trivial, beacuse $\leadstoran 0$ and $\leadstolan 0$
    are the identity relation.
    \item [$n+1$] The IH states that the simulation of the first
    $n$ steps produces a configuration which is almost everywhere identical to
    $\Theta (P', \Sigma', \Psi')$, with the differences that
    \begin{enumerate}
      \item The assocaitive table stored in $Y_{{|\#_r^\stm(P)|+1}}$ is a permutation
      of $\beta(P', \store', \Psi')$,
      \item Some values on the registers which are not used by $P$ can differ.
    \end{enumerate}
    The application Lemma \ref{lemma:workreginvariance} allow us to work on
    $\Theta (P', \Sigma', \Psi')$ instead of the
    configuration yielded by the IH because.
    So, we can apply Proposition \ref{prop:ratola} to obtain the claim.
  \end{itemize}
  The linearity of $k$ holds because Proposition \ref{prop:ratola}
  states that each step on the source program can be simulated with a
  constant number of steps of the destination program
\end{proof}

Lemma \ref{lemma:rantolan} can be instantiated to match the premises of
Characterization \ref{char:setofos}.

\begin{proof}[Proof of lemma \ref{lemma:sifpratosifpla}]
  We get the results we were aiming to instantiating Lemma \ref{lemma:rantolan}
  with $\store =[]\as X, x$, $\Psi=\Os$ and putting halt at the end of the program.
  Then we get that $\alpha(P;\halt)$ reduces to $\halt$, too and that the stores
  are identical on the value of $R$, call that value $\tau$
  . By the characterization \ref{char:setofos},
  we get that
  $$
  \Psi'=
    \{\omega \in \Bool^\Ss| \llbracket P\rrbracket (x, \omega)= \tau\}
  $$
  and that
  $$
    \gamma(\Psi')=\{\eta \in \Bool^\Nat| \llbracket \alpha(P) \rrbracket(x, \eta)= \tau\}
  $$
  Finally Lemma \ref{lemma:measureofgamma} proves that
  $$
  \mu\left(\{\omega \in \Bool^\Ss| \llbracket P\rrbracket (x, \omega)= \tau\}\right)=
  \mu(\Psi')=\mu(\gamma(\Psi'))=
    \mu\left(\{\eta \in \Bool^\Nat| \llbracket \alpha(P) \rrbracket(x, \eta)= \tau\}\right)
  $$
  This concludes the first part of the proof.

  Suppose that a $P$ is poly-time, Lemma \ref{lemma:rantolan} states
  that $\alpha(P)$ is poly-time, too. This completes the proof.
\end{proof}



























\subsubsection{From $\SIFPLA$ to $\SFPOD$}
\label{subsub:sifplatosfpod}

At this point we have shown that $\POR$ can be reduced to a formalism which does
not support random access to the tape, namely $\SIFPLA$. In order to complete
the reduction, we want to show that such formalism can be reducecd to
$\SFPOD$: the variant of $\SFP$ which reads characters from the oracle tape
on-demand. In the next section, we will show that $\SFPOD$ can
be reduced to $\SFP$.
%
This section is structured as follows: first, we define the formalism of the
On-Demand Stream Machine, in order to deifne $\SFPOD$, then we prove that
$\SIFPLA$ can be reduced to $\SFPOD$.
%
As for the case of orinary Stream Machines (Definition \ref{def:sm}), we limit
ourselves to single tape machine, because they naturally scale to multitape
machines.

%%% DF
%%%   Stream Machine

\begin{defn}[On-Demand Stream Machine]
  \label{def:odsm}
An \emph{On-Demand Stream Machine} is a quadruple
$M:= \langle \Qs,\Sigma, \delta,q\rangle$,
where:
\begin{itemize}
\itemsep0em
\item $\Qs$ is a finite set of states ranged over by
$q_1,\dots, q_n$
%
\item $\Sigma$ is a finite set of characters ranged
over by $c_1,\dots, c_n$
%
\item $\delta:\Qs \times \Sigmab \times
\{\zzero, \oone, \natural\} \longrightarrow \Qs
\times \Sigmab \times \{L,R\}$
\item $q\in \Qs$ is an initial state,
\end{itemize}

Moreover, we want $\delta$ such that $\forall c \in \Sigmab, q \in \Qs.$:
\begin{itemize}
  \item If
  $\delta(q, c, \natural)$ is defined, then $\delta(q, c, \zzero)$ and $\delta(q, c, \oone)$
  are not.
  \item $\delta(q, c, \zzero)\neq \delta(q, c, \oone)$.
\end{itemize}
\end{defn}

Observe that the only differnce between Definition \ref{def:odsm} and
Definition \ref{def:sm} is in the $\delta$ function: indeed we
extend the character which matches the oracle tape with an additional symbol,
$\natural$ wich doesn't match any character on the tape and which will cause
that tape not to advance.
%
The configuration of \emph{On-Demand Stream Machine} can be represented in
the same way of the configurations of ordinary stream machines, i.e. by
means of a tuple which contains the current state and the configuration of
the tapes.
%
The machine's transition function is different from
Definition \ref{def:smtransfun}, because it needs to allow configurations
which cause no advancements on the oracle tape.

%%% DF
%%% Stream Machine Reachability Function
\begin{defn}[Stream Machine Transition Function]
  \label{def:smodtransfun}
Given a stream machine $M=\langle \Qs,
\Sigma, \delta, q\rangle$,
we define the partial transition function
$\vdash_{\delta} \Sigmab^* \times \Qs
\times \Sigmab^* \times \{\zzero,
\oone\}^{\Nat} \longrightarrow \Sigmab^*
\times \Qs \times \Sigmab^* \times \{\zzero,
\oone\}^{\Nat}$
between two configurations of $M_S$ as:
%
\begin{align*}
  \langle \sigma, q, c\tau, \eta\rangle
  \vdash_{\delta} \langle\sigma c', q', \tau, \eta\rangle
  \ \ \ \ \ \ \ \ \ \ \ \ \ &\text{ if }
  \delta (q,c,\natural)
  = \langle q',c',R\rangle
  \\
  %
  \langle \sigma c_0, q, c_1\tau,\eta\rangle
  \vdash_{\delta} \langle \sigma, q', c_0c_1'\tau,
  \eta\rangle
   \ \ \ \ \ \ \ \ \ \ \ \ \ &\text{ if }
  \delta (q, c_1,\natural)
  = \langle q', c_1', L\rangle  \\
  %
  \langle \sigma, q, c\tau, \zzero \eta\rangle
  \vdash_{\delta} \langle\sigma c', q', \tau, \eta\rangle
  \ \ \ \ \ \ \ \ \ \ \ \ \ &\text{ if }
  \delta (q,c,\zzero)
  = \langle q',c',R\rangle
  \\
  %
  \langle \sigma c_0, q, c_1\tau, \zzero
  \eta\rangle
  \vdash_{\delta} \langle \sigma, q', c_0c_1'\tau,
  \eta\rangle
   \ \ \ \ \ \ \ \ \ \ \ \ \ &\text{ if }
  \delta (q, c_1,\zzero)
  = \langle q', c_1', L\rangle  \\
  %
  \langle \sigma, q, c\tau, \oone \eta\rangle
  \vdash_{\delta}
  \langle \sigma c', q', \tau, \eta\rangle
   \ \ \ \ \ \ \ \ \ \ \ \ \ &\text{ if }
   \delta(q, c, \oone)=
   \langle q', c', R\rangle \\
   %
   \langle \sigma c_0, q, c_1\tau,
   \oone\eta\rangle
   \vdash_{\delta} \langle \sigma,
   q', c_0c_1' \tau, \eta \rangle
    \ \ \ \ \ \ \ \ \ \ \ \ \ &\text{ if }
   \delta(q, c_1,\oone)
   = \langle q',c_1', L\rangle.
\end{align*}
\end{defn}

The family of On-Demand Stream Machine Reachability Functions are defined
exactly as in Definition \ref{def:smreachfuns}, even the notion of
final configuration (Notation \ref{notation:smfin}),
value computed by a Stream Machine (Definition \ref{def:smval}) and of
polynomial Stream Machine (Definition \ref{def:sfpmachine}) scale naturally to
On-Demand Stream Machines.
%
Finally, we can define the set $\SFPOD$.

\begin{defn}[$\SFPOD$]
  \label{def:sfpod}
  %\small
  \[
  \SFP := \{ f \in \Ss \times \Bool^\Nat~|~ \text{There is a Polynomial Canonical OD Stream
  Machine $M$ such that }f=f_M\}
  \]
  \normalsize
\end{defn}


Finally we need to state one of our last results, which now should be intuitive.
We will not show it formally because this kind of reductions are administrative
an pervasive in the literature. Moreover, showing it formally would require too
much technical work.
%
For these reason we will only describe the On-Demand Stream Machine
which corresponds to the encoded $P \in \lang{\stm_\LA}$.

\begin{prop}
  \label{prop:SFPODimplSIFPLA}
  For every $P \in \lang{\stm_\LA}$ there exists a $M_P \in \SFP$ such that
  for every $x \in \Ss$ and $\eta \in \Bool^\Ss$, $P(x, \eta)=P(x, \eta)$.
  Moreover, if $P$ is poly-time, then $M_P$ is poly-time.
\end{prop}
\begin{proof}
%
The construction relies on the fact that we can implement a $\SIFPLA$ program
by means of a multi-tape $\SFPOD$ machine which uses a tape to store the values
of each register, plus an additional tape containing the partial results
obtained during the evaluation of the expressions
and another tape containing $\eta$.

We will denote with $e$ the tape used for storing the result coming from
the evaluation of the expressions.

The machine works thanks to some invariant properties:

\begin{itemize}
\item On each tape the menaingful values are stored on the immediate right of the head.
\item The result of the last expression evaluated is stored on the $e$ tape on the immediate right of the head.
\item After any assignment operation, the value on the $e$ is not meaningful anymore.
\end{itemize}


The encoding of a $\SIFP$ expression can be easily computed on the $e_0$ tape:
accesses to the identifiers basically consist in copy of tapes, which is a simple operation,
due to the invariants properties mentioned above.
Moreover, when we defined the $\SIFPRA$ we have used a restricted set of expressions:
concatenations are easily implemented by the addition of a character at the
end of the $e_0$ tape which contains the value of the last expression computed,
as stated by the induction hypotheis on the invariant properties.
The only non-trivial operations are the binary ones, but since one of the
two operands is a register idetifier, this allows the machine to compare $e$
with the tape which corresponds to the identifier, and to replace the content of $e$
with the result of the comparion, which is either $\zzero$ of $\oone$.
All these operatons can be implemented without consuming any character
on the oracle tape.
%
To each statement $s_i$, we assign a sequence of machine states,
$q_{s_i}^I, q_{s_i}^1, q_{s_i}^2, \ldots, q_{s_i}^F$.
%
\begin{itemize}
  \item Assignments consist in copy of the value in $e$ to the tape corresponding to
  the destination register. This can be implemented without consuming any character
  on the oracle tape.
  \item The sequencing operation $s;t$ can be implemented inserting in $\delta$
  a composed transition from $q_s^F$ to $q_t^I$ which does not consume the oracle tape.
  \item A while statement $s:= \while f t$ requires the evaluation of $f$ and
  then passing to the evaluation of $t$, if such condition is true, or stepping
  to the next transition if it exists and such condition is false.
  After the evaluation of the body, the machine returns to the initial state of
  this statemen, namely: $q_s^I$.
  \item A $\rb$ statement is implemented consuming a charater on the tape and copying
  its value on the tape which corresponds to the register $R$.
\end{itemize}

the following invariants hold at the beginning of the execution and are kept true
throughout $M_P$'s execution. In particular, if we assume $P$ to be poly-time,
after the simulation of each statement it holds that:

\begin{itemize}
  \item The length of the non blank portion of the first tapes corresponding to
  the register is polynomially bounded because their contents are precisely
  the contents of $P$'s registers
  \item The length of all the tapes corresponding to the registers point to the
  leftmost symbol
\end{itemize}

It is well known that the reduction of the number of tapes on a poly-time Turng Machine
comes with a polynomial overhead in time; for this reason, we can conclude that
the poly-time multi-tape On-Demand Stream Machine we introduced above can be \emph{shrinked}
to a poly-time Canonical On-Demand Stream Machine. This concludes the proof.
\end{proof}

\begin{cor}
  \label{cor:SIFPLAtoSFPOD}
  For each poly-time $P\in \lang {\stm_\LA}$ there exists a multitape poly-time $\SFPOD$ machine $M_P$
  such that
  $$
  \mu\left(\{\eta \in \Bool^\Nat| \llbracket P\rrbracket (x, \eta)= \tau\}\right)
  =
    \mu\left(\{\eta \in \Bool^\Nat|  M_P(x, \eta)= \tau\}\right)
  $$
\end{cor}
\begin{proof}
  Consequence of Proposition \ref{prop:SFPODimplSIFPLA}, indeed:
  $$
\{\eta \in \Bool^\Nat| \llbracket P\rrbracket (x, \eta)= \tau\}
  =
    \{\eta \in \Bool^\Nat|  M_P(x, \eta)= \tau\}
  $$
\end{proof}

Just to sum up, we want to relate $\POR$ directly with $\SFPOD$.
We get the following result:

\begin{cor}
  For each $f\in \POR$ there exists an $\SFPOD$ machine $M_f$
  such that
  $$
  \mu\left(\{\omega \in \Bool^\Ss| f (x, \eta)= \tau\}\right)
  =
    \mu\left(\{\eta \in \Bool^\Nat| M_P(x, \eta)= \tau\}\right)
  $$
\end{cor}
\begin{proof}
  From Corollary \ref{cor:PORtoSIFPRAweak}
  we get that
  $$
  \forall x, y.
  \mu\left(\{\omega \in \Bool^\Ss| f(x, \omega)=y\}\right)=
  \mu\left(\{\omega \in \Bool^\Ss| \llbracket P\rrbracket (x, \omega)=y\}\right)
  $$
  for some poly-time $P \in \lang{\stm_\RA}$. Lemma \ref{lemma:sifpratosifpla}
  shows that
  $$
  \mu\left(\{\omega \in \Bool^\Ss| \llbracket P\rrbracket (x, \omega)= y\}\right)=
  \mu\left(\{\eta \in \Bool^\Nat| \llbracket Q \rrbracket(x, \eta)= y\}\right)
  $$
  For some poly-time $Q \in \lang{\stm_\RA}$. Finally, Corollary \ref{cor:SIFPLAtoSFPOD}
  states that:
  $$
  \mu\left(\{\eta \in \Bool^\Nat| \llbracket Q\rrbracket (x, \eta)= \tau\}\right)
  =
    \mu\left(\{\eta \in \Bool^\Nat|  M_P(x, \eta)= \tau\}\right)
  $$
  Putting togethe all these equivalences, we get:
  $$
    \mu\left(\{\omega \in \Bool^\Ss| f(x, \omega)=y\}\right)=\mu\left(\{\eta \in \Bool^\Nat|  M_P(x, \eta)= \tau\}\right)
  $$
  The introduction of the existential on $M_P$ comcludes the proof.

\end{proof}


























\subsubsection{From $\SFPOD$ to $\SFP$}
\label{subsub:sfpodtosfp}
The aim of this section is to show that having a formalism which supports
on-demand access to a source of randomness, or a formalism which is
\emph{fully randomic} (in the sense that each transition has a random outcome)
makes no difference.

\begin{prop}
  \label{prop:SFPODtoSFP}
  For every $M \in \SFPOD$ there exists a $N \in \SFP$ such that
  for every $x \in \Ss$ there exists a Reduction Tree $t \in \RT{\Nat} M x$
  and a Reduction Tree $\overline t \in \RT{\SFP} N x$
  such that every path $C$ in $\mathit{cylp}(t)$,
  the corresponding path $D$ in $\mathit{cylp}(\overline t)$ is such that
  $M(x, C) = N(x, D)$.
\end{prop}

Even in this case, the proof of this result relies on a reduction: in particular,
the reduction from $\SFPOD$ to $\SFP$ takes an On-Demand Stream Machine and
produces a Stream Machine which is equivalent to the first with respect to
Proposition \ref{prop:SFPODtoSFP}. This is done removing the $\natural$ transitions
form the transition function $\delta$ and replacing them with ordinary transitions.
%
The proof of Proposition \ref{prop:SFPODtoSFP} will follow the schema of Proposition
\ref{prop:PORimplSFP}, but with some simplifications:

\begin{itemize}
  \item We do dot need to extend the transition functions to total ones
  (i.e. $\reachesf n \delta$, or similar extensions), because
  our encoding will preserve the number of steps used by the reduction and so it
  won't run the machine for an overapproximated number of steps.
  \item The configuration of an On-Demand Stream Machine and the configuration of an
  ordinary stream amchine, mathematically, are the same type of object.
\end{itemize}

First, we introduce the encoding which turns a transition function for the $\SFPOD$
machine $M$ into a transition function for an equivalent machine in $\SFP$
(in the sense of Proposition \ref{prop:SFPODtoSFP}).

\begin{defn}[Encoding frmom On-Demand to Canonical Stream Machines]
  \label{def:SFPODtoSFPmap}
  We define the encodig from an On-Demand Stream Machine to a Canonical Stream Machine
  as below:
  $$
    H := \langle \mathbb Q, \Sigma, \delta, q_0\rangle \mapsto \left\langle \mathbb Q, \Sigma, \bigcup\Delta_H(\delta), q_0\right\rangle
  $$
  where $\Delta_H$ is defined as follows:
  \begin{align*}
    \Delta_H(\langle p, c_r, \zzero, q, c_w, d\rangle) &:= \{\langle p, c_r, \zzero, q, c_w, d\rangle\}\\
    \Delta_H(\langle p, c_r, \oone, q, c_w, d\rangle) &:= \{\langle p, c_r, \oone, q, c_w, d\rangle\}\\
    \Delta_H(\langle p, c_r, \natural, q, c_w, d\rangle) &:= \{\langle p, c_r, \zzero, q, c_w, d\rangle, \langle p, c_r, \oone, q, c_w, d\rangle\}\\
  \end{align*}
\end{defn}

% In a similar fashion to what we did in Section \ref{sec:SFPtoPOR}, we define a
% canonical reduction tree for a $\SFPOD$ reduction, then we show that this tree
% can be relabeled to match the corresponding reduction in $\SFP$.

As we anticipated, Proposition \ref{prop:SFPODtoSFP}, will be proven as a consequence of
a slightly stronger result. Namely: Lemma \ref{lemma:SFPODtoSFP}. Before, we prove a
thechnical result which describes the behaviour of $H(\delta)$ with respect to $\delta$,
i.e. Lemma \label{lemma:SFPODtoSFPtech}.
Lemma \ref{lemma:SFPODtoSFP} is a direct consequence of Lemma \label{lemma:SFPODtoSFPtech}.

\begin{lemma}
  \label{lemma:SFPODtoSFPtech}
  For every $M = \langle \Qs, \Sigma, \delta, q_0\rangle
  \in \SFPOD$, the there exists a $N = \langle \Qs, \Sigma, H(\delta), q_0\rangle
  \in\SFP$ such that
  for every $\langle \sigma, q, \tau, \eta\rangle$ configuration of $M$, if
  $\xi =c_1c_2\ldots c_k$ with $c_i \in \Bool$ for $1 \le i \le k$, then
  \begin{enumerate}
    \item if $\langle \sigma, q, \tau, \xi\eta\rangle \reaches {k} \delta \langle \sigma', q', \tau', \xi\eta\rangle$, then
    $\langle \sigma, q, \tau, \xi\eta\rangle \reaches {k} {H(\delta)} \langle \sigma', q', \tau', \eta\rangle$.
    \item if $\langle \sigma, q, \tau, \bbool\eta\rangle \reaches {1} \delta \langle \sigma', q', \tau', \eta\rangle$, then
    $\langle \sigma, q, \tau, \bbool\eta'\rangle \reaches {1} {H(\delta)} \langle \sigma', q', \tau', \eta'\rangle$.
  \end{enumerate}
\end{lemma}

\begin{proof}
  We start with the first claim, the proof is by induction on $k$.
  \begin{itemize}
    \item If $k=0$, the thesis is trivial.
    \item If $k=j+1$, the hypothesis induction states that
    $$
    \forall \chi =c_1c_2\ldots c_j.
\left(\langle \sigma, q, \tau, \chi\eta\rangle \reaches {j} \delta \langle \sigma'', q'', \tau'', \chi\eta\rangle \right)\leftrightarrow
\left(\langle \sigma, q, \tau, \chi\eta\rangle \reaches {j} {H(\delta)} \langle \sigma'', q'', \tau'', \eta\rangle\right)
    $$
    we know that
    $$
    \left(\langle \sigma, q, \tau, c_1c_2\ldots c_{j+1}\eta\rangle \reaches {j+1} \delta \langle \sigma', q', \tau', c_1c_2\ldots c_{j+1}\eta\rangle \right)
    $$
    so we derive that
    $$
    \left(\langle \sigma, q, \tau, c_1c_2\ldots c_j(c_{j+1}\eta)\rangle \reaches {j} \delta \langle \sigma'', q'', \tau'', c_1c_2\ldots c_j(c_{j+1}\eta)\rangle \right)\reaches 1\delta \langle\sigma', q', \tau', c_1c_2\ldots c_{j+1}\eta\rangle
    $$
    we can feed this sentence to the induction hypothesis obtaining:
    $$
    \left(\langle \sigma, q, \tau, c_1c_2\ldots (c_{j+1}\eta)\rangle \reaches {j} {H(\delta)} \langle \sigma', q', \tau', c_{j+1}\eta\rangle\right)
    $$
    Finally, we observe that since
    $$
    \langle \sigma'', q'', \tau'', c_1c_2\ldots c_j(c_{j+1}\eta)\rangle \reaches 1\delta\langle \sigma', q', \tau', c_1c_2\ldots c_{j+1}\eta\rangle
    $$
    then, acording to Definition \ref{def:SFPODtoSFPmap}, the $\delta$
    contains a transition labeled with $\natural$  which matches exactly the
    current configuration, moreover, according to Definition \ref{def:SFPODtoSFPmap}
    $H(\delta)$ contains a pair of transitions which match both the possible
    characters on the tape, namely $\zzero$ or $\oone$.
    so
    $$
    \langle \sigma'', q'', \tau'', c_{j+1}\eta\rangle \reaches 1{H(\delta)}\langle \sigma', q', \tau',\eta\rangle
    $$
    This concludes the derivation.
  \end{itemize}
  The second claim comes from the definition fo $H(\delta)$: the oracle consuming
  transition which are in $\delta$ are in $H(\delta)$, too.
\end{proof}

\begin{lemma}
  \label{lemma:SFPODtoSFP}
  For every $M = \langle \Qs, \Sigma, \delta, q_0\rangle
  \in \SFPOD$, the machine $N = \langle \Qs, \Sigma, H(\delta), q_0\rangle
  \in \SFP$ is such that for evry $n \in \Nat$,
  for every configuration of $M$ $\langle \sigma, q, \tau, \eta\rangle$ and for
  every $\sigma', \tau' \in \Ss, q \in \Qs$.
  %, if
  %$\xi =c_1c_2\ldots c_k$ with $c_i \in \Bool$ for $1 \le i \le k$
  %and $\chi = c_{k+1} c_{k+2}\ldots c_{n}$, then
  $$
  \mu \left(\{\eta \in \Bool^\Nat| \exists \eta'. \langle \sigma, q, \tau, \eta\rangle\reaches n \delta \langle \sigma', q', \tau', \eta'\rangle\}\right)
  =
  \mu \left(\{\chi \in \Bool^\Nat|  \exists \chi'. \langle \sigma, q, \tau, \xi\rangle\reaches n {H(\delta)} \langle \sigma', q', \tau', \chi'\rangle\}\right)
  $$
\end{lemma}
\begin{proof}
  The definition of $\reaches n \delta$ (Definition \ref{def:smreachfuns}) allows us to rewrite the statement:
  $$
  \exists \eta'. \langle \sigma, q, \tau, \eta\rangle\reaches n \delta \langle \sigma', q', \tau', \eta'\rangle
  $$
  as
  \begin{align*}
    \exists \eta', c_1, \ldots, c_k. &\langle \sigma, q, \tau, c_1c_2\ldots c_k\eta'\rangle\reaches {n_1} \delta \langle \sigma_1, q_{i_1}, \tau_1, c_1c_2\ldots c_k\eta'\rangle\reaches 1 \delta \langle \sigma_1', q_{i_1}', \tau_1, c_2\ldots c_k\eta'\rangle \land \\
     &\langle \sigma_1', q_{i_1}', \tau_1, c_2\ldots c_k\eta'\rangle  \reaches {n_2} \delta \langle \sigma_2, q_{i_2}, \tau_2, c_2\ldots c_k\eta'\rangle\reaches 1 \delta \langle \sigma_2', q_{i_2}', \tau_2', c_3\ldots c_k\eta'\rangle \land \\
     &\langle \sigma_2', q_{i_2}', \tau_2', c_3\ldots c_k\eta'\rangle \reaches {n_3} \delta \ldots \reaches {n_{k+1}} \delta
    \langle \sigma', q', \tau', \eta'\rangle
  \end{align*}
  Accordig to Lemma \ref{lemma:SFPODtoSFPtech} and Definititions \ref{def:sfpod} and \ref{def:SFPODtoSFPmap}, we can write:
  \small
  \begin{align*}
    &\exists \eta', c_1, \ldots, c_k. \\&\langle \sigma, q, \tau, c_1c_2\ldots c_k\eta'
    \rangle\reaches {n_1} \delta \langle \sigma_1, q_{i_1}, \tau_1, c_1c_2\ldots c_k\eta'\rangle\reaches 1 \delta \langle \sigma_1', q_{i_1}', \tau_1, c_2\ldots c_k\eta'\rangle \land \\
     &\langle \sigma_1', q_{i_1}', \tau_1, c_2\ldots c_k\eta'\rangle  \reaches {n_2} \delta \langle \sigma_2, q_{i_2}, \tau_2, c_2\ldots c_k\eta'\rangle\reaches 1 \delta \langle \sigma_2', q_{i_2}', \tau_2', c_3\ldots c_k\eta'\rangle \land \\
     &\langle \sigma_2', q_{i_2}', \tau_2', c_3\ldots c_k\eta'\rangle \reaches {n_3} \delta \ldots \reaches {n_{k+1}} \delta
    \langle \sigma', q', \tau', \eta'\rangle\\
    &\Longleftrightarrow\\
    &\exists \xi_1, \ldots, \xi_{k+1}. |\xi_1|=n_1\land \ldots |\xi_{k+1}|=n_{k+1}\land\\
    &\langle \sigma, q, \tau, \xi_1c_1\xi_2c_2\ldots c_k\xi_{k+1}\eta'\rangle\reaches {n_1} {H(\delta)} \langle \sigma_1, q_{i_1}, \tau_1, c_1\xi_2c_2\ldots c_k\xi_{k+1}\eta'\rangle\reaches 1 {H(\delta)} \langle \sigma_1', q_{i_1}', \tau_1, \xi_2c_2\ldots c_k\xi_{k+1}\eta'\rangle \land \\
     &\langle \sigma_1', q_{i_1}', \tau_1, \xi_2c_2\ldots c_k\xi_{k+1}\eta'\rangle  \reaches {n_2} {H(\delta)} \langle \sigma_2, q_{i_2}, \tau_2, c_2\ldots c_k\xi_{k+1}\eta'\rangle\reaches 1 {H(\delta)} \langle \sigma_2', q_{i_2}', \tau_2', \xi_3c_3\ldots c_k\xi_{k+1}\eta'\rangle \land \\
     &\langle \sigma_2', q_{i_2}', \tau_2', \xi_3c_3\ldots c_k\eta'\rangle \reaches {n_3} {H(\delta)} \ldots \reaches {n_{k+1}} {H(\delta)}
    \langle \sigma', q', \tau', \eta'\rangle
  \end{align*}
  \normalsize
  For this reason:
  $$
  \{\eta \in \Bool^\Nat| \exists \eta'. \langle \sigma, q, \tau, \eta\rangle\reaches n \delta \langle \sigma', q', \tau', \eta'\rangle\} = \{\eta \in \Bool^\Nat| \forall 0 \le i \le k. \eta(i) =c_i\rangle\}
  $$
  $$
  \{\chi \in \Bool^\Nat|  \exists \chi'. \langle \sigma, q, \tau, \xi\rangle\reaches n {H(\delta)} \langle \sigma', q', \tau', \chi'\rangle\} = \{\chi \in \Bool^\Nat| \forall 1 \le i \le k. \chi(n_i+i)=c_i\land \chi(0)=c_1 \rangle\}
  $$
  At this point, the conclusion is trivial because both the set can be expressed as an intersection of sets of cylinders with the same size.
\end{proof}

As a corollary, we get the result we are aiming to:

\begin{cor}
  \label{cor:SFPODtoSFP}
  For every $\SFPOD$ machine $M := \langle \Qs, \Sigma, \delta, q\rangle$,
  $N := \langle \Qs, \Sigma, H(\delta), q\rangle$ is such that:
  $$
  \forall x, y. \mu\left (\{\eta \in \Bool^\Nat | M(x, \eta)=y\}\right)
  =
  \mu\left (\{\eta \in \Bool^\Nat | N(x, \eta)=y\}\right)
  $$
\end{cor}

\begin{proof}
  The result comes from the expansion of the definition of function computed
  by a Stream Machine \ref{def:smval}.
  Then, from Definititions \ref{def:sfpod} and \ref{def:SFPODtoSFPmap},
  we observe that
  a final configuration on $M$ is a final configuration on $N$, too.
  Finally, applying Lemma \ref{lemma:SFPODtoSFP} on the initial configurations of
  $M$ and $N$ (wich are identical by definition),
  we get the result we are aiming to.
\end{proof}





































\section{Completing the picture}

\subsection{From $\SFP$ to $\PPT$}
\label{sub:SFPtoPPT}

In this last Section we want to show that the set of all the $\SFP$ functions
and the set of the $\PPT$ funciton are tightly linked. In particular
the measure of the set of oracles which link an input $\sigma$ and an
output $\tau$ througout a computation of a $\SFP$ function $M$ is equal
to the probability that
a certain $\PPT$ function computes $\tau$ on the same input $\sigma$, and vice-versa.
%
To do so, we give a formal definition of the $\PPT$ functions leveraging the formalism
of the Probabilistic Turing Machines (for short PTM), on top of it, we introduce
the notion of function evaluated such machines. Finally, $\PPT$ is basically defined as
the set of functions computed by a Probabilitic Polynomial Turing Machine.
 After that, we show that there
is a bijection between the class of $\SFP$ machines and the class of PTM machines
with the property we are aiming to.
%

\begin{defn}[Probabilistic Turing Machine]
A Probabilistic Turing Machine (PTM)
$M:= \langle \Qs, \Sigma, {\delta}_0, {\delta}_1, q \rangle$ is a quintuple where:
\begin{itemize}
\item $\Qs$ is a finite set of states ranged over by $q_1, \ldots, q_n$.
\item $\Sigma$ is a finite set of characters ranged over by $c_1, \ldots, c_n$.
\item $\delta_0 : \Qs \times \Sigmab \longrightarrow \Qs \times \Sigmab \times \{L, R\}$
is a transition function which describes the new configuration reached by a $\SFP$ machine.
$L, R$ are two fixed constants, and $\Sigmab =\Sigma \cup \{*\} \land *\neq \zero \land * \neq \one$.
\item $\delta_1 : \Qs \times \Sigmab  \times \longrightarrow \Qs \times \Sigmab \times \{L, R\}$ is another transition function.
\item $q \in \Qs$ is an initial state.
\end{itemize}
\end{defn}

As we did for $\SFP$ we will use only \emph{canonical} PTM,
wich use $\{\zzero, \oone\}$ as alphabet and are single-taped.
%

\begin{defn}[Canonical PTM]
  A Canonical PTM is a PTM in which:
  \begin{itemize}
    \item $\Sigma =\{\zzero, \oone\}$
    \item $L = \zzero, R = \oone$
  \end{itemize}
\end{defn}

The function computed by a \emph{canonical} PTM does not map an input in $\Ss$,
and an oracle in $\Bool^\Nat$ to another input,
but maps a string in $\Ss$ to a probability distribution on the set $\Ss$. This is
why we cannot prove that $\PPT=\SFP$, but we will prove a form of equivalence
between the two classes.
%
The definition of function computed by a PTM passes through the
notion of configuration and a random variables associated to a machine.
%
The configurations are defined as follows:
%
\begin{defn}[Configuration of a Probabilistic Turing Machine]
The configuration of a PTM $M$ is a triple $\{\sigma, q, \tau\}$ where:
\begin{itemize}
\item $\sigma \in \Sigmab^*$ is the portion of the first tape on the left of the head.
\item $q \in \Qs$ is the current state of $M$.
\item $\tau \in \Sigmab^*$ is the portion of the first tape on the right of the head.
\end{itemize}
\end{defn}

As we argumented above, a Probabilistic Turing Machine computes
\emph{Random Variables}, instead of simple values. In order to
give a formal definition of the random variable computed by a PTM, we
must take in account a probability space of all the possible sequences
of choices made by a PTM.



\begin{defn}[Sequence of Random Variables associated to a Probabilistic Turing Machine]
  \label{def:ptmX}
Given a PTM machine $M$, a configuration $\{\sigma, q, \tau\}$
and the probability space $\mathcal C$ for
$\Bool^\Nat$ (Definition \ref{def:cylsigmaalgebra}), we define the following
sequence of random variables:

\begin{align*}
\forall \eta \in \Bool^\Nat. X_{M, 0}^{\{\sigma, q, \tau\}} &\coloneqq \eta \mapsto \{\sigma, q, \tau\}\\
\forall \eta \in \Bool^\Nat. X_{M, n+1}^{\{\sigma, q, \tau\}} & \coloneqq \eta \mapsto \begin{cases}
\delta_0(X_{M, n}^{\{\sigma, q, \tau\}}(\eta)) & \text{ if } \eta(n)=0 \land \exists \langle \sigma', q' \tau'\rangle. \delta_0(X_{M, n}^{\{\sigma, q, \tau\}}(\eta))=\langle \sigma', q', \tau'\rangle\\
X_{M, n}^{\{\sigma, q, \tau\}}(\eta) & \text{ if } \eta(n)=0 \land \lnot\exists \langle \sigma', q' \tau'\rangle. \delta_0(X_{M, n}^{\{\sigma, q, \tau\}}(\eta))=\langle \sigma', q', \tau'\rangle\\
\delta_1(X_{M, n}^{\{\sigma, q, \tau\}}(\eta)) & \text{ if } \eta(n)=1 \land \exists \langle \sigma', q' \tau'\rangle. \delta_1(X_{M, n}^{\{\sigma, q, \tau\}}(\eta))=\langle \sigma', q', \tau'\rangle\\
X_{M, n}^{\{\sigma, q, \tau\}}(\eta) & \text{ if } \eta(n)=1 \land \lnot\exists \langle \sigma', q' \tau'\rangle. \delta_1(X_{M, n}^{\{\sigma, q, \tau\}}(\eta))=\langle \sigma', q', \tau'\rangle
\end{cases}
\end{align*}
\end{defn}


Intuitively the variable $X_{M, n}^{\{\sigma, q, \tau\}}$ describes
the configuration reacehd by the machine after exactly $n$ transitions.
%
As we did for the Stream Machines, we need do geve a formal definition of random
variable computed by a PTM. To do so, we need to define some sort of
\emph{final} random variable.

\begin{defn}[Final configuration of a PTM]
We say that a Probabilistic Turing Machine $M$ has final configuration $X_t$
if and only if $\forall t'>t.X_{M, t'}^{\{\sigma, q, \tau\}}=X_{M, t}^{\{\sigma, q, \tau\}}$.
\end{defn}

We are interested in chatacterizing the $\PPT$ class of functions.
For this reason, we define the notion of \emph{poly-time} PTM.

\begin{defn}[Poly-time Probabilistic Turing Machine]
We say that a Probabilistic Turing Machine $M$ is polynomial in time
if and only if
$$
\exists p\in POLY. \forall \sigma.X_{M, p(\sigma)}^{\langle \epsilon, q_0, \sigma\rangle}
\text{ is final}.
$$
\end{defn}

\begin{defn}[Random Variable computed by a Probabilistic Turing Machine]
  \label{def:ptmY}
We say that a Probabilistic Turing Machine $M$ computes $Y_{M,\sigma}$ if and only if
$\exists t \in \Nat. \forall \sigma.X_{M, t}^{\langle \sigma, q_0, \tau\rangle}$ is final.
In such case $Y_{M,\sigma}$ is the longest suffix of
$\pi_1(X_{M, t}^{\langle \sigma, q_0, \epsilon\rangle})$, which does not contain $\circledast$.
\end{defn}

It's easy to see that the class of the Polynomial Probabilistic Turing Machine coincides with the class of $\SFP$: the latter hard-codes the randomicity on a specific tape, while the latter encodes its as a behaviour. It is proved formally by the following proposition:

























\begin{prop}[Polynomial PTM and $\SFP$ equivalence]
\label{prop:ptm=sfp}
For each Polynomial PTM $M$, there is an $\SFP$ machine $N$ such that
$$
\forall \sigma, \tau.\mu(\{\eta \in \Bool^\Nat| N(\sigma, \eta)= \tau\})=\mathit{Pr}[{Y_{M,\sigma}}=\tau]
$$
and vice-versa.
\end{prop}


\begin{proof}
We observe that, as stated in Definition \ref{def:ptmY}, the random variable
$Y_{\cdot, \cdot}$ is equal to the random variable
$X_{M, t}^{\langle \sigma, q_0, \epsilon\rangle}$ for some $t \in \Nat$.
According to Definition \ref{def:ptmX}, the random variable
$X_{M, t}^{\langle \sigma, q_0, \epsilon\rangle}$ is defined on the $\sigma$-algebra
$\mathcal C$, using exactly $\mu$ as probability measure.
%
For these reasons, the claim can be restated as follows:

\begin{align*}
\forall \sigma, \tau.\mu(\{\eta \in \Bool^\Nat| N(\sigma, \eta)= \tau\})&=\mu(Y_{M, \sigma}^{-1}(\tau))\\
\forall \sigma, \tau.\mu(\{\eta \in \Bool^\Nat| N(\sigma, \eta)= \tau\})&=\mu(\{\eta \in \Bool^\Nat| Y_{M,\sigma} (\eta) = \tau\})
\end{align*}

In order to prove what we stated above,
we will show a stronger result: that there is bijection $I: \text{Stream Machines} \longrightarrow \PTM$ such that:

\begin{equation}
\label{eq:measure}
\forall n \in \Nat.\{\eta \in \Bool^\Nat| \langle \sigma, q_0, \tau, \eta\rangle  \reaches n \delta \langle \tau, q, \psi, n\rangle \} = \{\eta \in \Bool^\Nat| X_{I(N), n}^{\langle \epsilon, q_0, \sigma\rangle} (\eta)= {\langle \tau, q, \psi\rangle}\}
\end{equation}

Which entails:

\begin{equation}
\label{eq:measurecons}
\{\eta \in \Bool^\Nat| N(\sigma, \eta)= \tau\} = \{\eta \in \Bool^\Nat| Y_{I(N),\sigma} (\eta) = \tau\}
\end{equation}

For this reason, it suffices to show $I$ and to prove that \ref{eq:measure} holds.
$I$ is defined splitting the transition function of $N$ int two
transition functions. A transition from $\delta$ is assigned to $\delta_0$
if it matches the $\zzero$ character on the oracle-tape, otherwise it
is assigned to $\delta_1$.
%
$I$ can be defined as follows:

\begin{align*}
I &\coloneqq \langle \Qs, \Sigma, \delta, q_0 \rangle \mapsto \langle \Qs, \Sigma, \Delta_0(\delta),\Delta_1(\delta), q_0 \rangle\\
\Delta_i(\delta) &\coloneqq \{\langle p, c_r, i, q, c_w, d \rangle \in \delta \}
\end{align*}

$I$ is bijective: indeed, its inverse is a function, too.
$I^{-1}$ takes two transition functions  (ideally the two transition functions of $M$)
and joins them in a single transition function which behaves as $\delta_0$ if the tape has $\zzero$
under the head, and otherwise as $\delta_1$.
%
Now we prove the \ref{eq:measure} by induction on the number of steps required by $N$ to compute its output value.

\begin{itemize}
\item[0] In this case we know that
\[
\{\eta \langle \sigma, q_0, \tau, \eta\rangle  \reaches 0 \delta \langle \epsilon, q_0, \sigma, \eta\rangle \} = \Bool^\Nat = \{\eta \in \Bool^\Nat| X_{I(N), 0}^{\langle \epsilon, q_0, \sigma\rangle} (\eta)= {\langle \epsilon, q, \sigma\rangle}\}
\]
Which proves the thesis.

\item[n+1] In this case we must show that
\[
\{\eta \in \Bool^\Nat| \langle \sigma, q_0, \tau, \eta\rangle  \reaches {n+1}\delta \langle \tau, q, \psi, \eta'\rangle \} = \{\eta \in \Bool^\Nat| X_{I(N), n+1}^{\langle \epsilon, q_0, \sigma\rangle} (\eta)= {\langle \tau, q, \psi\rangle}\}
\]
Which proves the thesis. We also know that
\[
\forall m\le n.\{\eta \in \Bool^\Nat| \langle \sigma, q_0, \tau, \eta\rangle  \reaches m \delta \langle \tau, q, \psi, \eta''\rangle \} = \{\eta \in \Bool^\Nat| X_{I(N), m}^{\langle \epsilon, q_0, \sigma\rangle} (\eta)= {\langle \tau, q, \psi\rangle}\}
\]
But it's easy to show that $\{\eta \in \Bool^\Nat| \langle \sigma, q_0, \tau, \eta\rangle  \reaches {n+1}\delta \langle \tau, q, \psi, \eta'\rangle \} =$
\begin{equation}
\label{eq:simplptm1}
\begin{gathered}
\{\eta \in \Bool^\Nat| \langle \sigma, q_0, \tau, \eta\rangle  \reaches n\delta \langle \tau', q', \psi', \zzero\eta'\rangle \vdash_\delta  \langle \tau, q, \psi, \eta'\rangle\}\\
\cup\\
\{\eta \in \Bool^\Nat| \langle \sigma, q_0, \tau, \eta\rangle  \reaches {n} \delta \langle \tau', q', \psi', \oone\eta'\rangle \vdash_\delta  \langle \tau, q, \psi, \eta'\rangle\}\\
\end{gathered}
\end{equation}
For what concerns the $\{\eta \in \Bool^\Nat| X_{I(N), n+1}^{\langle \epsilon, q_0, \sigma\rangle} (\eta)= {\langle \tau, q, \psi\rangle}\} =$
\begin{equation}
\label {eq:simplptm2}
\begin{gathered}
\{\eta \in \Bool^\Nat| X_{I(N), n}^{\langle \epsilon, q_0, \sigma\rangle} (\eta)= {\langle \tau', q', \psi' \rangle}\land \eta(n)=0 \land \Delta_0(\delta)(\langle \tau', q', \psi' \rangle)=\langle \tau, q, \psi\rangle\}\\
\cup\\
\{\eta \in \Bool^\Nat| X_{I(N), n}^{\langle \epsilon, q_0, \sigma\rangle} (\eta)= {\langle \tau', q', \psi' \rangle}\land \eta(n)=1 \land \Delta_1(\delta)(\langle \tau', q', \psi' \rangle)=\langle \tau, q, \psi\rangle\}
\end{gathered}
\end{equation}
It is easy to see that the sets in \eqref{eq:simplptm1} and \ref{eq:simplptm2} are pairwise equal thanks to the IH and the definition of $I$.

Claim \eqref{eq:measurecons} is a consequence of the definition if $Y$.

The opposite direction (i.e. the one described by the statement) comes from the fact that $I$ is a bijection.
\begin{comment}, so that we can say that $\forall N \in SM\exists M' \in PTM. I^{-1}(M') = N$, so:

\[
\{\omega \in \Os| I^{-1}(M')(\sigma, \omega)= \tau\} = \{\omega \in \Os| Y_{I(I^{-1}(M')),\sigma} (\omega) = \tau\}= \{\omega \in \Os| Y_{M',\sigma} (\omega) = \tau\}
\]
\end{comment}
\begin{comment}
\item[0] In this case the $\TT$ function doesn't contain any matching transition for the initial configuration for neither of the possible outputs on the oracle tape, in this case the output is $\sigma$. This means that both $\Delta_0(\TT)$ and $\Delta_1(\TT)$ are undefined for the initial configuration, so $X^{I(N)}_1$ is undefined for all $\omega \in \Os$. This means that $Y^{I(N)}_0=Y^{I(N)}_1$ and that $\forall \omega \in \Os. Y_{I(N),\sigma} (\omega) =\sigma$.
\begin{align*}
\{\omega \in \Os| N(\sigma)= \sigma\} &= \Os \\
                                          &= \Os =\{\omega \in \Os| Y_{I(N),\sigma} (\omega) =\sigma\}
\end{align*}

For each other value of $\tau$ both the sides of the equivalence \eqref{eq:measure} are $0$. Both the computations took exactly 0 steps.
\end{comment}
\end{itemize}
\end{proof}

This result comletes the chain of reductions from $\POR$ to $\PPT$ and vice-versa.





























\subsection{Main Result}
\label{sec:mainresult}

At this point, we have described all the reduction which encode $\SFP$ in $\POR$
and vice-versa, so we can finally state the main result.
%
As we argumented in \nameref{par:introduction},
the equivalence relation we are proving, is not a strict functional equivalence
as equality of functions, for many reasons: some of the formalisms are
intrinsically dis-omogeneous, i.e. the seto which they represent are disjoint.
%
Moreover, sometimes, the identity between the class of functions could
not be proved at all. For example, when we reduced $\SIFPRA$ to $\SIFPLA$ we
lost the possibility to query the oracle on arbitrary coordinates.
%
We ended up proving that a weak form of equivalence holded between our formalisms.
Those results can be used to prove the overall result: that Conjecture \ref{conj:SFP}
holds.

\begin{theorem}[$\POR$ and $\SFP$ equivalence]
  \label{thm:por=sfp}
  It holds that:
  \[
  \forall f\in \POR. \exists M_f \in \SFP.
  \forall x, y.\mu\big( \{\omega \in \Os | f(x, \omega)=y\} \big)=
  \mu \big(\{\eta \in \Bool^\Nat | M_f(x, \eta)=y\}\big)
  \]
  and conversely:
  \[
  \forall M_f \in \SFP. \exists f\in \POR.
  \forall x, y.\mu \big(\{\eta \in \Bool^\Nat | M_f(x, \eta)=y\}\big)=
  \mu\big( \{\omega \in \Os | f(x, \omega)=y\} \big)
  \]
\end{theorem}

\begin{proof}
  The first result coincides with Corollary \ref{cor:SFPtoPOR}, while the second
  is a consequence of:
  \begin{itemize}
    \item Corollary \ref{cor:PORtoSIFPRA}
    \item Lemma \ref{lemma:sifpratosifpla}
    \item Corollary \ref{cor:SIFPLAtoSFPOD}
    \item Corollary \ref{cor:SFPODtoSFP}
  \end{itemize}
\end{proof}

Proposition \ref{prop:ptm=sfp} completes the picture, showing that the class of
functions $\SFP$ corresponds strictly to $\PPT$. Thanks to that result, we can prove
that Conjecture \ref{conj:taskc} holds joining Theorem \ref{thm:por=sfp} and
Proposition \ref{prop:ptm=sfp}.

\begin{theorem}
It holds that
  \begin{itemize}
    \item $\forall f\in \PPT. \exists g_f \in \POR. \mathit{Pr}[f(x)=y]=
    \mu(\{x \in \{\zzero, \oone\}^\Ss | g_f(x, \omega)=y\})$
    \item $\forall g \in \POR. \exists f_g \in \PPT.
     \mu(\{x \in \{\zzero, \oone\}^\Ss | g(x, \omega)=y\})=\mathit{Pr}[f_g(x)=y]$
  \end{itemize}
\end{theorem}

\begin{proof}
  Consequence of Theorem \ref{thm:por=sfp} and Proposition \ref{prop:ptm=sfp}.
\end{proof}
